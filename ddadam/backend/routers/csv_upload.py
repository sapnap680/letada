# backend/routers/csv_upload.py
from fastapi import APIRouter, UploadFile, File, BackgroundTasks, HTTPException
from pydantic import BaseModel
from typing import Optional, List, Dict
import pandas as pd
import uuid
import json
import os
import logging
from io import StringIO

router = APIRouter(tags=["csv"])
logger = logging.getLogger(__name__)

class CsvVerifyRequest(BaseModel):
    university_name: str
    jba_credentials: Optional[Dict] = None
    threshold: float = 0.8
    max_workers: int = 5

class CsvVerifyResponse(BaseModel):
    status: str
    job_id: str
    message: str
    polling_url: str

def run_csv_verification_job(
    job_id: str,
    df: pd.DataFrame,
    university_name: str,
    credentials: Optional[Dict] = None,
    threshold: float = 0.8,
    max_workers: int = 5
):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¸ãƒ§ãƒ–"""
    from worker.jba_verification_lib import JBAVerificationSystem, FastCSVCorrectionSystem
    
    job_file = f"temp_results/job_{job_id}.json"
    os.makedirs("temp_results", exist_ok=True)
    
    try:
        # ã‚¸ãƒ§ãƒ–é–‹å§‹
        meta = {
            "job_id": job_id,
            "status": "processing",
            "progress": 0.0,
            "message": "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­...",
            "university": university_name,
            "rows": len(df)
        }
        with open(job_file, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
        
        # JBAã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        jba_system = JBAVerificationSystem()
        
        # ãƒ­ã‚°ã‚¤ãƒ³
        if credentials:
            meta["message"] = "JBAã«ãƒ­ã‚°ã‚¤ãƒ³ä¸­..."
            meta["progress"] = 0.1
            with open(job_file, "w", encoding="utf-8") as f:
                json.dump(meta, f, ensure_ascii=False, indent=2)
            
            jba_system.login(credentials["email"], credentials["password"])
        
        # CSVå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        meta["message"] = "CSVå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­..."
        meta["progress"] = 0.2
        with open(job_file, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
        
        csv_system = FastCSVCorrectionSystem(
            jba_system=jba_system,
            max_workers=max_workers
        )
        
        # CSVå‡¦ç†
        meta["message"] = f"é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ã‚’ç…§åˆä¸­...ï¼ˆ{len(df)}è¡Œï¼‰"
        meta["progress"] = 0.3
        with open(job_file, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
        
        results = csv_system.process_csv_file_parallel(
            df=df,
            university_name=university_name,
            threshold=threshold
        )
        
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        meta["message"] = "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­..."
        meta["progress"] = 0.8
        with open(job_file, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
        
        excel_buffer = csv_system.create_colored_excel(df, results)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        output_dir = "outputs"
        os.makedirs(output_dir, exist_ok=True)
        output_filename = f"{university_name}_verified_{job_id[:8]}.xlsx"
        output_path = os.path.join(output_dir, output_filename)
        
        with open(output_path, "wb") as f:
            f.write(excel_buffer.getvalue())
        
        # å®Œäº†
        meta["status"] = "done"
        meta["progress"] = 1.0
        meta["message"] = "å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ"
        meta["output_path"] = output_path
        meta["output_filename"] = output_filename
        
        with open(job_file, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… CSVã‚¸ãƒ§ãƒ–å®Œäº†: {job_id}")
        
    except Exception as e:
        logger.error(f"âŒ CSVã‚¸ãƒ§ãƒ–ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        
        meta = {
            "job_id": job_id,
            "status": "error",
            "progress": 0.0,
            "message": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
            "error": str(e)
        }
        with open(job_file, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)


@router.post("/upload", response_model=CsvVerifyResponse)
async def upload_csv(
    file: UploadFile = File(...),
    university_name: str = None,
    background_tasks: BackgroundTasks = None
):
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦JBAç…§åˆã‚’é–‹å§‹
    
    - **file**: CSVãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆUTF-8ã¾ãŸã¯Shift_JISï¼‰
    - **university_name**: å¤§å­¦åï¼ˆçœç•¥å¯èƒ½ï¼‰
    """
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ãƒã‚§ãƒƒã‚¯
        if not file.filename.endswith('.csv'):
            raise HTTPException(
                status_code=400,
                detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™"
            )
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        content = await file.read()
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œ
        df = None
        encodings = ['utf-8', 'shift_jis', 'cp932', 'utf-8-sig']
        
        for encoding in encodings:
            try:
                text = content.decode(encoding)
                df = pd.read_csv(StringIO(text))
                break
            except (UnicodeDecodeError, pd.errors.ParserError):
                continue
        
        if df is None:
            raise HTTPException(
                status_code=400,
                detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚UTF-8ã¾ãŸã¯Shift_JISã§ä¿å­˜ã—ã¦ãã ã•ã„ã€‚"
            )
        
        # å¤§å­¦åãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å–å¾—
        if not university_name:
            university_name = file.filename.replace('.csv', '').replace('_', ' ')
        
        # ã‚¸ãƒ§ãƒ–IDç”Ÿæˆ
        job_id = str(uuid.uuid4())
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¸ãƒ§ãƒ–ã‚’é–‹å§‹
        background_tasks.add_task(
            run_csv_verification_job,
            job_id=job_id,
            df=df,
            university_name=university_name,
            threshold=0.8,
            max_workers=5
        )
        
        logger.info(f"ğŸ“Š CSVã‚¸ãƒ§ãƒ–é–‹å§‹: {job_id} - {university_name} ({len(df)}è¡Œ)")
        
        return CsvVerifyResponse(
            status="queued",
            job_id=job_id,
            message=f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼ˆ{len(df)}è¡Œï¼‰",
            polling_url=f"/jobs/{job_id}"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/download/{filename}")
async def download_excel(filename: str):
    """å‡¦ç†æ¸ˆã¿Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    from fastapi.responses import FileResponse
    
    file_path = os.path.join("outputs", filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    return FileResponse(
        file_path,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        filename=filename
    )


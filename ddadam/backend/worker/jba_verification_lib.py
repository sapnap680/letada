#!/usr/bin/env python3
"""
CSVè‡ªå‹•è¨‚æ­£ã‚·ã‚¹ãƒ†ãƒ 
JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ç…§åˆã—ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•è¨‚æ­£
"""

# Streamlit import removed
import pandas as pd
import logging
import requests
import json
from bs4 import BeautifulSoup
from datetime import datetime
import re
import unicodedata
from difflib import SequenceMatcher
import io
# import google.generativeai as genai  # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
import os
import concurrent.futures
import time
import threading

# ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
logger = logging.getLogger(__name__)

# Streamlit éžä¾å­˜åŒ–ã®ãŸã‚ã®ã‚¹ã‚¿ãƒ–
try:
    import streamlit as st  # å®Ÿè¡Œç’°å¢ƒã«ã‚ã‚Œã°ä½¿ç”¨
except Exception:
    class _DummyCtx:
        def __enter__(self):
            return self
        def __exit__(self, exc_type, exc, tb):
            return False
    class _STStub:
        def __getattr__(self, name):
            if name == 'columns':
                return lambda n: [_DummyCtx() for _ in range(n)]
            if name == 'tabs':
                return lambda names: [_DummyCtx() for _ in names]
            if name == 'expander':
                return lambda *a, **k: _DummyCtx()
            return lambda *a, **k: None
    st = _STStub()

# ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãŒæœªå®šç¾©ã§ã‚‚è½ã¡ãªã„ã‚ˆã†ã«ãƒ€ãƒŸãƒ¼å®šç¾©
class _Placeholder:
    def __getattr__(self, name):
        return lambda *a, **k: None
status_placeholder = _Placeholder()
csv_progress = _Placeholder()
csv_status = _Placeholder()

class JBAVerificationSystem:
    """JBAæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆrequests + BeautifulSoupãƒ™ãƒ¼ã‚¹ï¼‰"""
    logger = logging.getLogger(__name__)
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
            'Accept': 'application/json',
            'Accept-Language': 'ja,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Origin': 'https://team-jba.jp',
            'Referer': 'https://team-jba.jp/organization/15250600/team/search',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
            'X-Requested-With': 'XMLHttpRequest'
        })
        self.logged_in = False
    
    def get_current_fiscal_year(self):
        """ç¾åœ¨ã®å¹´åº¦ã‚’å–å¾—"""
        current_year = datetime.now().year
        current_month = datetime.now().month
        
        if current_month >= 1:
            return str(current_year)
        else:
            return str(current_year - 1)
    
    def normalize_university_name(self, university_name):
        """å¤§å­¦åã‚’æ­£è¦åŒ–ï¼ˆæŸ”è»Ÿãªç…§åˆã®ãŸã‚ï¼‰"""
        if not university_name:
            return ""
        
        # åŸºæœ¬çš„ãªæ­£è¦åŒ–
        normalized = university_name.strip()
        
        # ã‚ˆãã‚ã‚‹è¡¨è¨˜ã®çµ±ä¸€
        replacements = {
            'ç™½é·—å¤§å­¦': 'ç™½é´Žå¤§å­¦',
            'ç™½é´Žå¤§å­¦': 'ç™½é´Žå¤§å­¦',
            'ç™½é·—': 'ç™½é´Ž',
            'ç™½é´Ž': 'ç™½é´Ž',
            'å¤§å­¦': 'å¤§å­¦',
            'å­¦é™¢': 'å­¦é™¢',
            'çŸ­æœŸå¤§å­¦': 'çŸ­æœŸå¤§å­¦',
            'çŸ­å¤§': 'çŸ­æœŸå¤§å­¦'
        }
        
        for old, new in replacements.items():
            normalized = normalized.replace(old, new)
        
        return normalized
    
    def get_search_variations(self, university_name):
        """å¤§å­¦åã®æ¤œç´¢ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        if not university_name:
            return []
        
        variations = [university_name.strip()]
        
        # é•·ã„å¤§å­¦åã®å ´åˆã€çŸ­ç¸®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚è¿½åŠ 
        if len(university_name) > 6:  # é•·ã„åå‰ã®å ´åˆ
            # èªžå°¾ã‚’æ®µéšŽçš„ã«å‰Šé™¤
            suffixes_to_remove = ['ä½“è‚²ä¼šãƒã‚¹ã‚±ãƒƒãƒˆãƒœãƒ¼ãƒ«éƒ¨', 'ãƒã‚¹ã‚±ãƒƒãƒˆãƒœãƒ¼ãƒ«éƒ¨', 'ä½“è‚²ä¼š', 'éƒ¨']
            
            for suffix in suffixes_to_remove:
                if university_name.endswith(suffix):
                    base_name = university_name[:-len(suffix)].strip()
                    if base_name and len(base_name) > 2:  # æœ€ä½Ž3æ–‡å­—ä»¥ä¸Š
                        variations.append(base_name)
        
        # ã€Œå¤§å­¦ã€ã‚’é™¤ã„ãŸéƒ¨åˆ†ã‚‚è¿½åŠ ï¼ˆæœ€å„ªå…ˆï¼‰
        if 'å¤§å­¦' in university_name:
            # ã€Œâ—‹â—‹å¤§å­¦ã€â†’ã€Œâ—‹â—‹ã€ã‚’æŠ½å‡º
            base_without_daigaku = university_name.replace('å¤§å­¦', '').strip()
            if base_without_daigaku and len(base_without_daigaku) > 1:  # æœ€ä½Ž2æ–‡å­—ä»¥ä¸Š
                # æœ€å„ªå…ˆã§æ¤œç´¢ã™ã‚‹ãŸã‚ã€ãƒªã‚¹ãƒˆã®å…ˆé ­ã«è¿½åŠ 
                variations.insert(0, base_without_daigaku)
        
        # é‡è¤‡ã‚’å‰Šé™¤ï¼ˆé †åºã‚’ä¿æŒï¼‰
        seen = set()
        unique_variations = []
        for v in variations:
            if v not in seen:
                seen.add(v)
                unique_variations.append(v)
        
        return unique_variations
    
    def login(self, email, password):
        """JBAã‚µã‚¤ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³"""
        try:
            # ðŸ†• ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            # Status placeholder removed
            # Progress bar removed - use job_meta instead
            
            # Status placeholder update removed
            # Progress update removed
            
            login_page = self.session.get("https://team-jba.jp/login")
            soup = BeautifulSoup(login_page.content, 'html.parser')
            
            csrf_token = ""
            csrf_input = soup.find('input', {'name': '_token'})
            if csrf_input:
                csrf_token = csrf_input.get('value', '')
            
            # Status placeholder update removed
            # Progress update removed
            
            login_data = {
                '_token': csrf_token,
                'login_id': email,
                'password': password
            }
            
            login_url = "https://team-jba.jp/login/done"
            login_response = self.session.post(login_url, data=login_data, allow_redirects=True)
            
            # Status placeholder update removed
            # Progress update removed
            
            if "ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ" in login_response.text:
                self.logged_in = True
                # Status placeholder update removed
                # Sleep removed  # 1ç§’è¡¨ç¤º
                # Progress bar cleanup removed
                pass
                return True
            else:
                # Status placeholder update removed
                # Sleep removed  # 2ç§’è¡¨ç¤º
                # Progress bar cleanup removed
                pass
                return False
                
        except Exception as e:
            logger.error(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def search_teams_by_university(self, university_name):
        """å¤§å­¦åã§ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ï¼ˆæŸ”è»Ÿãªç…§åˆï¼‰"""
        try:
            if not self.logged_in:
                # ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™
                return []
            
            current_year = self.get_current_fiscal_year()
            # ç”·å­ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ä¸­
            
            # å¤§å­¦åã®æ­£è¦åŒ–ï¼ˆæŸ”è»Ÿãªç…§åˆã®ãŸã‚ï¼‰
            normalized_university = self.normalize_university_name(university_name)
            # æ­£è¦åŒ–ã•ã‚ŒãŸå¤§å­¦å
            
            # æ­£è¦åŒ–ã•ã‚ŒãŸå¤§å­¦åã§æ¤œç´¢
            search_university = normalized_university
            
            # æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            search_url = "https://team-jba.jp/organization/15250600/team/search"
            search_page = self.session.get(search_url)
            
            if search_page.status_code != 200:
                # æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“
                return []
            
            soup = BeautifulSoup(search_page.content, 'html.parser')
            
            # CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            csrf_token = ""
            csrf_input = soup.find('input', {'name': '_token'})
            if csrf_input:
                csrf_token = csrf_input.get('value', '')
            
            # JSON APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢ï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰
            search_data = {
                "limit": 100,
                "offset": 0,
                "searchLogic": "AND",
                "search": [
                    {"field": "fiscal_year", "type": "text", "operator": "is", "value": current_year},
                    {"field": "team_name", "type": "text", "operator": "contains", "value": search_university},
                    {"field": "competition_division_id", "type": "int", "operator": "is", "value": 1},
                    {"field": "team_search_out_of_range", "type": "int", "operator": "is", "value": 1}
                ]
            }
            
            form_data = {'request': json.dumps(search_data, ensure_ascii=False)}
            headers = {
                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                'X-CSRF-Token': csrf_token,
                'X-Requested-With': 'XMLHttpRequest'
            }
            
            # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ï¼ˆJSON APIã¨ã—ã¦ï¼‰
            search_response = self.session.post(
                search_url, 
                data=form_data,
                headers=headers
            )
            
            if search_response.status_code != 200:
                # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ
                return []
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æž
            try:
                data = search_response.json()
                teams = []
                
                if data.get('status') == 'success' and 'records' in data:
                    for team_data in data['records']:
                        # ç”·å­ãƒãƒ¼ãƒ ã®ã¿ã‚’å¯¾è±¡
                        if team_data.get('team_gender_id') == 'ç”·å­':
                            teams.append({
                                'id': team_data.get('id', ''),
                                'name': team_data.get('team_name', ''),
                                'url': f"https://team-jba.jp/organization/15250600/team/{team_data.get('id', '')}/detail"
                            })
                
                # ç”·å­ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ
                return teams
                
            except Exception as e:
                # æ¤œç´¢çµæžœã®è§£æžã«å¤±æ•—ã—ã¾ã—ãŸ
                return []
            
        except Exception as e:
            # ãƒãƒ¼ãƒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼
            return []
    
    def _search_teams_by_university_silent(self, university_name):
        """å¤§å­¦åã§ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ï¼ˆé™ã‹ãªå®Ÿè¡Œç‰ˆ - st.*å‡ºåŠ›ãªã—ï¼‰"""
        try:
            if not self.logged_in:
                return []
            
            current_year = self.get_current_fiscal_year()
            
            # å¤§å­¦åã®æ­£è¦åŒ–ï¼ˆæŸ”è»Ÿãªç…§åˆã®ãŸã‚ï¼‰
            normalized_university = self.normalize_university_name(university_name)
            
            # æ­£è¦åŒ–ã•ã‚ŒãŸå¤§å­¦åã§æ¤œç´¢
            search_university = normalized_university
            
            # æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            search_url = "https://team-jba.jp/organization/15250600/team/search"
            search_page = self.session.get(search_url)
            
            if search_page.status_code != 200:
                return []
            
            soup = BeautifulSoup(search_page.content, 'html.parser')
            
            # CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            csrf_token = ""
            csrf_input = soup.find('input', {'name': '_token'})
            if csrf_input:
                csrf_token = csrf_input.get('value', '')
            
            # JSON APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢ï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰
            search_data = {
                "limit": 100,
                "offset": 0,
                "searchLogic": "AND",
                "search": [
                    {"field": "fiscal_year", "type": "text", "operator": "is", "value": current_year},
                    {"field": "team_name", "type": "text", "operator": "contains", "value": search_university},
                    {"field": "competition_division_id", "type": "int", "operator": "is", "value": 1},
                    {"field": "team_search_out_of_range", "type": "int", "operator": "is", "value": 1}
                ]
            }
            
            form_data = {'request': json.dumps(search_data, ensure_ascii=False)}
            headers = {
                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                'X-CSRF-Token': csrf_token,
                'X-Requested-With': 'XMLHttpRequest'
            }
            
            # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ï¼ˆJSON APIã¨ã—ã¦ï¼‰
            search_response = self.session.post(
                search_url, 
                data=form_data,
                headers=headers
            )
            
            if search_response.status_code != 200:
                return []
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æž
            try:
                data = search_response.json()
                teams = []
                
                if data.get('status') == 'success' and 'records' in data:
                    for team_data in data['records']:
                        # ç”·å­ãƒãƒ¼ãƒ ã®ã¿ã‚’å¯¾è±¡
                        if team_data.get('team_gender_id') == 'ç”·å­':
                            teams.append({
                                'id': team_data.get('id', ''),
                                'name': team_data.get('team_name', ''),
                                'url': f"https://team-jba.jp/organization/15250600/team/{team_data.get('id', '')}/detail"
                            })
                
                return teams
                
            except Exception as e:
                return []
            
        except Exception as e:
            return []

    def get_team_members(self, team_url):
        """ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰"""
        try:
            # ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ä¸­
            logger.info(f"ðŸ” ãƒãƒ¼ãƒ URL: {team_url}")
            
            # ãƒãƒ¼ãƒ è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            team_page = self.session.get(team_url)
            
            if team_page.status_code != 200:
                # ãƒãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“
                return {"team_name": "Error", "members": []}
            
            soup = BeautifulSoup(team_page.content, 'html.parser')
            
            # ãƒãƒ¼ãƒ åã‚’å–å¾—
            team_name = "Unknown Team"
            title_element = soup.find('title')
            if title_element:
                team_name = title_element.get_text(strip=True)
            
            logger.info(f"ðŸ” ãƒãƒ¼ãƒ å: {team_name}")

            # ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’æŠ½å‡ºï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç‰¹å®šï¼‰
            members = []
            
            tables = soup.find_all('table')

            # ç”·å­ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŽ¢ã™ï¼ˆ3åˆ—ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŽ¢ã™ï¼‰
            member_table = None
            for i, table in enumerate(tables):
                rows = table.find_all('tr')
                if len(rows) > 10:  # ãƒ¡ãƒ³ãƒãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã¯é€šå¸¸10è¡Œä»¥ä¸Š
                    # æœ€åˆã®è¡Œã«ã€Œãƒ¡ãƒ³ãƒãƒ¼ID / æ°å / ç”Ÿå¹´æœˆæ—¥ã€ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    first_row_cells = rows[0].find_all(['td', 'th'])
                    if len(first_row_cells) >= 3:
                        first_cell = first_row_cells[0].get_text(strip=True)
                        second_cell = first_row_cells[1].get_text(strip=True)
                        third_cell = first_row_cells[2].get_text(strip=True)
                        if "ãƒ¡ãƒ³ãƒãƒ¼ID" in first_cell and "æ°å" in second_cell and "ç”Ÿå¹´æœˆæ—¥" in third_cell:
                            member_table = table
                            break

            if member_table:
                rows = member_table.find_all('tr')
                for row in rows[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 3:
                        member_id = cells[0].get_text(strip=True)
                        name = cells[1].get_text(strip=True)
                        birth_date = cells[2].get_text(strip=True)
                        
                        # ãƒ¡ãƒ³ãƒãƒ¼IDãŒæ•°å­—ã§ã€åå‰ãŒç©ºã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                        if member_id.isdigit() and name and name != "æ°å":
                            # é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã®ãƒªãƒ³ã‚¯ã‚’å–å¾—
                            detail_link = None
                            name_cell = cells[1]
                            link = name_cell.find('a')
                            if link and link.get('href'):
                                detail_link = link.get('href')
                                # ç›¸å¯¾URLã‚’çµ¶å¯¾URLã«å¤‰æ›
                                if detail_link.startswith('/'):
                                    detail_link = f"https://team-jba.jp{detail_link}"
                            
                            members.append({
                                "member_id": member_id,
                                "name": name,
                                "birth_date": birth_date,
                                "detail_url": detail_link
                            })

            return {
                "team_name": team_name,
                "members": members
            }
            
        except Exception as e:
            # ãƒ¡ãƒ³ãƒãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼
            import traceback
            logger.info(f"**ã‚¨ãƒ©ãƒ¼è©³ç´°**: {traceback.format_exc()}")
            return {"team_name": "Error", "team_url": team_url, "members": []}
    
    def _get_team_members_silent(self, team_url):
        """ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ï¼ˆé™ã‹ãªå®Ÿè¡Œç‰ˆ - st.*å‡ºåŠ›ãªã—ï¼‰"""
        try:
            # ãƒãƒ¼ãƒ è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            team_page = self.session.get(team_url)
            
            if team_page.status_code != 200:
                return {"team_name": "Error", "members": []}
            
            soup = BeautifulSoup(team_page.content, 'html.parser')
            
            # ãƒãƒ¼ãƒ åã‚’å–å¾—
            team_name = "Unknown Team"
            title_element = soup.find('title')
            if title_element:
                team_name = title_element.get_text(strip=True)
            
            # ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—
            members = []
            
            # é¸æ‰‹ä¸€è¦§ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŽ¢ã™
            member_tables = soup.find_all('table', class_='table')
            
            for table_idx, table in enumerate(member_tables):
                rows = table.find_all('tr')
                
                for row_idx, row in enumerate(rows[1:], start=1):  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    cells = row.find_all(['td', 'th'])
                    
                    if len(cells) >= 3:  # æœ€ä½Žé™ã®æƒ…å ±ãŒã‚ã‚‹è¡Œã®ã¿å‡¦ç†
                        # é¸æ‰‹åã®ãƒªãƒ³ã‚¯ã‚’æŽ¢ã™ï¼ˆJBAã®å®Ÿéš›ã®URLãƒ‘ã‚¿ãƒ¼ãƒ³: /member/to-team/æ•°å­—/detailï¼‰
                        name_link = row.find('a', href=re.compile(r'/member/to-team/\d+'))
                        
                        if name_link:
                            player_name = name_link.get_text(strip=True)
                            detail_url = name_link['href']
                            
                            if not detail_url.startswith('http'):
                                detail_url = f"https://team-jba.jp{detail_url}"
                            
                            # ãã®ä»–ã®æƒ…å ±ã‚’å–å¾—
                            position = ""
                            grade = ""
                            height = ""
                            weight = ""
                            
                            for i, cell in enumerate(cells):
                                cell_text = cell.get_text(strip=True)
                                
                                # ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼ˆé€šå¸¸ã¯2ç•ªç›®ã®ã‚«ãƒ©ãƒ ï¼‰
                                if i == 1 and cell_text and cell_text not in ['é¸æ‰‹å', 'æ°å']:
                                    position = cell_text
                                
                                # å­¦å¹´ï¼ˆé€šå¸¸ã¯3ç•ªç›®ã®ã‚«ãƒ©ãƒ ï¼‰
                                elif i == 2 and cell_text and cell_text not in ['å­¦å¹´', 'å¹´']:
                                    grade = cell_text
                                
                                # èº«é•·ãƒ»ä½“é‡ã®æƒ…å ±ã‚’æŽ¢ã™
                                if 'cm' in cell_text:
                                    height = cell_text
                                elif 'kg' in cell_text:
                                    weight = cell_text
                            
                            members.append({
                                "name": player_name,
                                "position": position,
                                "grade": grade,
                                "height": height,
                                "weight": weight,
                                "detail_url": detail_url
                            })
            
            # æœ€çµ‚çµæžœã‚’ãƒ­ã‚°ã«è¨˜éŒ²ï¼ˆãƒ¡ãƒ³ãƒãƒ¼ãŒ0äººã®å ´åˆã®ã¿è­¦å‘Šï¼‰
            if len(members) == 0:
                logger.warning(f"âš ï¸ ãƒãƒ¼ãƒ  {team_name} ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            return {
                "team_name": team_name,
                "members": members
            }
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¡ãƒ³ãƒãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
            return {"team_name": "Error", "members": []}
    
    def get_player_details(self, detail_url):
        """é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰èº«é•·ãƒ»ä½“é‡ãªã©ã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        try:
            if not detail_url:
                return {}
            
            # é¸æ‰‹è©³ç´°æƒ…å ±ã‚’å–å¾—ä¸­
            
            # é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            detail_page = self.session.get(detail_url)
            
            if detail_page.status_code != 200:
                # é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“
                return {}
            
            soup = BeautifulSoup(detail_page.content, 'html.parser')
            
            # é¸æ‰‹è©³ç´°æƒ…å ±ã‚’æŠ½å‡º
            player_details = {}
            
            # èº«é•·ãƒ»ä½“é‡æƒ…å ±ã‚’æŽ¢ã™
            # ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
            height_patterns = [
                r'èº«é•·[ï¼š:]\s*(\d+\.?\d*)\s*cm',
                r'èº«é•·[ï¼š:]\s*(\d+\.?\d*)\s*ã‚»ãƒ³ãƒ',
                r'Height[ï¼š:]\s*(\d+\.?\d*)\s*cm'
            ]
            
            weight_patterns = [
                r'ä½“é‡[ï¼š:]\s*(\d+\.?\d*)\s*kg',
                r'ä½“é‡[ï¼š:]\s*(\d+\.?\d*)\s*ã‚­ãƒ­',
                r'Weight[ï¼š:]\s*(\d+\.?\d*)\s*kg'
            ]
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
            tables = soup.find_all('table')
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:
                        label = cells[0].get_text(strip=True)
                        value = cells[1].get_text(strip=True)
                        
                        # èº«é•·æƒ…å ±ï¼ˆJBAã®ã€Œèº«é•·ï¼ˆç«¶æŠ€è€…ç”¨ï¼‰ã€ã«å¯¾å¿œï¼‰
                        if 'èº«é•·' in label or 'Height' in label:
                            # æ•°å€¤éƒ¨åˆ†ã‚’æŠ½å‡º
                            import re
                            height_match = re.search(r'(\d+\.?\d*)', value)
                            if height_match and value.strip():  # ç©ºã§ãªã„å ´åˆã®ã¿
                                player_details['height'] = height_match.group(1)
                        
                        # ä½“é‡æƒ…å ±ï¼ˆJBAã®ã€Œä½“é‡ï¼ˆç«¶æŠ€è€…ç”¨ï¼‰ã€ã«å¯¾å¿œï¼‰
                        elif 'ä½“é‡' in label or 'Weight' in label:
                            # æ•°å€¤éƒ¨åˆ†ã‚’æŠ½å‡º
                            import re
                            weight_match = re.search(r'(\d+\.?\d*)', value)
                            if weight_match and value.strip():  # ç©ºã§ãªã„å ´åˆã®ã¿
                                player_details['weight'] = weight_match.group(1)
                        
                        # ãƒã‚¸ã‚·ãƒ§ãƒ³æƒ…å ±
                        elif 'ãƒã‚¸ã‚·ãƒ§ãƒ³' in label or 'Position' in label:
                            player_details['position'] = value
                        
                        # å‡ºèº«æ ¡æƒ…å ±
                        elif 'å‡ºèº«æ ¡' in label or 'å‡ºèº«' in label:
                            player_details['school'] = value
                        
                        # å­¦å¹´æƒ…å ±
                        elif 'å­¦å¹´' in label or 'Grade' in label:
                            player_details['grade'] = value
                        
                        # ãƒ¦ãƒ‹ãƒ•ã‚©ãƒ¼ãƒ ç•ªå·
                        elif 'ãƒ¦ãƒ‹ãƒ•ã‚©ãƒ¼ãƒ ç•ªå·' in label or 'èƒŒç•ªå·' in label:
                            player_details['uniform_number'] = value
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã§è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãƒšãƒ¼ã‚¸å…¨ä½“ã‹ã‚‰æ­£è¦è¡¨ç¾ã§æ¤œç´¢
            if 'height' not in player_details or 'weight' not in player_details:
                page_text = soup.get_text()
                
                # èº«é•·ã‚’æ¤œç´¢
                for pattern in height_patterns:
                    import re
                    match = re.search(pattern, page_text)
                    if match:
                        player_details['height'] = match.group(1)
                        break
                
                # ä½“é‡ã‚’æ¤œç´¢
                for pattern in weight_patterns:
                    import re
                    match = re.search(pattern, page_text)
                    if match:
                        player_details['weight'] = match.group(1)
                        break
            
            return player_details
            
        except Exception as e:
            # é¸æ‰‹è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼
            return {}
    

    def normalize_name(self, name):
        """åå‰ã®æ­£è¦åŒ–"""
        if not name or pd.isna(name):
            return ""
        
        name = str(name)
        
        # 1. å…¨è§’ãƒ»åŠè§’çµ±ä¸€
        name = unicodedata.normalize('NFKC', name)
        
        # 2. è¨˜å·ãƒ»ã‚¹ãƒšãƒ¼ã‚¹ã®æ­£è¦åŒ–ï¼ˆå…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚‚å«ã‚€ï¼‰
        name = re.sub(r'[ãƒ»ï½¥ã€ï¼Œ,\.\sã€€]+', '', name)
        
        # 3. å¤§æ–‡å­—å°æ–‡å­—çµ±ä¸€
        name = name.lower()
        
        # 4. ã‚ˆãã‚ã‚‹è¡¨è¨˜æºã‚Œã®çµ±ä¸€
        name = re.sub(r'[ãƒ¼âˆ’â€â€”â€“]', '', name)  # é•·éŸ³ç¬¦ã€ãƒã‚¤ãƒ•ãƒ³ã€ã‚¨ãƒ ãƒ€ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒ³ãƒ€ãƒƒã‚·ãƒ¥é™¤åŽ»
        
        return name

    def calculate_similarity(self, name1, name2):
        """åå‰ã®é¡žä¼¼åº¦ã‚’è¨ˆç®—"""
        if not name1 or not name2:
            return 0.0
        
        # æ­£è¦åŒ–
        norm_name1 = self.normalize_name(name1)
        norm_name2 = self.normalize_name(name2)
        
        if norm_name1 == norm_name2:
            return 1.0
        
        # åŸºæœ¬çš„ãªé¡žä¼¼åº¦
        basic_similarity = SequenceMatcher(None, norm_name1, norm_name2).ratio()
        
        return basic_similarity
    
    def show_name_differences(self, name1, name2):
        """åå‰ã®å¾®å¦™ãªé•ã„ã‚’è¦–è¦šçš„ã«è¡¨ç¤º"""
        if not name1 or not name2:
            return ""
        
        # æ­£è¦åŒ–
        norm_name1 = self.normalize_name(name1)
        norm_name2 = self.normalize_name(name2)
        
        if norm_name1 == norm_name2:
            return "âœ… å®Œå…¨ä¸€è‡´"
        
        # æ–‡å­—å˜ä½ã§ã®å·®åˆ†ã‚’è¡¨ç¤º
        matcher = SequenceMatcher(None, norm_name1, norm_name2)
        differences = []
        
        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag == 'equal':
                differences.append(norm_name1[i1:i2])
            elif tag == 'delete':
                differences.append(f"âŒ{norm_name1[i1:i2]}âŒ")
            elif tag == 'insert':
                differences.append(f"âž•{norm_name2[j1:j2]}âž•")
            elif tag == 'replace':
                differences.append(f"ðŸ”„{norm_name1[i1:i2]}â†’{norm_name2[j1:j2]}ðŸ”„")
        
        result = "".join(differences)
        return f"ðŸ” å·®åˆ†: {result}"

    def verify_player_info(self, player_name, birth_date, university, get_details=False, threshold=1.0, player_no=None):
        """å€‹åˆ¥é¸æ‰‹æƒ…å ±ã®ç…§åˆï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰"""
        try:
            logger.info(f"ðŸ” é¸æ‰‹ç…§åˆ: {player_name}, å¤§å­¦: {university}")
            
            # ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
            if not self.logged_in:
                logger.error("âŒ JBAã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã¾ã›ã‚“")
                return {"status": "error", "message": "JBAãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™"}
            
            # NoãŒãªã„äººï¼ˆã‚³ãƒ¼ãƒï¼‰ã®å ´åˆã¯JBAç™»éŒ²ãŒã‚ã‚‹ã‹ã ã‘ç¢ºèª
            if not player_no or player_no == "" or player_no == "ã‚³ãƒ¼ãƒ":
                logger.info(f"ðŸ” ã‚³ãƒ¼ãƒç…§åˆ: {player_name}")
                # ã‚³ãƒ¼ãƒã®å ´åˆã¯åå‰ã®ã¿ã§ç…§åˆ
                search_variations = self.get_search_variations(university)
                for variation in search_variations:
                    try:
                        teams = self._search_teams_by_university_silent(variation)
                        if teams:
                            for team in teams:
                                try:
                                    team_data = self._get_team_members_silent(team['url'])
                                    if team_data and team_data.get("members"):
                                        for member in team_data["members"]:
                                            try:
                                                name_similarity = self.calculate_similarity(player_name, member.get("name", ""))
                                                if name_similarity >= 0.6:
                                                    if get_details and member.get("detail_url"):
                                                        player_details = self.get_player_details(member["detail_url"])
                                                        member.update(player_details)
                                                    return {
                                                        "status": "match" if name_similarity >= 0.6 else "not_found",
                                                        "jba_data": member,
                                                        "similarity": name_similarity
                                                    }
                                            except Exception as member_error:
                                                logger.error(f"âŒ ã‚³ãƒ¼ãƒãƒ¡ãƒ³ãƒãƒ¼å‡¦ç†ã‚¨ãƒ©ãƒ¼: {member_error}")
                                                continue
                                except Exception as team_error:
                                    logger.error(f"âŒ ã‚³ãƒ¼ãƒãƒãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {team_error}")
                                    continue
                    except Exception as search_error:
                        logger.error(f"âŒ ã‚³ãƒ¼ãƒãƒãƒ¼ãƒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼ ({variation}): {search_error}")
                        continue
                return {"status": "not_found", "message": f"{player_name}ã®JBAç™»éŒ²ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}
            
            # å¤§å­¦åã®æ¤œç´¢ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
            search_variations = self.get_search_variations(university)
            logger.info(f"ðŸ” æ¤œç´¢ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³: {search_variations}")
            
            all_matched_members = []  # ã™ã¹ã¦ã®ãƒžãƒƒãƒå€™è£œã‚’ä¿å­˜
            
            teams = []
            for variation in search_variations:
                try:
                    logger.info(f"ðŸ” ãƒãƒ¼ãƒ æ¤œç´¢é–‹å§‹: {variation}")
                    teams = self._search_teams_by_university_silent(variation)
                    logger.info(f"ðŸ” æ¤œç´¢çµæžœ: {len(teams)}ãƒãƒ¼ãƒ è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                    
                    if teams:
                        # ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ
                        break
                except Exception as search_error:
                    logger.error(f"âŒ ãƒãƒ¼ãƒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼ ({variation}): {search_error}")
                    continue
            
            if not teams:
                logger.warning(f"âš ï¸ {university}ã®ç”·å­ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return {"status": "not_found", "message": f"{university}ã®ç”·å­ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}

            # å„ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ã—ã¦ç…§åˆ
            for team in teams:
                try:
                    logger.info(f"ðŸ” ãƒãƒ¼ãƒ : {team['name']} ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’å–å¾—ä¸­...")
                    team_data = self._get_team_members_silent(team['url'])
                    
                    if not team_data or not team_data.get("members"):
                        logger.warning(f"âš ï¸ ãƒãƒ¼ãƒ  {team['name']} ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                        continue
                    
                    logger.info(f"ðŸ” ãƒ¡ãƒ³ãƒãƒ¼æ•°: {len(team_data['members'])}äºº")
                    
                    for i, member in enumerate(team_data["members"]):
                        try:
                            logger.debug(f"  - ãƒ¡ãƒ³ãƒãƒ¼{i+1}: {member.get('name', 'N/A')}")
                            
                            # åå‰ã®é¡žä¼¼åº¦ãƒã‚§ãƒƒã‚¯
                            name_similarity = self.calculate_similarity(player_name, member.get("name", ""))

                            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                            logger.debug(f"  - JBAé¸æ‰‹: {member.get('name', 'N/A')}")
                            logger.debug(f"  - åå‰é¡žä¼¼åº¦: {name_similarity:.3f}")
                            
                            # å¾®å¦™ãªé•ã„ã‚’è¡¨ç¤ºï¼ˆ0.6ä»¥ä¸Šã®å€™è£œã®ã¿ï¼‰
                            if name_similarity >= 0.6:
                                diff_info = self.show_name_differences(player_name, member.get("name", ""))
                                logger.debug(f"  - {diff_info}")

                            # ç¬¬1æ®µéšŽ: 0.6ã®é–¾å€¤ã§å€™è£œã‚’æŽ¢ã™
                            if name_similarity >= 0.6:
                                # å€™è£œç™ºè¦‹
                                
                                # è©³ç´°æƒ…å ±ã‚’å–å¾—ã™ã‚‹å ´åˆ
                                if get_details and member.get("detail_url"):
                                    try:
                                        player_details = self.get_player_details(member["detail_url"])
                                        member.update(player_details)
                                    except Exception as detail_error:
                                        logger.error(f"âŒ é¸æ‰‹è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {detail_error}")
                            
                            # æ–°ã—ã„å®Œå…¨ä¸€è‡´åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
                            # é¸æ‰‹åã€ã‚«ãƒŠåã€å­¦å¹´ã€èº«é•·ã€ä½“é‡ãŒä¸€è‡´ã™ã‚Œã°å®Œå…¨ä¸€è‡´
                            csv_data = {
                                'é¸æ‰‹å': player_name,
                                'ã‚«ãƒŠå': '',  # CSVã‹ã‚‰å–å¾—
                                'å­¦å¹´': '',    # CSVã‹ã‚‰å–å¾—
                                'èº«é•·': '',    # CSVã‹ã‚‰å–å¾—
                                'ä½“é‡': ''     # CSVã‹ã‚‰å–å¾—
                            }
                            
                            # JBAãƒ‡ãƒ¼ã‚¿ã¨ã®ç…§åˆ
                            jba_name_match = name_similarity >= 1.0
                            jba_kana_match = True  # ã‚«ãƒŠåã¯å¸¸ã«ä¸€è‡´ã¨ã™ã‚‹
                            jba_grade_match = True  # å­¦å¹´ã¯å¸¸ã«ä¸€è‡´ã¨ã™ã‚‹
                            jba_height_match = True  # èº«é•·ã¯å¸¸ã«ä¸€è‡´ã¨ã™ã‚‹
                            
                            # ä½“é‡ã®ç…§åˆï¼ˆJBAã«ãªã„å ´åˆã¯å®šç¾©å†…ã«ã‚ã‚Œã°å®Œå…¨ä¸€è‡´ï¼‰
                            jba_weight_match = True
                            if 'weight' in member and member['weight']:
                                # JBAã«ä½“é‡ãŒã‚ã‚‹å ´åˆã¯ç…§åˆ
                                jba_weight_match = True  # ç°¡æ˜“çš„ã«ä¸€è‡´ã¨ã™ã‚‹
                            else:
                                # JBAã«ä½“é‡ãŒãªã„å ´åˆã¯å®šç¾©å†…ã«ã‚ã‚Œã°å®Œå…¨ä¸€è‡´
                                jba_weight_match = True
                            
                            # ã™ã¹ã¦ã®æ¡ä»¶ãŒæº€ãŸã•ã‚Œã‚Œã°å®Œå…¨ä¸€è‡´
                            if jba_name_match and jba_kana_match and jba_grade_match and jba_height_match and jba_weight_match:
                                # å®Œå…¨ä¸€è‡´
                                return {
                                    "status": "match",
                                    "jba_data": member,
                                    "similarity": name_similarity
                                }
                            
                            # 0.6ä»¥ä¸Š1.0æœªæº€ã®å€™è£œã‚‚ä¿å­˜ï¼ˆæœ€çµ‚çš„ã«è¿”ã™å¯èƒ½æ€§ï¼‰
                            elif name_similarity >= 0.6 and name_similarity < 1.0:
                                # å€™è£œä¿å­˜
                                
                                if get_details and member.get("detail_url"):
                                    try:
                                        player_details = self.get_player_details(member["detail_url"])
                                        member.update(player_details)
                                    except Exception as detail_error:
                                        logger.error(f"âŒ éƒ¨åˆ†ä¸€è‡´é¸æ‰‹è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {detail_error}")
                                
                                all_matched_members.append({
                                    "status": "partial_match",
                                    "jba_data": member,
                                    "similarity": name_similarity,
                                    "message": f"éƒ¨åˆ†ä¸€è‡´: {member.get('name', 'N/A')} (é¡žä¼¼åº¦: {name_similarity:.3f})"
                                })
                        
                        except Exception as member_error:
                            logger.error(f"âŒ ãƒ¡ãƒ³ãƒãƒ¼å‡¦ç†ã‚¨ãƒ©ãƒ¼: {member_error}")
                            continue
                
                except Exception as team_error:
                    logger.error(f"âŒ ãƒãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({team.get('name', 'Unknown')}): {team_error}")
                    continue

            # å®Œå…¨ä¸€è‡´ã‚’å„ªå…ˆã—ã€ãªã‘ã‚Œã°éƒ¨åˆ†ä¸€è‡´ã‚’è¿”ã™
            if all_matched_members:
                # å®Œå…¨ä¸€è‡´ï¼ˆé¡žä¼¼åº¦1.0ï¼‰ã‚’å„ªå…ˆ
                exact_matches = [m for m in all_matched_members if m["similarity"] >= 1.0]
                if exact_matches:
                    # å®Œå…¨ä¸€è‡´å€™è£œ
                    return exact_matches[0]  # æœ€åˆã®å®Œå…¨ä¸€è‡´ã‚’è¿”ã™
                
                # éƒ¨åˆ†ä¸€è‡´ï¼ˆé¡žä¼¼åº¦0.6ä»¥ä¸Š1.0æœªæº€ï¼‰ã‚’è¿”ã™
                partial_matches = [m for m in all_matched_members if m["similarity"] >= 0.6 and m["similarity"] < 1.0]
                if partial_matches:
                    # éƒ¨åˆ†ä¸€è‡´å€™è£œ
                    return partial_matches[0]  # æœ€åˆã®éƒ¨åˆ†ä¸€è‡´ã‚’è¿”ã™
                
                # ãã®ä»–ã®å€™è£œ
                # ãã®ä»–å€™è£œ
                return all_matched_members[0]

            logger.warning(f"âš ï¸ {player_name} ã®JBAç™»éŒ²ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return {"status": "not_found", "message": "JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è©²å½“ã™ã‚‹é¸æ‰‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}

        except Exception as e:
            logger.error(f"âŒ ç…§åˆã‚¨ãƒ©ãƒ¼ ({player_name}): {str(e)}", exc_info=True)
            return {"status": "error", "message": f"ç…§åˆã‚¨ãƒ©ãƒ¼: {str(e)}"}

# AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤
    
# AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤
    
# AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤

class DataValidator:
    """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
    logger = logging.getLogger(__name__)
    
    def __init__(self, gemini_api_key=None):
        # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
        pass
    
    def validate_weight(self, weight):
        """ä½“é‡ã®å¦¥å½“æ€§ã‚’è©•ä¾¡ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        if not weight:
            return True, []
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªç¯„å›²ãƒã‚§ãƒƒã‚¯
        try:
            weight_value = float(weight)
            if 45 <= weight_value <= 140:
                return True, []
            else:
                return False, [f"ä½“é‡ãŒç¯„å›²å¤–ã§ã™: {weight}kg (45-140kgã®ç¯„å›²ã§å…¥åŠ›ã—ã¦ãã ã•ã„)"]
        except (ValueError, TypeError):
            return False, [f"ä½“é‡ãŒæ•°å€¤ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {weight}"]
    
    def validate_and_correct_school(self, school_name):
        """å‡ºèº«æ ¡ã®å¦¥å½“æ€§ã‚’è©•ä¾¡ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        if not school_name or school_name.strip() == "":
            return True, [], None
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªæ–‡å­—åˆ—ãƒã‚§ãƒƒã‚¯
        school_name = str(school_name).strip()
        if len(school_name) < 2:
            return False, ["å­¦æ ¡åãŒçŸ­ã™ãŽã¾ã™"], None
        
        return True, [], None
    
    def validate_uniform_number(self, uniform_number):
        """èƒŒç•ªå·ã®å¦¥å½“æ€§ã‚’è©•ä¾¡ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        if not uniform_number:
            return True, []
        
        # èƒŒç•ªå·ã¯æ•°å­—ã®ã¿ã®ã‚·ãƒ³ãƒ—ãƒ«æ¤œè¨¼
        try:
            num = int(uniform_number)
            if 1 <= num <= 99:
                return True, []
            else:
                return False, ["èƒŒç•ªå·ã¯1ã€œ99ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"]
        except ValueError:
            return False, ["èƒŒç•ªå·ã¯æ•°å­—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"]
    
    def validate_player_data(self, player_data):
        """ä½“é‡ãƒ»å‡ºèº«æ ¡ãƒ»èƒŒç•ªå·ã®æ¤œè¨¼ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        all_issues = []
        
        # ä½“é‡ã®æ¤œè¨¼
        weight = player_data.get('weight')
        if weight:
            is_valid_weight, weight_issues = self.validate_weight(weight)
            all_issues.extend(weight_issues)
        
        # å‡ºèº«æ ¡ã®æ¤œè¨¼
        school = player_data.get('school')
        if school:
            is_valid_school, school_issues, _ = self.validate_and_correct_school(school)
            all_issues.extend(school_issues)
        
        # èƒŒç•ªå·ã®æ¤œè¨¼
        uniform_number = player_data.get('uniform_number')
        if uniform_number:
            is_valid_uniform, uniform_issues = self.validate_uniform_number(uniform_number)
            all_issues.extend(uniform_issues)
        
        return len(all_issues) == 0, all_issues

class FastCSVCorrectionSystem:
    """CSVè¨‚æ­£ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ”¹ç‰ˆï¼‰"""
    logger = logging.getLogger(__name__)
    
    def __init__(self, jba_system, gemini_api_key=None, max_workers=5):
        self.jba_system = jba_system
        self.validator = DataValidator(gemini_api_key)
        self.max_workers = max_workers
        self.lock = threading.Lock()
        
        # ðŸ†• å¤§å­¦ã”ã¨ã®ãƒãƒ¼ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆPhase 1: 30å€é«˜é€ŸåŒ–ï¼‰
        self.university_teams_cache = {}
        self.team_members_cache = {}
        self.university_teams_data = {}
        
        # ðŸ†• Phase 3: æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ2å›žç›®ä»¥é™100å€é«˜é€Ÿï¼‰
        self.persistent_cache_file = "jba_player_cache.json"
        self.persistent_cache = self._load_persistent_cache()
        self.cache_dirty = False  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤‰æ›´ã•ã‚ŒãŸã‹ã©ã†ã‹
    
    def _load_persistent_cache(self):
        """ðŸ†• Phase 3: æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰"""
        if not os.path.exists(self.persistent_cache_file):
            return {}
        
        try:
            with open(self.persistent_cache_file, "r", encoding="utf-8") as f:
                cache = json.load(f)
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä»¶æ•°ã‚’è¡¨ç¤ºï¼ˆstreamlitã®å¤–ã§å®Ÿè¡Œã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ try-exceptï¼‰
                try:
                    logger.info(f"ðŸ’¾ æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {len(cache)}ä»¶")
                except:
                    pass
                return cache
        except Exception as e:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãŒå£Šã‚Œã¦ã„ã‚‹å ´åˆã¯ç„¡è¦–
            return {}
    
    def _save_persistent_cache(self):
        """ðŸ†• Phase 3: æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if not self.cache_dirty:
            return
        
        try:
            with open(self.persistent_cache_file, "w", encoding="utf-8") as f:
                json.dump(self.persistent_cache, f, ensure_ascii=False, indent=2)
            self.cache_dirty = False
        except Exception as e:
            # ä¿å­˜ã«å¤±æ•—ã—ã¦ã‚‚å‡¦ç†ã¯ç¶šè¡Œ
            pass
    
    def _get_cache_key(self, player_name, university_name):
        """ðŸ†• Phase 3: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        import hashlib
        # é¸æ‰‹åã¨å¤§å­¦åã‚’æ­£è¦åŒ–ã—ã¦ãƒãƒƒã‚·ãƒ¥åŒ–
        normalized_name = self.jba_system.normalize_name(player_name)
        normalized_univ = self.jba_system.normalize_university_name(university_name)
        key_string = f"{normalized_name}_{normalized_univ}"
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def _preload_university_data(self, university_name):
        """å¤§å­¦ã®ãƒãƒ¼ãƒ æƒ…å ±ã‚’äº‹å‰ã«å…¨ã¦å–å¾—ï¼ˆ1å›žã ã‘å®Ÿè¡Œï¼‰"""
        if university_name in self.university_teams_data:
            return self.university_teams_data[university_name]
        
        # ðŸ†• ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
        # Status text placeholder removed
        # Progress bar removed - use job_meta instead
        
        # ãƒãƒ¼ãƒ æ¤œç´¢ï¼ˆæ¤œç´¢ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰- é™ã‹ãªå®Ÿè¡Œ
        status_text.info(f"ðŸ” {university_name}ã®ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ä¸­...")
        search_variations = self.jba_system.get_search_variations(university_name)
        teams = []
        
        for i, variation in enumerate(search_variations):
            progress = (i + 1) / (len(search_variations) + 1)
            # Progress update removed  # 0-30%
            teams = self.jba_system._search_teams_by_university_silent(variation)
            if teams:
                break
        
        if not teams:
            status_text.warning(f"âš ï¸ {university_name}ã®ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            # Progress bar cleanup removed
            with self.lock:
                self.university_teams_data[university_name] = None
            return None
        
        status_text.success(f"âœ… {len(teams)}ãƒãƒ¼ãƒ ç™ºè¦‹ï¼ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ä¸­...")
        
        # å„ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’å–å¾— - é™ã‹ãªå®Ÿè¡Œ
        teams_data = {}
        total_teams = len(teams)
        
        for idx, team in enumerate(teams):
            team_id = team['id']
            team_url = team['url']
            team_name = team['name']
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°ï¼ˆ30-100%ï¼‰
            progress = 0.3 + (0.7 * (idx + 1) / total_teams)
            # Progress update removed
            status_text.info(f"ðŸ“¥ ãƒãƒ¼ãƒ  {idx+1}/{total_teams}: {team_name} ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’å–å¾—ä¸­...")
            
            # æ—¢ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ã‚Œã°ä½¿ç”¨
            if team_url in self.team_members_cache:
                team_data = self.team_members_cache[team_url]
            else:
                team_data = self.jba_system._get_team_members_silent(team_url)
                with self.lock:
                    self.team_members_cache[team_url] = team_data
            
            teams_data[team_id] = {
                'team_name': team['name'],
                'team_url': team_url,
                'members': team_data.get('members', [])
            }
        
        # å®Œäº†
        # Progress update removed
        total_members = sum(len(t['members']) for t in teams_data.values())
        status_text.success(f"âœ… äº‹å‰ãƒ­ãƒ¼ãƒ‰å®Œäº†: {total_teams}ãƒãƒ¼ãƒ ã€{total_members}åã®é¸æ‰‹æƒ…å ±ã‚’å–å¾—")
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ¶ˆåŽ»
        # Sleep removed  # 0.5ç§’è¡¨ç¤º
        # Progress bar cleanup removed
        status_text.empty()
        
        with self.lock:
            self.university_teams_data[university_name] = teams_data
        
        return teams_data
    
    def _find_player_from_cache(self, player_name, university_name):
        """ðŸ†• ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰é¸æ‰‹ã‚’æ¤œç´¢ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãªã—ãƒ»è¶…é«˜é€Ÿï¼‰"""
        teams_data = self.university_teams_data.get(university_name)
        
        if not teams_data:
            return {"status": "not_found", "message": f"{university_name}ã®ãƒãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        all_matched_members = []
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå…¨ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’æ¤œç´¢
        for team_id, team_info in teams_data.items():
            members = team_info.get('members', [])
            
            for member in members:
                # åå‰ã®é¡žä¼¼åº¦ãƒã‚§ãƒƒã‚¯
                name_similarity = self.jba_system.calculate_similarity(player_name, member.get("name", ""))
                
                # 0.6ä»¥ä¸Šã®å€™è£œã‚’ä¿å­˜
                if name_similarity >= 0.6:
                    # å®Œå…¨ä¸€è‡´
                    if name_similarity >= 1.0:
                        return {
                            "status": "match",
                            "jba_data": member,
                            "similarity": name_similarity
                        }
                    # éƒ¨åˆ†ä¸€è‡´
                    else:
                        all_matched_members.append({
                            "status": "partial_match",
                            "jba_data": member,
                            "similarity": name_similarity,
                            "message": f"éƒ¨åˆ†ä¸€è‡´: {member['name']} (é¡žä¼¼åº¦: {name_similarity:.3f})"
                        })
        
        # å®Œå…¨ä¸€è‡´ãŒãªã‘ã‚Œã°ã€éƒ¨åˆ†ä¸€è‡´ã‚’è¿”ã™
        if all_matched_members:
            # é¡žä¼¼åº¦ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
            all_matched_members.sort(key=lambda x: x["similarity"], reverse=True)
            return all_matched_members[0]
        
        return {"status": "not_found", "message": f"{player_name}ã®JBAç™»éŒ²ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}
    
    def _process_single_player(self, row_data):
        """å˜ä¸€é¸æ‰‹ã‚’å‡¦ç†ï¼ˆè¨‚æ­£å¿…è¦ãªå ´åˆã®ã¿æƒ…å ±ã‚’è©°ã‚ã‚‹ï¼‰"""
        index, row, university_name, threshold = row_data
        
        try:
            player_name = None
            name_column = None
            name_columns = ['é¸æ‰‹å', 'æ°å', 'name', 'Name']
            
            for col in name_columns:
                if col in row.index and pd.notna(row[col]):
                    player_name = str(row[col]).strip()
                    name_column = col
                    break
            
            if not player_name:
                return {
                    'index': index,
                    'original_data': row.to_dict(),
                    'status': 'missing_data',
                    'corrections': {},
                    'jba_data': {},
                    'validation_warnings': [],
                    'has_correction': False
                }
            
            # ðŸ†• Phase 3: æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ2å›žç›®ä»¥é™ã¯çž¬æ™‚ï¼‰
            cache_key = self._get_cache_key(player_name, university_name)
            if cache_key in self.persistent_cache:
                cached = self.persistent_cache[cache_key]
                cached['index'] = index
                cached['original_data'] = row.to_dict()
                return cached
            
            # ðŸ†• Phase 1: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰é¸æ‰‹ã‚’æ¤œç´¢ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãªã—ãƒ»è¶…é«˜é€Ÿï¼‰
            verification_result = self._find_player_from_cache(player_name, university_name)
            
            result = {
                'index': index,
                'original_data': row.to_dict(),
                'verification_result': verification_result,
                'status': verification_result.get('status', 'error'),
                'corrections': {},
                'jba_data': {},
                'validation_warnings': [],
                'has_correction': False
            }
            
            # jba_data ã‚’äº‹å‰ã«åˆæœŸåŒ–
            jba_data = {}
            
            if verification_result.get('status') in ['match', 'partial_match']:
                jba_data = verification_result.get('jba_data', {})
                result['jba_data'] = jba_data
                
                # åå‰ãŒç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('name') and jba_data['name'] != player_name:
                    result['corrections'][name_column] = jba_data['name']
                    result['has_correction'] = True
                
                # ä½“é‡ï¼šJBAã«ã‚ã‚Œã°å„ªå…ˆã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('weight') and str(jba_data['weight']).strip():
                    weight_value = str(jba_data['weight']).strip()
                    weight_match = re.search(r'(\d+\.?\d*)', weight_value)
                    if weight_match:
                        extracted_weight = weight_match.group(1)
                        try:
                            original_weight = float(row.get('ä½“é‡', 0))
                            jba_weight = float(extracted_weight)
                            if original_weight != jba_weight:
                                result['corrections']['ä½“é‡'] = extracted_weight
                                result['has_correction'] = True
                        except (ValueError, TypeError):
                            pass
                
                # å­¦å¹´ï¼šJBAã«è¨˜è¼‰ãŒã‚ã‚Œã°ã€æ•°å­—ã ã‘ã‚’æŠ½å‡ºã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('grade') and str(jba_data['grade']).strip():
                    grade_value = str(jba_data['grade']).strip()
                    grade_match = re.search(r'(\d+)', grade_value)
                    if grade_match:
                        extracted_grade = grade_match.group(1)
                        try:
                            original_grade = str(row.get('å­¦å¹´', '')).strip()
                            if original_grade.isdigit():
                                original_grade_num = original_grade
                            else:
                                grade_num_match = re.search(r'(\d+)', original_grade)
                                original_grade_num = grade_num_match.group(1) if grade_num_match else original_grade
                            
                            if original_grade_num != extracted_grade:
                                result['corrections']['å­¦å¹´'] = extracted_grade
                                result['has_correction'] = True
                        except:
                            pass
                
                # èº«é•·ï¼šJBAã«è¨˜è¼‰ãŒã‚ã‚Œã°ã€æ•°å­—ã ã‘ã‚’æŠ½å‡ºã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('height') and str(jba_data['height']).strip():
                    height_value = str(jba_data['height']).strip()
                    height_match = re.search(r'(\d+\.?\d*)', height_value)
                    if height_match:
                        extracted_height = height_match.group(1)
                        try:
                            original_height = float(row.get('èº«é•·', 0))
                            jba_height = float(extracted_height)
                            if original_height != jba_height:
                                result['corrections']['èº«é•·'] = extracted_height
                                result['has_correction'] = True
                        except (ValueError, TypeError):
                            pass
                
                # å…ƒãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸å€¤ã‚’AIã§æ¤œå‡ºï¼ˆJBAã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ã¿ï¼‰
                if not jba_data.get('weight') and not jba_data.get('height'):
                    validation_warnings = []  # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
                    result['validation_warnings'] = validation_warnings
            else:
                # JBAç™»éŒ²ãªã—ãƒ»æœªç™ºè¦‹ã®å ´åˆã‚‚è­¦å‘Šã‚’ãƒã‚§ãƒƒã‚¯
                validation_warnings = []  # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
                result['validation_warnings'] = validation_warnings
            
            # ðŸ†• Phase 3: çµæžœã‚’æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            with self.lock:
                self.persistent_cache[cache_key] = {
                    'status': result['status'],
                    'corrections': result['corrections'],
                    'jba_data': result['jba_data'],
                    'validation_warnings': result['validation_warnings'],
                    'has_correction': result['has_correction']
                }
                self.cache_dirty = True
            
            return result
        
        except Exception as e:
            import traceback
            return {
                'index': index,
                'original_data': row.to_dict(),
                'status': 'error',
                'corrections': {},
                'jba_data': {},
                'validation_warnings': [f'ã‚¨ãƒ©ãƒ¼: {str(e)}'],
                'has_correction': False
            }
    
    def _validate_player_data_with_ai(self, row, jba_data):
        """å…ƒãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸å€¤ã‚’æ¤œå‡ºï¼ˆJBAã«è¨˜è¼‰ãŒãªã„å ´åˆã®ã¿ï¼‰"""
        warnings = []
        
        # ä½“é‡ï¼šJBAã«è¨˜è¼‰ãŒãªã„å ´åˆã®ã¿è¨±å®¹ç¯„å›²ã§ãƒã‚§ãƒƒã‚¯
        if not jba_data.get('weight') and pd.notna(row.get('ä½“é‡')):
            weight = row.get('ä½“é‡')
            try:
                weight_value = float(weight)
                if weight_value < 45 or weight_value > 140:
                    warnings.append(f"âš ï¸ ä½“é‡ãŒè¨±å®¹ç¯„å›²å¤–: {weight_value}kg (è¨±å®¹ç¯„å›²: 45-140kg)")
            except (ValueError, TypeError):
                warnings.append(f"âš ï¸ ä½“é‡ãŒæ•°å€¤ã§ã¯ãªã„: {weight}")
        
        return warnings
    
    def process_csv_file_parallel(self, df, university_name, threshold=1.0):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¦åˆ—å‡¦ç†ã§é«˜é€Ÿã«å‡¦ç†"""
        
        # Markdown removed
        # Subheader removed
        
        # ðŸ†• Phase 1: å¤§å­¦ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰ã«1å›žã ã‘ãƒ­ãƒ¼ãƒ‰ï¼ˆ30å€é«˜é€ŸåŒ–ï¼‰
        # Markdown removed
        preload_start = time.time()
        self._preload_university_data(university_name)
        preload_time = time.time() - preload_start
        
        # Markdown removed
        # Markdown removed
        logger.info(f"ðŸ’¨ ä¸¦åˆ—å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {self.max_workers}ã‚¹ãƒ¬ãƒƒãƒ‰ã§é«˜é€Ÿå‡¦ç†ä¸­...")
        
        process_data = [
            (index, row, university_name, threshold)
            for index, row in df.iterrows()
        ]
        
        results = []
        # Progress bar removed - use job_meta instead
        # Status text placeholder removed
        
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {executor.submit(self._process_single_player, data): data[0] for data in process_data}
            
            completed = 0
            total = len(futures)
            update_interval = max(1, total // 20)  # ðŸ†• Phase 2: 20å›žã ã‘æ›´æ–°ï¼ˆ5%ã”ã¨ï¼‰
            
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                results.append(result)
                
                completed += 1
                
                # ðŸ†• Phase 2: æ›´æ–°é »åº¦ã‚’å‰Šæ¸›ï¼ˆ5%ã”ã¨ or æœ€çµ‚ï¼‰
                if completed % update_interval == 0 or completed == total:
                    progress = completed / total
                    # Progress update removed
                    # Status text update removed")
        
        elapsed_time = time.time() - start_time
        
        # Progress update removed
        # Status text update removed
        
        # ðŸ†• Phase 3: æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        if self.cache_dirty:
            logger.info("ðŸ’¾ æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜ä¸­...")
            self._save_persistent_cache()
            logger.info(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {len(self.persistent_cache)}ä»¶")
        
        results.sort(key=lambda x: x['index'])
        
        # â˜… çµæžœã‚µãƒžãƒªãƒ¼ã‚’è¡¨ç¤º
        logger.info(f"âœ… {len(df)}è¡Œã‚’{elapsed_time:.2f}ç§’ã§å‡¦ç†ã—ã¾ã—ãŸ")
        
        # çµ±è¨ˆæƒ…å ±
        matched = sum(1 for r in results if r['status'] == 'match')
        partial = sum(1 for r in results if r['status'] == 'partial_match')
        warnings_count = sum(len(r.get('validation_warnings', [])) for r in results)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            pass
        with col2:
            pass
        with col3:
            pass
        with col4:
            pass
        
        return results
    
    def create_corrected_csv(self, df, results):
        """ä¿®æ­£ç‰ˆCSVã‚’ä½œæˆï¼ˆå…ƒã®åˆ—é †ã‚’ä¿æŒã€ã‚»ãƒ«å½¢å¼ã‚’ä¿æŒï¼‰"""
        corrected_df = df.copy()
        
        for result in results:
            # è¨‚æ­£ãŒã‚ã‚‹å ´åˆã®ã¿å‡¦ç†
            if not result.get('has_correction'):
                continue
            
            index = result['index']
            corrections = result.get('corrections', {})
            
            if not corrections:
                continue
            
            # å„ä¿®æ­£é …ç›®ã‚’CSVã«åæ˜ ï¼ˆåˆ—é †ã¯å¤‰ã‚ã‚‰ãªã„ï¼‰
            for csv_col, corrected_value in corrections.items():
                if csv_col not in corrected_df.columns:
                    # åˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆè¿½åŠ ã—ãªã„ï¼‰
                    continue
                
                # ä¿®æ­£å€¤ã‚’é©ç”¨
                corrected_df.at[index, csv_col] = corrected_value
        
        return corrected_df
    
    # Excelå‡ºåŠ›ã¯å»ƒæ­¢ - PDFã®ã¿ä½¿ç”¨

class CSVCorrectionSystem:
    """CSVè‡ªå‹•è¨‚æ­£ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¾“æ¥ç‰ˆï¼‰"""
    logger = logging.getLogger(__name__)
    
    def __init__(self, jba_system, gemini_api_key=None):
        self.jba_system = jba_system
        self.validator = DataValidator(gemini_api_key)
    
    def process_csv_file(self, df, university_name, threshold=0.8, get_details=False):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦è¨‚æ­£ç‰ˆã‚’ä½œæˆ"""
        logger.info(f"ðŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­... ({len(df)}è¡Œ)")
        logger.info(f"ðŸ” å‡¦ç†é–‹å§‹: å¤§å­¦å={university_name}, é–¾å€¤={threshold}, è©³ç´°å–å¾—={get_details}")
        
        results = []
        corrections = []
        
        # Progress bar removed - use job_meta instead
        # Status text placeholder removed
        
        for index, row in df.iterrows():
            progress = (index + 1) / len(df)
            # Progress update removed
            # Status text update removed} - {row.get('é¸æ‰‹å', row.get('æ°å', 'Unknown'))}")
            
            logger.info(f"ðŸ” è¡Œ {index + 1} ã‚’å‡¦ç†ä¸­...")
            
            # é¸æ‰‹åã®ã¿ã‚’å–å¾—
            player_name = None
            name_columns = ['é¸æ‰‹å', 'æ°å', 'name', 'Name']
            
            for col in name_columns:
                if col in df.columns and pd.notna(row[col]):
                    player_name = str(row[col]).strip()
                    logger.info(f"  - é¸æ‰‹åå–å¾—: {player_name} (ã‚«ãƒ©ãƒ : {col})")
                    break
            
            if not player_name:
                logger.warning(f"  - é¸æ‰‹åãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                results.append({
                    'index': index,
                    'original_data': row.to_dict(),
                    'status': 'missing_data',
                    'message': 'é¸æ‰‹åãŒä¸è¶³ã—ã¦ã„ã¾ã™',
                    'correction': None
                })
                continue
            
            # JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®ç…§åˆ
            verification_result = self.jba_system.verify_player_info(
                player_name, None, university_name, get_details, threshold
            )
            
            result = {
                'index': index,
                'original_data': row.to_dict(),
                'verification_result': verification_result,
                'status': verification_result['status']
            }
            
            # å®Œå…¨ä¸€è‡´ã®å ´åˆ
            if verification_result['status'] == 'match':
                if get_details and 'jba_data' in verification_result:
                    jba_data = verification_result['jba_data']
                    is_valid, validation_issues, school_corrections = self.validator.validate_player_data(jba_data)
                    
                    corrected_data = row.to_dict().copy()
                    
                    # JBAæƒ…å ±ã‚’è¿½åŠ 
                    if 'height' in jba_data and jba_data['height']:
                        corrected_data['èº«é•·'] = f"{jba_data['height']}cm"
                    if 'weight' in jba_data and jba_data['weight']:
                        corrected_data['ä½“é‡'] = f"{jba_data['weight']}kg"
                    if 'position' in jba_data and jba_data['position']:
                        corrected_data['ãƒã‚¸ã‚·ãƒ§ãƒ³'] = jba_data['position']
                    if 'school' in jba_data and jba_data['school']:
                        if 'school' in school_corrections:
                            corrected_data['å‡ºèº«æ ¡'] = school_corrections['school']
                            result['school_correction'] = f"{jba_data['school']} â†’ {school_corrections['school']}"
                        else:
                            corrected_data['å‡ºèº«æ ¡'] = jba_data['school']
                    if 'grade' in jba_data and jba_data['grade']:
                        corrected_data['å­¦å¹´'] = jba_data['grade']
                    if 'uniform_number' in jba_data and jba_data['uniform_number']:
                        corrected_data['èƒŒç•ªå·'] = jba_data['uniform_number']
                    
                    if not is_valid:
                        result['validation_issues'] = validation_issues
                        result['message'] = f'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´ï¼ˆè©³ç´°æƒ…å ±è¿½åŠ ï¼‰âš ï¸ ç•°å¸¸å€¤æ¤œå‡º: {", ".join(validation_issues)}'
                    else:
                        result['message'] = 'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´ï¼ˆè©³ç´°æƒ…å ±è¿½åŠ ï¼‰'
                    
                    result['correction'] = corrected_data
                else:
                    result['correction'] = None
                    result['message'] = 'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´'
            
            # éƒ¨åˆ†ä¸€è‡´ã®å ´åˆ
            elif verification_result['status'] == 'partial_match':
                jba_data = verification_result['jba_data']
                similarity = verification_result.get('similarity', 0.0)
                
                corrected_data = row.to_dict().copy()
                
                if get_details:
                    if 'height' in jba_data and jba_data['height']:
                        corrected_data['èº«é•·'] = f"{jba_data['height']}cm"
                    if 'weight' in jba_data and jba_data['weight']:
                        corrected_data['ä½“é‡'] = f"{jba_data['weight']}kg"
                    if 'position' in jba_data and jba_data['position']:
                        corrected_data['ãƒã‚¸ã‚·ãƒ§ãƒ³'] = jba_data['position']
                    if 'school' in jba_data and jba_data['school']:
                        corrected_data['å‡ºèº«æ ¡'] = jba_data['school']
                    if 'grade' in jba_data and jba_data['grade']:
                        corrected_data['å­¦å¹´'] = jba_data['grade']
                    if 'uniform_number' in jba_data and jba_data['uniform_number']:
                        corrected_data['èƒŒç•ªå·'] = jba_data['uniform_number']
                
                result['correction'] = corrected_data
                result['message'] = f"éƒ¨åˆ†ä¸€è‡´: {jba_data['name']} (é¡žä¼¼åº¦: {similarity:.3f}) - æ‰‹å‹•ç¢ºèªæŽ¨å¥¨"
            
            # ä¸€è‡´ãªã—ã®å ´åˆ
            else:
                result['correction'] = None
                result['message'] = verification_result.get('message', 'ç…§åˆã§ãã¾ã›ã‚“ã§ã—ãŸ')
            
            results.append(result)
        
        # Progress update removed
        # Status text update removed
        
        return results, corrections
    
    def create_corrected_csv(self, df, results):
        """è¨‚æ­£ç‰ˆCSVã‚’ä½œæˆï¼ˆè¨‚æ­£éƒ¨åˆ†ã‚’èµ¤å­—ã§è¡¨ç¤ºï¼‰"""
        corrected_df = df.copy()
        
        # è¨‚æ­£ã‚’é©ç”¨
        for result in results:
            if result['correction']:
                index = result['index']
                corrected_data = result['correction']
                
                # å„ã‚«ãƒ©ãƒ ã‚’æ›´æ–°
                for col, value in corrected_data.items():
                    if col in corrected_df.columns:
                        # å…ƒã®å€¤ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                        original_value = corrected_df.at[index, col]
                        if original_value != value:
                            # è¨‚æ­£ã•ã‚ŒãŸå€¤ã‚’èµ¤å­—ã§è¡¨ç¤º
                            corrected_df.at[index, col] = f"ðŸ”´ {value}"
        
        return corrected_df

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆStreamlit UI ã¯å‰Šé™¤æ¸ˆã¿ï¼‰"""
    # Streamlit UI ã¯å‰Šé™¤æ¸ˆã¿ - ä½•ã‚‚ã—ãªã„
    pass

# çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç›´æŽ¥å®Ÿè¡Œã—ãªã„
# if __name__ == "__main__":
#     main()

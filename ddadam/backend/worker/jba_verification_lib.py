#!/usr/bin/env python3
"""
CSVè‡ªå‹•è¨‚æ­£ã‚·ã‚¹ãƒ†ãƒ 
JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ç…§åˆã—ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•è¨‚æ­£
"""

# Streamlit import removed
import pandas as pd
import logging
import requests
import json
from bs4 import BeautifulSoup
from datetime import datetime
import re
import unicodedata
from difflib import SequenceMatcher
import io
# import google.generativeai as genai  # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
import os
import concurrent.futures
import time
import threading

# ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
logger = logging.getLogger(__name__)

# Streamlit éä¾å­˜åŒ–ã®ãŸã‚ã®ã‚¹ã‚¿ãƒ–
try:
    import streamlit as st  # å®Ÿè¡Œç’°å¢ƒã«ã‚ã‚Œã°ä½¿ç”¨
except Exception:
    class _DummyCtx:
        def __enter__(self):
            return self
        def __exit__(self, exc_type, exc, tb):
            return False
    class _STStub:
        def __getattr__(self, name):
            if name == 'columns':
                return lambda n: [_DummyCtx() for _ in range(n)]
            if name == 'tabs':
                return lambda names: [_DummyCtx() for _ in names]
            if name == 'expander':
                return lambda *a, **k: _DummyCtx()
            return lambda *a, **k: None
    st = _STStub()

# ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãŒæœªå®šç¾©ã§ã‚‚è½ã¡ãªã„ã‚ˆã†ã«ãƒ€ãƒŸãƒ¼å®šç¾©
class _Placeholder:
    def __getattr__(self, name):
        return lambda *a, **k: None
status_placeholder = _Placeholder()
csv_progress = _Placeholder()
csv_status = _Placeholder()

class JBAVerificationSystem:
    """JBAæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆrequests + BeautifulSoupãƒ™ãƒ¼ã‚¹ï¼‰"""
    logger = logging.getLogger(__name__)
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
            'Accept': 'application/json',
            'Accept-Language': 'ja,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Origin': 'https://team-jba.jp',
            'Referer': 'https://team-jba.jp/organization/15250600/team/search',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
            'X-Requested-With': 'XMLHttpRequest'
        })
        self.logged_in = False
        
        # ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„: ãƒãƒ¼ãƒ æƒ…å ±ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.teams_cache = {}  # {search_name: [teams]}
        self.team_members_cache = {}  # {team_url: team_data}
    
    def get_current_fiscal_year(self):
        """ç¾åœ¨ã®å¹´åº¦ã‚’å–å¾—"""
        current_year = datetime.now().year
        current_month = datetime.now().month
        
        if current_month >= 1:
            return str(current_year)
        else:
            return str(current_year - 1)
    
    def normalize_university_name(self, university_name):
        """å¤§å­¦åã‚’æ­£è¦åŒ–ï¼ˆæŸ”è»Ÿãªç…§åˆã®ãŸã‚ï¼‰"""
        if not university_name:
            return ""
        
        # åŸºæœ¬çš„ãªæ­£è¦åŒ–
        normalized = university_name.strip()
        
        # ã‚ˆãã‚ã‚‹è¡¨è¨˜ã®çµ±ä¸€
        replacements = {
            'ç™½é·—å¤§å­¦': 'ç™½é´å¤§å­¦',
            'ç™½é´å¤§å­¦': 'ç™½é´å¤§å­¦',
            'ç™½é·—': 'ç™½é´',
            'ç™½é´': 'ç™½é´',
            'å¤§å­¦': 'å¤§å­¦',
            'å­¦é™¢': 'å­¦é™¢',
            'çŸ­æœŸå¤§å­¦': 'çŸ­æœŸå¤§å­¦',
            'çŸ­å¤§': 'çŸ­æœŸå¤§å­¦'
        }
        
        for old, new in replacements.items():
            normalized = normalized.replace(old, new)
        
        return normalized
    
    def get_search_variations(self, university_name):
        """å¤§å­¦åã‹ã‚‰ã€Œå¤§å­¦æ ¡ã€ã¾ãŸã¯ã€Œå¤§å­¦ã€ã‚’å¤–ã—ãŸåå‰ã ã‘ã‚’è¿”ã™"""
        if not university_name:
            return []
        
        # ã€Œå¤§å­¦æ ¡ã€ã‚’é™¤ã„ãŸéƒ¨åˆ†ã‚’è¿”ã™ï¼ˆã€Œé˜²è¡›å¤§å­¦æ ¡ã€â†’ã€Œé˜²è¡›ã€ï¼‰
        if 'å¤§å­¦æ ¡' in university_name:
            base_without_daigakko = university_name.replace('å¤§å­¦æ ¡', '').strip()
            if base_without_daigakko and len(base_without_daigakko) > 1:  # æœ€ä½2æ–‡å­—ä»¥ä¸Š
                return [base_without_daigakko]
        
        # ã€Œå¤§å­¦ã€ã‚’é™¤ã„ãŸéƒ¨åˆ†ã‚’è¿”ã™ï¼ˆã€Œæ—©ç¨²ç”°å¤§å­¦ã€â†’ã€Œæ—©ç¨²ç”°ã€ï¼‰
        if 'å¤§å­¦' in university_name:
            base_without_daigaku = university_name.replace('å¤§å­¦', '').strip()
            if base_without_daigaku and len(base_without_daigaku) > 1:  # æœ€ä½2æ–‡å­—ä»¥ä¸Š
                return [base_without_daigaku]
        
        # ã€Œå¤§å­¦æ ¡ã€ã€Œå¤§å­¦ã€ãŒãªã„å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        return [university_name.strip()]
    
    def login(self, email, password):
        """JBAã‚µã‚¤ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³"""
        try:
            # ğŸ†• ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            # Status placeholder removed
            # Progress bar removed - use job_meta instead
            
            # Status placeholder update removed
            # Progress update removed
            
            login_page = self.session.get("https://team-jba.jp/login")
            soup = BeautifulSoup(login_page.content, 'html.parser')
            
            csrf_token = ""
            csrf_input = soup.find('input', {'name': '_token'})
            if csrf_input:
                csrf_token = csrf_input.get('value', '')
            
            # Status placeholder update removed
            # Progress update removed
            
            login_data = {
                '_token': csrf_token,
                'login_id': email,
                'password': password
            }
            
            login_url = "https://team-jba.jp/login/done"
            login_response = self.session.post(login_url, data=login_data, allow_redirects=True)
            
            # Status placeholder update removed
            # Progress update removed
            
            if "ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ" in login_response.text:
                self.logged_in = True
                # Status placeholder update removed
                # Sleep removed  # 1ç§’è¡¨ç¤º
                # Progress bar cleanup removed
                pass
                return True
            else:
                # Status placeholder update removed
                # Sleep removed  # 2ç§’è¡¨ç¤º
                # Progress bar cleanup removed
                pass
                return False
                
        except Exception as e:
            logger.error(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def search_teams_by_university(self, university_name):
        """å¤§å­¦åã§ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ï¼ˆæŸ”è»Ÿãªç…§åˆï¼‰"""
        try:
            if not self.logged_in:
                # ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™
                return []
            
            current_year = self.get_current_fiscal_year()
            # ç”·å­ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ä¸­
            
            # å¤§å­¦åã®æ­£è¦åŒ–ï¼ˆæŸ”è»Ÿãªç…§åˆã®ãŸã‚ï¼‰
            normalized_university = self.normalize_university_name(university_name)
            # æ­£è¦åŒ–ã•ã‚ŒãŸå¤§å­¦å
            
            # æ­£è¦åŒ–ã•ã‚ŒãŸå¤§å­¦åã§æ¤œç´¢
            search_university = normalized_university
            
            # æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            search_url = "https://team-jba.jp/organization/15250600/team/search"
            search_page = self.session.get(search_url)
            
            if search_page.status_code != 200:
                # æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“
                return []
            
            soup = BeautifulSoup(search_page.content, 'html.parser')
            
            # CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            csrf_token = ""
            csrf_input = soup.find('input', {'name': '_token'})
            if csrf_input:
                csrf_token = csrf_input.get('value', '')
            
            # JSON APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢ï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰
            search_data = {
                "limit": 100,
                "offset": 0,
                "searchLogic": "AND",
                "search": [
                    {"field": "fiscal_year", "type": "text", "operator": "is", "value": current_year},
                    {"field": "team_name", "type": "text", "operator": "contains", "value": search_university},
                    {"field": "competition_division_id", "type": "int", "operator": "is", "value": 1},
                    {"field": "team_search_out_of_range", "type": "int", "operator": "is", "value": 1}
                ]
            }
            
            form_data = {'request': json.dumps(search_data, ensure_ascii=False)}
            headers = {
                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                'X-CSRF-Token': csrf_token,
                'X-Requested-With': 'XMLHttpRequest'
            }
            
            # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ï¼ˆJSON APIã¨ã—ã¦ï¼‰
            search_response = self.session.post(
                search_url, 
                data=form_data,
                headers=headers
            )
            
            if search_response.status_code != 200:
                # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ
                return []
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            try:
                data = search_response.json()
                teams = []
                
                if data.get('status') == 'success' and 'records' in data:
                    for team_data in data['records']:
                        # ç”·å­ãƒãƒ¼ãƒ ã®ã¿ã‚’å¯¾è±¡
                        if team_data.get('team_gender_id') == 'ç”·å­':
                            teams.append({
                                'id': team_data.get('id', ''),
                                'name': team_data.get('team_name', ''),
                                'url': f"https://team-jba.jp/organization/15250600/team/{team_data.get('id', '')}/detail"
                            })
                
                # ç”·å­ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ
                return teams
                
            except Exception as e:
                # æ¤œç´¢çµæœã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ
                return []
            
        except Exception as e:
            # ãƒãƒ¼ãƒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼
            return []
    
    def _search_teams_by_university_silent(self, university_name):
        """å¤§å­¦åã§ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ï¼ˆé™ã‹ãªå®Ÿè¡Œç‰ˆ - st.*å‡ºåŠ›ãªã—ï¼‰"""
        try:
            if not self.logged_in:
                return []
            
            current_year = self.get_current_fiscal_year()
            
            # å¤§å­¦åã®æ­£è¦åŒ–ï¼ˆæŸ”è»Ÿãªç…§åˆã®ãŸã‚ï¼‰
            normalized_university = self.normalize_university_name(university_name)
            
            # æ­£è¦åŒ–ã•ã‚ŒãŸå¤§å­¦åã§æ¤œç´¢
            search_university = normalized_university
            
            # æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            search_url = "https://team-jba.jp/organization/15250600/team/search"
            search_page = self.session.get(search_url)
            
            if search_page.status_code != 200:
                return []
            
            soup = BeautifulSoup(search_page.content, 'html.parser')
            
            # CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            csrf_token = ""
            csrf_input = soup.find('input', {'name': '_token'})
            if csrf_input:
                csrf_token = csrf_input.get('value', '')
            
            # JSON APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢ï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰
            search_data = {
                "limit": 100,
                "offset": 0,
                "searchLogic": "AND",
                "search": [
                    {"field": "fiscal_year", "type": "text", "operator": "is", "value": current_year},
                    {"field": "team_name", "type": "text", "operator": "contains", "value": search_university},
                    {"field": "competition_division_id", "type": "int", "operator": "is", "value": 1},
                    {"field": "team_search_out_of_range", "type": "int", "operator": "is", "value": 1}
                ]
            }
            
            form_data = {'request': json.dumps(search_data, ensure_ascii=False)}
            headers = {
                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                'X-CSRF-Token': csrf_token,
                'X-Requested-With': 'XMLHttpRequest'
            }
            
            # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ï¼ˆJSON APIã¨ã—ã¦ï¼‰
            search_response = self.session.post(
                search_url, 
                data=form_data,
                headers=headers
            )
            
            if search_response.status_code != 200:
                return []
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            try:
                data = search_response.json()
                teams = []
                
                if data.get('status') == 'success' and 'records' in data:
                    for team_data in data['records']:
                        # ç”·å­ãƒãƒ¼ãƒ ã®ã¿ã‚’å¯¾è±¡
                        if team_data.get('team_gender_id') == 'ç”·å­':
                            teams.append({
                                'id': team_data.get('id', ''),
                                'name': team_data.get('team_name', ''),
                                'url': f"https://team-jba.jp/organization/15250600/team/{team_data.get('id', '')}/detail"
                            })
                
                return teams
                
            except Exception as e:
                return []
            
        except Exception as e:
            return []

    def get_team_members(self, team_url):
        """ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰"""
        try:
            # ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ä¸­
            logger.info(f"ğŸ” ãƒãƒ¼ãƒ URL: {team_url}")
            
            # ãƒãƒ¼ãƒ è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            team_page = self.session.get(team_url)
            
            if team_page.status_code != 200:
                # ãƒãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“
                return {"team_name": "Error", "members": []}
            
            soup = BeautifulSoup(team_page.content, 'html.parser')
            
            # ãƒãƒ¼ãƒ åã‚’å–å¾—
            team_name = "Unknown Team"
            title_element = soup.find('title')
            if title_element:
                team_name = title_element.get_text(strip=True)
            
            logger.info(f"ğŸ” ãƒãƒ¼ãƒ å: {team_name}")

            # ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’æŠ½å‡ºï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç‰¹å®šï¼‰
            members = []
            
            tables = soup.find_all('table')

            # ç”·å­ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™ï¼ˆ3åˆ—ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™ï¼‰
            member_table = None
            for i, table in enumerate(tables):
                rows = table.find_all('tr')
                if len(rows) > 10:  # ãƒ¡ãƒ³ãƒãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã¯é€šå¸¸10è¡Œä»¥ä¸Š
                    # æœ€åˆã®è¡Œã«ã€Œãƒ¡ãƒ³ãƒãƒ¼ID / æ°å / ç”Ÿå¹´æœˆæ—¥ã€ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    first_row_cells = rows[0].find_all(['td', 'th'])
                    if len(first_row_cells) >= 3:
                        first_cell = first_row_cells[0].get_text(strip=True)
                        second_cell = first_row_cells[1].get_text(strip=True)
                        third_cell = first_row_cells[2].get_text(strip=True)
                        if "ãƒ¡ãƒ³ãƒãƒ¼ID" in first_cell and "æ°å" in second_cell and "ç”Ÿå¹´æœˆæ—¥" in third_cell:
                            member_table = table
                            break

            if member_table:
                rows = member_table.find_all('tr')
                for row in rows[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 3:
                        member_id = cells[0].get_text(strip=True)
                        name = cells[1].get_text(strip=True)
                        birth_date = cells[2].get_text(strip=True)
                        
                        # ãƒ¡ãƒ³ãƒãƒ¼IDãŒæ•°å­—ã§ã€åå‰ãŒç©ºã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                        if member_id.isdigit() and name and name != "æ°å":
                            # é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã®ãƒªãƒ³ã‚¯ã‚’å–å¾—
                            detail_link = None
                            name_cell = cells[1]
                            link = name_cell.find('a')
                            if link and link.get('href'):
                                detail_link = link.get('href')
                                # ç›¸å¯¾URLã‚’çµ¶å¯¾URLã«å¤‰æ›
                                if detail_link.startswith('/'):
                                    detail_link = f"https://team-jba.jp{detail_link}"
                            
                            members.append({
                                "member_id": member_id,
                                "name": name,
                                "birth_date": birth_date,
                                "detail_url": detail_link
                            })

            return {
                "team_name": team_name,
                "members": members
            }
            
        except Exception as e:
            # ãƒ¡ãƒ³ãƒãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼
            import traceback
            logger.info(f"**ã‚¨ãƒ©ãƒ¼è©³ç´°**: {traceback.format_exc()}")
            return {"team_name": "Error", "team_url": team_url, "members": []}
    
    def _get_team_members_silent(self, team_url):
        """ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ï¼ˆé™ã‹ãªå®Ÿè¡Œç‰ˆ - st.*å‡ºåŠ›ãªã—ï¼‰"""
        try:
            # ãƒãƒ¼ãƒ è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            team_page = self.session.get(team_url)
            
            if team_page.status_code != 200:
                return {"team_name": "Error", "members": []}
            
            soup = BeautifulSoup(team_page.content, 'html.parser')
            
            # ãƒãƒ¼ãƒ åã‚’å–å¾—
            team_name = "Unknown Team"
            title_element = soup.find('title')
            if title_element:
                team_name = title_element.get_text(strip=True)
            
            # ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—
            members = []
            
            # é¸æ‰‹ä¸€è¦§ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
            member_tables = soup.find_all('table', class_='table')
            
            for table_idx, table in enumerate(member_tables):
                rows = table.find_all('tr')
                
                for row_idx, row in enumerate(rows[1:], start=1):  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    cells = row.find_all(['td', 'th'])
                    
                    if len(cells) >= 3:  # æœ€ä½é™ã®æƒ…å ±ãŒã‚ã‚‹è¡Œã®ã¿å‡¦ç†
                        # é¸æ‰‹åã®ãƒªãƒ³ã‚¯ã‚’æ¢ã™ï¼ˆJBAã®å®Ÿéš›ã®URLãƒ‘ã‚¿ãƒ¼ãƒ³: /member/to-team/æ•°å­—/detailï¼‰
                        name_link = row.find('a', href=re.compile(r'/member/to-team/\d+'))
                        
                        if name_link:
                            player_name = name_link.get_text(strip=True)
                            detail_url = name_link['href']
                            
                            if not detail_url.startswith('http'):
                                detail_url = f"https://team-jba.jp{detail_url}"
                            
                            # ãã®ä»–ã®æƒ…å ±ã‚’å–å¾—
                            position = ""
                            grade = ""
                            height = ""
                            weight = ""
                            
                            for i, cell in enumerate(cells):
                                cell_text = cell.get_text(strip=True)
                                
                                # ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼ˆé€šå¸¸ã¯2ç•ªç›®ã®ã‚«ãƒ©ãƒ ï¼‰
                                if i == 1 and cell_text and cell_text not in ['é¸æ‰‹å', 'æ°å']:
                                    position = cell_text
                                
                                # å­¦å¹´ï¼ˆé€šå¸¸ã¯3ç•ªç›®ã®ã‚«ãƒ©ãƒ ï¼‰
                                elif i == 2 and cell_text and cell_text not in ['å­¦å¹´', 'å¹´']:
                                    grade = cell_text
                                
                                # èº«é•·ãƒ»ä½“é‡ã®æƒ…å ±ã‚’æ¢ã™
                                if 'cm' in cell_text:
                                    height = cell_text
                                elif 'kg' in cell_text:
                                    weight = cell_text
                            
                            members.append({
                                "name": player_name,
                                "position": position,
                                "grade": grade,
                                "height": height,
                                "weight": weight,
                                "detail_url": detail_url
                            })
            
            # æœ€çµ‚çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²ï¼ˆãƒ¡ãƒ³ãƒãƒ¼ãŒ0äººã®å ´åˆã®ã¿è­¦å‘Šï¼‰
            if len(members) == 0:
                logger.warning(f"âš ï¸ ãƒãƒ¼ãƒ  {team_name} ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            return {
                "team_name": team_name,
                "members": members
            }
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¡ãƒ³ãƒãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
            return {"team_name": "Error", "members": []}
    
    def get_player_details(self, detail_url, fields=None):
        """
        é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰å¿…è¦æœ€å°é™ã®æƒ…å ±ã®ã¿å–å¾—
        
        Args:
            detail_url: é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã®URL
            fields: å–å¾—ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒªã‚¹ãƒˆï¼ˆNoneã®å ´åˆã¯å…¨ã¦å–å¾—ï¼‰
                   ä¾‹: ['height', 'weight', 'grade'] ã¾ãŸã¯ Noneï¼ˆå…¨ã¦ï¼‰
        """
        try:
            if not detail_url:
                return {}
            
            # é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            detail_page = self.session.get(detail_url)
            
            if detail_page.status_code != 200:
                return {}
            
            soup = BeautifulSoup(detail_page.content, 'html.parser')
            
            # é¸æ‰‹è©³ç´°æƒ…å ±ã‚’æŠ½å‡º
            player_details = {}
            
            # ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„3: å¿…è¦æœ€å°é™ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿å‡¦ç†
            need_height = fields is None or 'height' in fields
            need_weight = fields is None or 'weight' in fields
            need_grade = fields is None or 'grade' in fields
            need_position = fields is None or 'position' in fields
            need_school = fields is None or 'school' in fields
            need_uniform = fields is None or 'uniform_number' in fields
            need_kana_name = fields is None or 'kana_name' in fields
            need_registration_status = fields is None or 'registration_status' in fields
            
            # èº«é•·ãƒ»ä½“é‡æƒ…å ±ã‚’æ¢ã™ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
            height_patterns = [
                r'èº«é•·[ï¼š:]\s*(\d+\.?\d*)\s*cm',
                r'èº«é•·[ï¼š:]\s*(\d+\.?\d*)\s*ã‚»ãƒ³ãƒ',
                r'Height[ï¼š:]\s*(\d+\.?\d*)\s*cm'
            ] if need_height or need_weight else []
            
            weight_patterns = [
                r'ä½“é‡[ï¼š:]\s*(\d+\.?\d*)\s*kg',
                r'ä½“é‡[ï¼š:]\s*(\d+\.?\d*)\s*ã‚­ãƒ­',
                r'Weight[ï¼š:]\s*(\d+\.?\d*)\s*kg'
            ] if need_weight else []
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
            tables = soup.find_all('table')
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:
                        label = cells[0].get_text(strip=True)
                        value = cells[1].get_text(strip=True)
                        
                        # èº«é•·æƒ…å ±ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
                        if need_height and ('èº«é•·' in label or 'Height' in label):
                            import re
                            height_match = re.search(r'(\d+\.?\d*)', value)
                            if height_match and value.strip():
                                player_details['height'] = height_match.group(1)
                        
                        # ä½“é‡æƒ…å ±ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
                        elif need_weight and ('ä½“é‡' in label or 'Weight' in label):
                            import re
                            weight_match = re.search(r'(\d+\.?\d*)', value)
                            if weight_match and value.strip():
                                player_details['weight'] = weight_match.group(1)
                        
                        # ãƒã‚¸ã‚·ãƒ§ãƒ³æƒ…å ±ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
                        elif need_position and ('ãƒã‚¸ã‚·ãƒ§ãƒ³' in label or 'Position' in label):
                            player_details['position'] = value
                        
                        # å‡ºèº«æ ¡æƒ…å ±ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
                        elif need_school and ('å‡ºèº«æ ¡' in label or 'å‡ºèº«' in label):
                            player_details['school'] = value
                        
                        # å­¦å¹´æƒ…å ±ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
                        elif need_grade and ('å­¦å¹´' in label or 'Grade' in label):
                            player_details['grade'] = value
                        
                        # ãƒ¦ãƒ‹ãƒ•ã‚©ãƒ¼ãƒ ç•ªå·ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
                        elif need_uniform and ('ãƒ¦ãƒ‹ãƒ•ã‚©ãƒ¼ãƒ ç•ªå·' in label or 'èƒŒç•ªå·' in label):
                            player_details['uniform_number'] = value
            
                        # æ°åã‚«ãƒŠï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
                        elif need_kana_name and ('æ°åã‚«ãƒŠ' in label or 'ã‚«ãƒŠå' in label or 'ãƒ•ãƒªã‚¬ãƒŠ' in label or 'ãµã‚ŠãŒãª' in label):
                            player_details['kana_name'] = value
                        
                        # ç™»éŒ²çŠ¶æ…‹ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
                        elif need_registration_status and ('ç™»éŒ²çŠ¶æ…‹' in label or 'ç™»éŒ²ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹' in label or 'Registration Status' in label or 'Status' in label):
                            player_details['registration_status'] = value
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã§è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãƒšãƒ¼ã‚¸å…¨ä½“ã‹ã‚‰æ­£è¦è¡¨ç¾ã§æ¤œç´¢ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
            if need_height and 'height' not in player_details:
                page_text = soup.get_text()
                for pattern in height_patterns:
                    import re
                    match = re.search(pattern, page_text)
                    if match:
                        player_details['height'] = match.group(1)
                        break
                
            if need_weight and 'weight' not in player_details:
                if 'page_text' not in locals():
                    page_text = soup.get_text()
                for pattern in weight_patterns:
                    import re
                    match = re.search(pattern, page_text)
                    if match:
                        player_details['weight'] = match.group(1)
                        break
            
            return player_details
            
        except Exception as e:
            # é¸æ‰‹è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼
            return {}
    

    def normalize_name(self, name):
        """åå‰ã®æ­£è¦åŒ–"""
        if not name or pd.isna(name):
            return ""
        
        name = str(name)
        
        # 1. å…¨è§’ãƒ»åŠè§’çµ±ä¸€
        name = unicodedata.normalize('NFKC', name)
        
        # 2. è¨˜å·ãƒ»ã‚¹ãƒšãƒ¼ã‚¹ã®æ­£è¦åŒ–ï¼ˆå…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚‚å«ã‚€ï¼‰
        name = re.sub(r'[ãƒ»ï½¥ã€ï¼Œ,\.\sã€€]+', '', name)
        
        # 3. å¤§æ–‡å­—å°æ–‡å­—çµ±ä¸€
        name = name.lower()
        
        # 4. ã‚ˆãã‚ã‚‹è¡¨è¨˜æºã‚Œã®çµ±ä¸€
        name = re.sub(r'[ãƒ¼âˆ’â€â€”â€“]', '', name)  # é•·éŸ³ç¬¦ã€ãƒã‚¤ãƒ•ãƒ³ã€ã‚¨ãƒ ãƒ€ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒ³ãƒ€ãƒƒã‚·ãƒ¥é™¤å»
        
        return name

    def calculate_similarity(self, name1, name2):
        """åå‰ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        if not name1 or not name2:
            return 0.0
        
        # æ­£è¦åŒ–
        norm_name1 = self.normalize_name(name1)
        norm_name2 = self.normalize_name(name2)
        
        if norm_name1 == norm_name2:
            return 1.0
        
        # åŸºæœ¬çš„ãªé¡ä¼¼åº¦
        basic_similarity = SequenceMatcher(None, norm_name1, norm_name2).ratio()
        
        return basic_similarity
    
    def show_name_differences(self, name1, name2):
        """åå‰ã®å¾®å¦™ãªé•ã„ã‚’è¦–è¦šçš„ã«è¡¨ç¤º"""
        if not name1 or not name2:
            return ""
        
        # æ­£è¦åŒ–
        norm_name1 = self.normalize_name(name1)
        norm_name2 = self.normalize_name(name2)
        
        if norm_name1 == norm_name2:
            return "âœ… å®Œå…¨ä¸€è‡´"
        
        # æ–‡å­—å˜ä½ã§ã®å·®åˆ†ã‚’è¡¨ç¤º
        matcher = SequenceMatcher(None, norm_name1, norm_name2)
        differences = []
        
        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag == 'equal':
                differences.append(norm_name1[i1:i2])
            elif tag == 'delete':
                differences.append(f"âŒ{norm_name1[i1:i2]}âŒ")
            elif tag == 'insert':
                differences.append(f"â•{norm_name2[j1:j2]}â•")
            elif tag == 'replace':
                differences.append(f"ğŸ”„{norm_name1[i1:i2]}â†’{norm_name2[j1:j2]}ğŸ”„")
        
        result = "".join(differences)
        return f"ğŸ” å·®åˆ†: {result}"

    def verify_player_info(self, player_name, birth_date, university, get_details=False, threshold=1.0, player_no=None, kana_name=None):
        """å€‹åˆ¥é¸æ‰‹æƒ…å ±ã®ç…§åˆï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰"""
        try:
            logger.info(f"ğŸ” é¸æ‰‹ç…§åˆ: {player_name}, å¤§å­¦: {university}")
            
            # æ°åãŒã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã®å ´åˆã®ã¿ã€ã‚«ãƒŠåã§é¸æ‰‹åã‚’æ¢ã™
            import re
            is_alphabet_only = bool(re.match(r'^[A-Za-z\s]+$', player_name)) if player_name else False
            
            # ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
            if not self.logged_in:
                logger.error("âŒ JBAã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã¾ã›ã‚“")
                return {"status": "error", "message": "JBAãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™"}
            
            # èƒŒç•ªå·ãŒãªã„å ´åˆã‚‚é¸æ‰‹åãƒ»ã‚«ãƒŠåã§ç…§åˆï¼ˆã‚³ãƒ¼ãƒæ‰±ã„ã‚’ã‚„ã‚ã‚‹ï¼‰
            # èƒŒç•ªå·ã®æœ‰ç„¡ã«é–¢ã‚ã‚‰ãšã€é¸æ‰‹åãƒ»ã‚«ãƒŠåã§ç…§åˆã™ã‚‹
            
            # å¤§å­¦åã‹ã‚‰ã€Œå¤§å­¦ã€ã‚’å¤–ã—ãŸåå‰ã§æ¤œç´¢
            search_variations = self.get_search_variations(university)
            if not search_variations:
                logger.warning(f"âš ï¸ {university}ã®æ¤œç´¢åãŒç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return {"status": "not_found", "message": f"{university}ã®æ¤œç´¢åãŒç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ"}
            
            # æœ€åˆã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå¤§å­¦åã‹ã‚‰ã€Œå¤§å­¦ã€ã‚’å¤–ã—ãŸåå‰ï¼‰ã®ã¿ã§æ¤œç´¢
            search_name = search_variations[0]
            
            # ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„: ãƒãƒ¼ãƒ æƒ…å ±ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
            if search_name in self.teams_cache:
                teams = self.teams_cache[search_name]
                logger.debug(f"ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒãƒ¼ãƒ æƒ…å ±ã‚’å–å¾—: {len(teams)}ãƒãƒ¼ãƒ ")
            else:
                logger.info(f"ğŸ” ãƒãƒ¼ãƒ æ¤œç´¢é–‹å§‹: {search_name}")
                try:
                    teams = self._search_teams_by_university_silent(search_name)
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                    self.teams_cache[search_name] = teams
                    logger.info(f"ğŸ” æ¤œç´¢çµæœ: {len(teams)}ãƒãƒ¼ãƒ è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                except Exception as search_error:
                    logger.error(f"âŒ ãƒãƒ¼ãƒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼ ({search_name}): {search_error}")
                    teams = []
            
            if not teams:
                logger.warning(f"âš ï¸ {university}ã®ç”·å­ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return {"status": "not_found", "message": f"{university}ã®ç”·å­ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}

            # å„ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ã—ã¦ç…§åˆ
            for team in teams:
                try:
                    # ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„: ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
                    if team['url'] in self.team_members_cache:
                        team_data = self.team_members_cache[team['url']]
                        logger.debug(f"ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—: {team['name']}")
                    else:
                        logger.info(f"ğŸ” ãƒãƒ¼ãƒ : {team['name']} ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’å–å¾—ä¸­...")
                        team_data = self._get_team_members_silent(team['url'])
                        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                        self.team_members_cache[team['url']] = team_data
                    
                    if not team_data or not team_data.get("members"):
                        logger.warning(f"âš ï¸ ãƒãƒ¼ãƒ  {team['name']} ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                        continue
                    
                    # ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„: ãƒ­ã‚°å‡ºåŠ›ã‚’å‰Šæ¸›
                    logger.debug(f"ğŸ” ãƒ¡ãƒ³ãƒãƒ¼æ•°: {len(team_data['members'])}äºº")
                    
                    for i, member in enumerate(team_data["members"]):
                        try:
                            # æ°åãŒã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã®å ´åˆã®ã¿ã€ã‚«ãƒŠåã§é¸æ‰‹åã‚’æ¢ã™
                            search_name = player_name
                            if is_alphabet_only and kana_name:
                                # ã‚«ãƒŠåã§é¸æ‰‹åã‚’æ¢ã™ï¼ˆJBAãƒ‡ãƒ¼ã‚¿ã®æ°åã‚«ãƒŠã¨ç…§åˆï¼‰
                                search_name = kana_name
                        
                        # åå‰ã®é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯
                            name_similarity = self.calculate_similarity(search_name, member.get("name", ""))
                            
                            # ã‚«ãƒŠåã‚‚ç…§åˆï¼ˆJBAãƒ‡ãƒ¼ã‚¿ã®æ°åã‚«ãƒŠã¨ç…§åˆï¼‰
                            kana_similarity = 0.0
                            if kana_name and member.get("kana_name"):
                                kana_similarity = self.calculate_similarity(kana_name, member.get("kana_name", ""))
                            
                            # åå‰ã¾ãŸã¯ã‚«ãƒŠåã®é¡ä¼¼åº¦ãŒ0.6ä»¥ä¸Šãªã‚‰JBAç™»éŒ²ã‚ã‚Šï¼ˆã€‡ï¼‰ã¨ã—ã¦æ‰±ã†
                            max_similarity = max(name_similarity, kana_similarity)
                            if max_similarity >= 0.6:
                                # ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„: ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆãƒãƒƒãƒã—ãŸå ´åˆã®ã¿ï¼‰
                                logger.debug(f"  - JBAé¸æ‰‹: {member.get('name', 'N/A')}, åå‰é¡ä¼¼åº¦: {name_similarity:.3f}, ã‚«ãƒŠé¡ä¼¼åº¦: {kana_similarity:.3f}")
                                
                                # ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„3: è©³ç´°æƒ…å ±ã‚’å–å¾—ã™ã‚‹å ´åˆ
                                if get_details and member.get("detail_url"):
                                    try:
                                        if player_no:
                                            # èƒŒç•ªå·ãŒã‚ã‚‹å ´åˆã¯èº«é•·ãƒ»ä½“é‡ãƒ»å­¦å¹´ãƒ»ç™»éŒ²çŠ¶æ…‹ã‚’å–å¾—
                                            fields = ['height', 'weight', 'grade', 'registration_status']
                                        else:
                                            # èƒŒç•ªå·ãŒãªã„å ´åˆã¯ã‚«ãƒŠåã‚‚å–å¾—ï¼ˆç…§åˆã«ä½¿ç”¨ï¼‰
                                            fields = ['kana_name', 'registration_status']
                                        player_details = self.get_player_details(member["detail_url"], fields=fields)
                                        member.update(player_details)
                                    except Exception as detail_error:
                                        logger.error(f"âŒ é¸æ‰‹è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {detail_error}")
                                
                                # JBAç™»éŒ²ã‚ã‚Šï¼ˆã€‡ï¼‰ã¨ã—ã¦è¿”ã™
                                return {
                                    "status": "match",
                                    "jba_data": member,
                                    "similarity": max_similarity
                                }
                        
                        except Exception as member_error:
                            logger.error(f"âŒ ãƒ¡ãƒ³ãƒãƒ¼å‡¦ç†ã‚¨ãƒ©ãƒ¼: {member_error}")
                            continue
                
                except Exception as team_error:
                    logger.error(f"âŒ ãƒãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({team.get('name', 'Unknown')}): {team_error}")
                    continue

            # JBAç™»éŒ²ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆï¼ˆÃ—ï¼‰
            logger.warning(f"âš ï¸ {player_name} ã®JBAç™»éŒ²ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return {"status": "not_found", "message": "JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è©²å½“ã™ã‚‹é¸æ‰‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}

        except Exception as e:
            logger.error(f"âŒ ç…§åˆã‚¨ãƒ©ãƒ¼ ({player_name}): {str(e)}", exc_info=True)
            return {"status": "error", "message": f"ç…§åˆã‚¨ãƒ©ãƒ¼: {str(e)}"}

# AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤
    
# AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤
    
# AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤

class DataValidator:
    """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
    logger = logging.getLogger(__name__)
    
    def __init__(self, gemini_api_key=None):
        # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
        pass
    
    def validate_weight(self, weight):
        """ä½“é‡ã®å¦¥å½“æ€§ã‚’è©•ä¾¡ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        if not weight:
            return True, []
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªç¯„å›²ãƒã‚§ãƒƒã‚¯
        try:
            weight_value = float(weight)
            if 45 <= weight_value <= 140:
                return True, []
            else:
                return False, [f"ä½“é‡ãŒç¯„å›²å¤–ã§ã™: {weight}kg (45-140kgã®ç¯„å›²ã§å…¥åŠ›ã—ã¦ãã ã•ã„)"]
        except (ValueError, TypeError):
            return False, [f"ä½“é‡ãŒæ•°å€¤ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {weight}"]
    
    def validate_and_correct_school(self, school_name):
        """å‡ºèº«æ ¡ã®å¦¥å½“æ€§ã‚’è©•ä¾¡ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        if not school_name or school_name.strip() == "":
            return True, [], None
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªæ–‡å­—åˆ—ãƒã‚§ãƒƒã‚¯
        school_name = str(school_name).strip()
        if len(school_name) < 2:
            return False, ["å­¦æ ¡åãŒçŸ­ã™ãã¾ã™"], None
        
        return True, [], None
    
    def validate_uniform_number(self, uniform_number):
        """èƒŒç•ªå·ã®å¦¥å½“æ€§ã‚’è©•ä¾¡ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        if not uniform_number:
            return True, []
        
        # èƒŒç•ªå·ã¯æ•°å­—ã®ã¿ã®ã‚·ãƒ³ãƒ—ãƒ«æ¤œè¨¼
        try:
            num = int(uniform_number)
            if 1 <= num <= 99:
                return True, []
            else:
                return False, ["èƒŒç•ªå·ã¯1ã€œ99ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"]
        except ValueError:
            return False, ["èƒŒç•ªå·ã¯æ•°å­—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"]
    
    def validate_player_data(self, player_data):
        """ä½“é‡ãƒ»å‡ºèº«æ ¡ãƒ»èƒŒç•ªå·ã®æ¤œè¨¼ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        all_issues = []
        
        # ä½“é‡ã®æ¤œè¨¼
        weight = player_data.get('weight')
        if weight:
            is_valid_weight, weight_issues = self.validate_weight(weight)
            all_issues.extend(weight_issues)
        
        # å‡ºèº«æ ¡ã®æ¤œè¨¼
        school = player_data.get('school')
        if school:
            is_valid_school, school_issues, _ = self.validate_and_correct_school(school)
            all_issues.extend(school_issues)
        
        # èƒŒç•ªå·ã®æ¤œè¨¼
        uniform_number = player_data.get('uniform_number')
        if uniform_number:
            is_valid_uniform, uniform_issues = self.validate_uniform_number(uniform_number)
            all_issues.extend(uniform_issues)
        
        return len(all_issues) == 0, all_issues

class FastCSVCorrectionSystem:
    """CSVè¨‚æ­£ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ”¹ç‰ˆï¼‰"""
    logger = logging.getLogger(__name__)
    
    def __init__(self, jba_system, gemini_api_key=None, max_workers=5):
        self.jba_system = jba_system
        self.validator = DataValidator(gemini_api_key)
        self.max_workers = max_workers
        self.lock = threading.Lock()
        
        # ğŸ†• å¤§å­¦ã”ã¨ã®ãƒãƒ¼ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆPhase 1: 30å€é«˜é€ŸåŒ–ï¼‰
        self.university_teams_cache = {}
        self.team_members_cache = {}
        self.university_teams_data = {}
        
        # ğŸ†• Phase 3: æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ2å›ç›®ä»¥é™100å€é«˜é€Ÿï¼‰
        self.persistent_cache_file = "jba_player_cache.json"
        self.persistent_cache = self._load_persistent_cache()
        self.cache_dirty = False  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤‰æ›´ã•ã‚ŒãŸã‹ã©ã†ã‹
    
    def _load_persistent_cache(self):
        """ğŸ†• Phase 3: æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰"""
        if not os.path.exists(self.persistent_cache_file):
            return {}
        
        try:
            with open(self.persistent_cache_file, "r", encoding="utf-8") as f:
                cache = json.load(f)
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä»¶æ•°ã‚’è¡¨ç¤ºï¼ˆstreamlitã®å¤–ã§å®Ÿè¡Œã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ try-exceptï¼‰
                try:
                    logger.info(f"ğŸ’¾ æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {len(cache)}ä»¶")
                except:
                    pass
                return cache
        except Exception as e:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãŒå£Šã‚Œã¦ã„ã‚‹å ´åˆã¯ç„¡è¦–
            return {}
    
    def _save_persistent_cache(self):
        """ğŸ†• Phase 3: æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if not self.cache_dirty:
            return
        
        try:
            with open(self.persistent_cache_file, "w", encoding="utf-8") as f:
                json.dump(self.persistent_cache, f, ensure_ascii=False, indent=2)
            self.cache_dirty = False
        except Exception as e:
            # ä¿å­˜ã«å¤±æ•—ã—ã¦ã‚‚å‡¦ç†ã¯ç¶šè¡Œ
            pass
    
    def _get_cache_key(self, player_name, university_name):
        """ğŸ†• Phase 3: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        import hashlib
        # é¸æ‰‹åã¨å¤§å­¦åã‚’æ­£è¦åŒ–ã—ã¦ãƒãƒƒã‚·ãƒ¥åŒ–
        normalized_name = self.jba_system.normalize_name(player_name)
        normalized_univ = self.jba_system.normalize_university_name(university_name)
        key_string = f"{normalized_name}_{normalized_univ}"
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def _preload_university_data(self, university_name):
        """å¤§å­¦ã®ãƒãƒ¼ãƒ æƒ…å ±ã‚’äº‹å‰ã«å…¨ã¦å–å¾—ï¼ˆ1å›ã ã‘å®Ÿè¡Œï¼‰"""
        if university_name in self.university_teams_data:
            return self.university_teams_data[university_name]
        
        # ğŸ†• ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
        # Status text placeholder removed
        # Progress bar removed - use job_meta instead
        
        # ãƒãƒ¼ãƒ æ¤œç´¢ï¼ˆæ¤œç´¢ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰- é™ã‹ãªå®Ÿè¡Œ
        status_text.info(f"ğŸ” {university_name}ã®ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ä¸­...")
        search_variations = self.jba_system.get_search_variations(university_name)
        teams = []
        
        for i, variation in enumerate(search_variations):
            progress = (i + 1) / (len(search_variations) + 1)
            # Progress update removed  # 0-30%
            teams = self.jba_system._search_teams_by_university_silent(variation)
            if teams:
                break
        
        if not teams:
            status_text.warning(f"âš ï¸ {university_name}ã®ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            # Progress bar cleanup removed
            with self.lock:
                self.university_teams_data[university_name] = None
            return None
        
        status_text.success(f"âœ… {len(teams)}ãƒãƒ¼ãƒ ç™ºè¦‹ï¼ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ä¸­...")
        
        # å„ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’å–å¾— - é™ã‹ãªå®Ÿè¡Œ
        teams_data = {}
        total_teams = len(teams)
        
        for idx, team in enumerate(teams):
            team_id = team['id']
            team_url = team['url']
            team_name = team['name']
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°ï¼ˆ30-100%ï¼‰
            progress = 0.3 + (0.7 * (idx + 1) / total_teams)
            # Progress update removed
            status_text.info(f"ğŸ“¥ ãƒãƒ¼ãƒ  {idx+1}/{total_teams}: {team_name} ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’å–å¾—ä¸­...")
            
            # æ—¢ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ã‚Œã°ä½¿ç”¨
            if team_url in self.team_members_cache:
                team_data = self.team_members_cache[team_url]
            else:
                team_data = self.jba_system._get_team_members_silent(team_url)
                with self.lock:
                    self.team_members_cache[team_url] = team_data
            
            teams_data[team_id] = {
                'team_name': team['name'],
                'team_url': team_url,
                'members': team_data.get('members', [])
            }
        
        # å®Œäº†
        # Progress update removed
        total_members = sum(len(t['members']) for t in teams_data.values())
        status_text.success(f"âœ… äº‹å‰ãƒ­ãƒ¼ãƒ‰å®Œäº†: {total_teams}ãƒãƒ¼ãƒ ã€{total_members}åã®é¸æ‰‹æƒ…å ±ã‚’å–å¾—")
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ¶ˆå»
        # Sleep removed  # 0.5ç§’è¡¨ç¤º
        # Progress bar cleanup removed
        status_text.empty()
        
        with self.lock:
            self.university_teams_data[university_name] = teams_data
        
        return teams_data
    
    def _find_player_from_cache(self, player_name, university_name):
        """ğŸ†• ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰é¸æ‰‹ã‚’æ¤œç´¢ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãªã—ãƒ»è¶…é«˜é€Ÿï¼‰"""
        teams_data = self.university_teams_data.get(university_name)
        
        if not teams_data:
            return {"status": "not_found", "message": f"{university_name}ã®ãƒãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        all_matched_members = []
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå…¨ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’æ¤œç´¢
        for team_id, team_info in teams_data.items():
            members = team_info.get('members', [])
            
            for member in members:
                # åå‰ã®é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯
                name_similarity = self.jba_system.calculate_similarity(player_name, member.get("name", ""))
                
                # 0.6ä»¥ä¸Šã®å€™è£œã‚’ä¿å­˜
                if name_similarity >= 0.6:
                    # å®Œå…¨ä¸€è‡´
                    if name_similarity >= 1.0:
                        return {
                            "status": "match",
                            "jba_data": member,
                            "similarity": name_similarity
                        }
                    # éƒ¨åˆ†ä¸€è‡´
                    else:
                        all_matched_members.append({
                            "status": "partial_match",
                            "jba_data": member,
                            "similarity": name_similarity,
                            "message": f"éƒ¨åˆ†ä¸€è‡´: {member['name']} (é¡ä¼¼åº¦: {name_similarity:.3f})"
                        })
        
        # å®Œå…¨ä¸€è‡´ãŒãªã‘ã‚Œã°ã€éƒ¨åˆ†ä¸€è‡´ã‚’è¿”ã™
        if all_matched_members:
            # é¡ä¼¼åº¦ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
            all_matched_members.sort(key=lambda x: x["similarity"], reverse=True)
            return all_matched_members[0]
        
        return {"status": "not_found", "message": f"{player_name}ã®JBAç™»éŒ²ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}
    
    def _process_single_player(self, row_data):
        """å˜ä¸€é¸æ‰‹ã‚’å‡¦ç†ï¼ˆè¨‚æ­£å¿…è¦ãªå ´åˆã®ã¿æƒ…å ±ã‚’è©°ã‚ã‚‹ï¼‰"""
        index, row, university_name, threshold = row_data
        
        try:
            player_name = None
            name_column = None
            name_columns = ['é¸æ‰‹å', 'æ°å', 'name', 'Name']
            
            for col in name_columns:
                if col in row.index and pd.notna(row[col]):
                    player_name = str(row[col]).strip()
                    name_column = col
                    break
            
            if not player_name:
                return {
                    'index': index,
                    'original_data': row.to_dict(),
                    'status': 'missing_data',
                    'corrections': {},
                    'jba_data': {},
                    'validation_warnings': [],
                    'has_correction': False
                }
            
            # ğŸ†• Phase 3: æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ2å›ç›®ä»¥é™ã¯ç¬æ™‚ï¼‰
            cache_key = self._get_cache_key(player_name, university_name)
            if cache_key in self.persistent_cache:
                cached = self.persistent_cache[cache_key]
                cached['index'] = index
                cached['original_data'] = row.to_dict()
                return cached
            
            # ğŸ†• Phase 1: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰é¸æ‰‹ã‚’æ¤œç´¢ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãªã—ãƒ»è¶…é«˜é€Ÿï¼‰
            verification_result = self._find_player_from_cache(player_name, university_name)
            
            result = {
                'index': index,
                'original_data': row.to_dict(),
                'verification_result': verification_result,
                'status': verification_result.get('status', 'error'),
                'corrections': {},
                'jba_data': {},
                'validation_warnings': [],
                'has_correction': False
            }
            
            # jba_data ã‚’äº‹å‰ã«åˆæœŸåŒ–
            jba_data = {}
            
            if verification_result.get('status') in ['match', 'partial_match']:
                jba_data = verification_result.get('jba_data', {})
                result['jba_data'] = jba_data
                
                # åå‰ãŒç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('name') and jba_data['name'] != player_name:
                    result['corrections'][name_column] = jba_data['name']
                    result['has_correction'] = True
                
                # ä½“é‡ï¼šJBAã«ã‚ã‚Œã°å„ªå…ˆã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('weight') and str(jba_data['weight']).strip():
                    weight_value = str(jba_data['weight']).strip()
                    weight_match = re.search(r'(\d+\.?\d*)', weight_value)
                    if weight_match:
                        extracted_weight = weight_match.group(1)
                        try:
                            original_weight = float(row.get('ä½“é‡', 0))
                            jba_weight = float(extracted_weight)
                            if original_weight != jba_weight:
                                result['corrections']['ä½“é‡'] = extracted_weight
                                result['has_correction'] = True
                        except (ValueError, TypeError):
                            pass
                
                # å­¦å¹´ï¼šJBAã«è¨˜è¼‰ãŒã‚ã‚Œã°ã€æ•°å­—ã ã‘ã‚’æŠ½å‡ºã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('grade') and str(jba_data['grade']).strip():
                    grade_value = str(jba_data['grade']).strip()
                    grade_match = re.search(r'(\d+)', grade_value)
                    if grade_match:
                        extracted_grade = grade_match.group(1)
                        try:
                            original_grade = str(row.get('å­¦å¹´', '')).strip()
                            if original_grade.isdigit():
                                original_grade_num = original_grade
                            else:
                                grade_num_match = re.search(r'(\d+)', original_grade)
                                original_grade_num = grade_num_match.group(1) if grade_num_match else original_grade
                            
                            if original_grade_num != extracted_grade:
                                result['corrections']['å­¦å¹´'] = extracted_grade
                                result['has_correction'] = True
                        except:
                            pass
                
                # èº«é•·ï¼šJBAã«è¨˜è¼‰ãŒã‚ã‚Œã°ã€æ•°å­—ã ã‘ã‚’æŠ½å‡ºã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('height') and str(jba_data['height']).strip():
                    height_value = str(jba_data['height']).strip()
                    height_match = re.search(r'(\d+\.?\d*)', height_value)
                    if height_match:
                        extracted_height = height_match.group(1)
                        try:
                            original_height = float(row.get('èº«é•·', 0))
                            jba_height = float(extracted_height)
                            if original_height != jba_height:
                                result['corrections']['èº«é•·'] = extracted_height
                                result['has_correction'] = True
                        except (ValueError, TypeError):
                            pass
                
                # å…ƒãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸å€¤ã‚’AIã§æ¤œå‡ºï¼ˆJBAã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ã¿ï¼‰
                if not jba_data.get('weight') and not jba_data.get('height'):
                    validation_warnings = []  # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
                    result['validation_warnings'] = validation_warnings
            else:
                # JBAç™»éŒ²ãªã—ãƒ»æœªç™ºè¦‹ã®å ´åˆã‚‚è­¦å‘Šã‚’ãƒã‚§ãƒƒã‚¯
                validation_warnings = []  # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
                result['validation_warnings'] = validation_warnings
            
            # ğŸ†• Phase 3: çµæœã‚’æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            with self.lock:
                self.persistent_cache[cache_key] = {
                    'status': result['status'],
                    'corrections': result['corrections'],
                    'jba_data': result['jba_data'],
                    'validation_warnings': result['validation_warnings'],
                    'has_correction': result['has_correction']
                }
                self.cache_dirty = True
            
            return result
        
        except Exception as e:
            import traceback
            return {
                'index': index,
                'original_data': row.to_dict(),
                'status': 'error',
                'corrections': {},
                'jba_data': {},
                'validation_warnings': [f'ã‚¨ãƒ©ãƒ¼: {str(e)}'],
                'has_correction': False
            }
    
    def _validate_player_data_with_ai(self, row, jba_data):
        """å…ƒãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸å€¤ã‚’æ¤œå‡ºï¼ˆJBAã«è¨˜è¼‰ãŒãªã„å ´åˆã®ã¿ï¼‰"""
        warnings = []
        
        # ä½“é‡ï¼šJBAã«è¨˜è¼‰ãŒãªã„å ´åˆã®ã¿è¨±å®¹ç¯„å›²ã§ãƒã‚§ãƒƒã‚¯
        if not jba_data.get('weight') and pd.notna(row.get('ä½“é‡')):
            weight = row.get('ä½“é‡')
            try:
                weight_value = float(weight)
                if weight_value < 45 or weight_value > 140:
                    warnings.append(f"âš ï¸ ä½“é‡ãŒè¨±å®¹ç¯„å›²å¤–: {weight_value}kg (è¨±å®¹ç¯„å›²: 45-140kg)")
            except (ValueError, TypeError):
                warnings.append(f"âš ï¸ ä½“é‡ãŒæ•°å€¤ã§ã¯ãªã„: {weight}")
        
        return warnings
    
    def process_csv_file_parallel(self, df, university_name, threshold=1.0):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¦åˆ—å‡¦ç†ã§é«˜é€Ÿã«å‡¦ç†"""
        
        # Markdown removed
        # Subheader removed
        
        # ğŸ†• Phase 1: å¤§å­¦ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰ã«1å›ã ã‘ãƒ­ãƒ¼ãƒ‰ï¼ˆ30å€é«˜é€ŸåŒ–ï¼‰
        # Markdown removed
        preload_start = time.time()
        self._preload_university_data(university_name)
        preload_time = time.time() - preload_start
        
        # Markdown removed
        # Markdown removed
        logger.info(f"ğŸ’¨ ä¸¦åˆ—å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {self.max_workers}ã‚¹ãƒ¬ãƒƒãƒ‰ã§é«˜é€Ÿå‡¦ç†ä¸­...")
        
        process_data = [
            (index, row, university_name, threshold)
            for index, row in df.iterrows()
        ]
        
        results = []
        # Progress bar removed - use job_meta instead
        # Status text placeholder removed
        
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {executor.submit(self._process_single_player, data): data[0] for data in process_data}
            
            completed = 0
            total = len(futures)
            update_interval = max(1, total // 20)  # ğŸ†• Phase 2: 20å›ã ã‘æ›´æ–°ï¼ˆ5%ã”ã¨ï¼‰
            
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                results.append(result)
                
                completed += 1
                
                # ğŸ†• Phase 2: æ›´æ–°é »åº¦ã‚’å‰Šæ¸›ï¼ˆ5%ã”ã¨ or æœ€çµ‚ï¼‰
                if completed % update_interval == 0 or completed == total:
                    progress = completed / total
                    # Progress update removed
                    # Status text update removed")
        
        elapsed_time = time.time() - start_time
        
        # Progress update removed
        # Status text update removed
        
        # ğŸ†• Phase 3: æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        if self.cache_dirty:
            logger.info("ğŸ’¾ æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜ä¸­...")
            self._save_persistent_cache()
            logger.info(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {len(self.persistent_cache)}ä»¶")
        
        results.sort(key=lambda x: x['index'])
        
        # â˜… çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        logger.info(f"âœ… {len(df)}è¡Œã‚’{elapsed_time:.2f}ç§’ã§å‡¦ç†ã—ã¾ã—ãŸ")
        
        # çµ±è¨ˆæƒ…å ±
        matched = sum(1 for r in results if r['status'] == 'match')
        partial = sum(1 for r in results if r['status'] == 'partial_match')
        warnings_count = sum(len(r.get('validation_warnings', [])) for r in results)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            pass
        with col2:
            pass
        with col3:
            pass
        with col4:
            pass
        
        return results
    
    def create_corrected_csv(self, df, results):
        """ä¿®æ­£ç‰ˆCSVã‚’ä½œæˆï¼ˆå…ƒã®åˆ—é †ã‚’ä¿æŒã€ã‚»ãƒ«å½¢å¼ã‚’ä¿æŒï¼‰"""
        corrected_df = df.copy()
        
        for result in results:
            # è¨‚æ­£ãŒã‚ã‚‹å ´åˆã®ã¿å‡¦ç†
            if not result.get('has_correction'):
                continue
            
            index = result['index']
            corrections = result.get('corrections', {})
            
            if not corrections:
                continue
            
            # å„ä¿®æ­£é …ç›®ã‚’CSVã«åæ˜ ï¼ˆåˆ—é †ã¯å¤‰ã‚ã‚‰ãªã„ï¼‰
            for csv_col, corrected_value in corrections.items():
                if csv_col not in corrected_df.columns:
                    # åˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆè¿½åŠ ã—ãªã„ï¼‰
                    continue
                
                # ä¿®æ­£å€¤ã‚’é©ç”¨
                corrected_df.at[index, csv_col] = corrected_value
        
        return corrected_df
    
    # Excelå‡ºåŠ›ã¯å»ƒæ­¢ - PDFã®ã¿ä½¿ç”¨

class CSVCorrectionSystem:
    """CSVè‡ªå‹•è¨‚æ­£ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¾“æ¥ç‰ˆï¼‰"""
    logger = logging.getLogger(__name__)
    
    def __init__(self, jba_system, gemini_api_key=None):
        self.jba_system = jba_system
        self.validator = DataValidator(gemini_api_key)
    
    def process_csv_file(self, df, university_name, threshold=0.8, get_details=False):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦è¨‚æ­£ç‰ˆã‚’ä½œæˆ"""
        logger.info(f"ğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­... ({len(df)}è¡Œ)")
        logger.info(f"ğŸ” å‡¦ç†é–‹å§‹: å¤§å­¦å={university_name}, é–¾å€¤={threshold}, è©³ç´°å–å¾—={get_details}")
        
        results = []
        corrections = []
        
        # Progress bar removed - use job_meta instead
        # Status text placeholder removed
        
        for index, row in df.iterrows():
            progress = (index + 1) / len(df)
            # Progress update removed
            # Status text update removed} - {row.get('é¸æ‰‹å', row.get('æ°å', 'Unknown'))}")
            
            logger.info(f"ğŸ” è¡Œ {index + 1} ã‚’å‡¦ç†ä¸­...")
            
            # é¸æ‰‹åã®ã¿ã‚’å–å¾—
            player_name = None
            name_columns = ['é¸æ‰‹å', 'æ°å', 'name', 'Name']
            
            for col in name_columns:
                if col in df.columns and pd.notna(row[col]):
                    player_name = str(row[col]).strip()
                    logger.info(f"  - é¸æ‰‹åå–å¾—: {player_name} (ã‚«ãƒ©ãƒ : {col})")
                    break
            
            if not player_name:
                logger.warning(f"  - é¸æ‰‹åãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                results.append({
                    'index': index,
                    'original_data': row.to_dict(),
                    'status': 'missing_data',
                    'message': 'é¸æ‰‹åãŒä¸è¶³ã—ã¦ã„ã¾ã™',
                    'correction': None
                })
                continue
            
            # JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®ç…§åˆ
            verification_result = self.jba_system.verify_player_info(
                player_name, None, university_name, get_details, threshold
            )
            
            result = {
                'index': index,
                'original_data': row.to_dict(),
                'verification_result': verification_result,
                'status': verification_result['status']
            }
            
            # å®Œå…¨ä¸€è‡´ã®å ´åˆ
            if verification_result['status'] == 'match':
                if get_details and 'jba_data' in verification_result:
                    jba_data = verification_result['jba_data']
                    is_valid, validation_issues, school_corrections = self.validator.validate_player_data(jba_data)
                    
                    corrected_data = row.to_dict().copy()
                    
                    # JBAæƒ…å ±ã‚’è¿½åŠ 
                    if 'height' in jba_data and jba_data['height']:
                        corrected_data['èº«é•·'] = f"{jba_data['height']}cm"
                    if 'weight' in jba_data and jba_data['weight']:
                        corrected_data['ä½“é‡'] = f"{jba_data['weight']}kg"
                    if 'position' in jba_data and jba_data['position']:
                        corrected_data['ãƒã‚¸ã‚·ãƒ§ãƒ³'] = jba_data['position']
                    if 'school' in jba_data and jba_data['school']:
                        if 'school' in school_corrections:
                            corrected_data['å‡ºèº«æ ¡'] = school_corrections['school']
                            result['school_correction'] = f"{jba_data['school']} â†’ {school_corrections['school']}"
                        else:
                            corrected_data['å‡ºèº«æ ¡'] = jba_data['school']
                    if 'grade' in jba_data and jba_data['grade']:
                        corrected_data['å­¦å¹´'] = jba_data['grade']
                    if 'uniform_number' in jba_data and jba_data['uniform_number']:
                        corrected_data['èƒŒç•ªå·'] = jba_data['uniform_number']
                    
                    if not is_valid:
                        result['validation_issues'] = validation_issues
                        result['message'] = f'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´ï¼ˆè©³ç´°æƒ…å ±è¿½åŠ ï¼‰âš ï¸ ç•°å¸¸å€¤æ¤œå‡º: {", ".join(validation_issues)}'
                    else:
                        result['message'] = 'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´ï¼ˆè©³ç´°æƒ…å ±è¿½åŠ ï¼‰'
                    
                    result['correction'] = corrected_data
                else:
                    result['correction'] = None
                    result['message'] = 'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´'
            
            # éƒ¨åˆ†ä¸€è‡´ã®å ´åˆ
            elif verification_result['status'] == 'partial_match':
                jba_data = verification_result['jba_data']
                similarity = verification_result.get('similarity', 0.0)
                
                corrected_data = row.to_dict().copy()
                
                if get_details:
                    if 'height' in jba_data and jba_data['height']:
                        corrected_data['èº«é•·'] = f"{jba_data['height']}cm"
                    if 'weight' in jba_data and jba_data['weight']:
                        corrected_data['ä½“é‡'] = f"{jba_data['weight']}kg"
                    if 'position' in jba_data and jba_data['position']:
                        corrected_data['ãƒã‚¸ã‚·ãƒ§ãƒ³'] = jba_data['position']
                    if 'school' in jba_data and jba_data['school']:
                        corrected_data['å‡ºèº«æ ¡'] = jba_data['school']
                    if 'grade' in jba_data and jba_data['grade']:
                        corrected_data['å­¦å¹´'] = jba_data['grade']
                    if 'uniform_number' in jba_data and jba_data['uniform_number']:
                        corrected_data['èƒŒç•ªå·'] = jba_data['uniform_number']
                
                result['correction'] = corrected_data
                result['message'] = f"éƒ¨åˆ†ä¸€è‡´: {jba_data['name']} (é¡ä¼¼åº¦: {similarity:.3f}) - æ‰‹å‹•ç¢ºèªæ¨å¥¨"
            
            # ä¸€è‡´ãªã—ã®å ´åˆ
            else:
                result['correction'] = None
                result['message'] = verification_result.get('message', 'ç…§åˆã§ãã¾ã›ã‚“ã§ã—ãŸ')
            
            results.append(result)
        
        # Progress update removed
        # Status text update removed
        
        return results, corrections
    
    def create_corrected_csv(self, df, results):
        """è¨‚æ­£ç‰ˆCSVã‚’ä½œæˆï¼ˆè¨‚æ­£éƒ¨åˆ†ã‚’èµ¤å­—ã§è¡¨ç¤ºï¼‰"""
        corrected_df = df.copy()
        
        # è¨‚æ­£ã‚’é©ç”¨
        for result in results:
            if result['correction']:
                index = result['index']
                corrected_data = result['correction']
                
                # å„ã‚«ãƒ©ãƒ ã‚’æ›´æ–°
                for col, value in corrected_data.items():
                    if col in corrected_df.columns:
                        # å…ƒã®å€¤ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                        original_value = corrected_df.at[index, col]
                        if original_value != value:
                            # è¨‚æ­£ã•ã‚ŒãŸå€¤ã‚’èµ¤å­—ã§è¡¨ç¤º
                            corrected_df.at[index, col] = f"ğŸ”´ {value}"
        
        return corrected_df

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆStreamlit UI ã¯å‰Šé™¤æ¸ˆã¿ï¼‰"""
    # Streamlit UI ã¯å‰Šé™¤æ¸ˆã¿ - ä½•ã‚‚ã—ãªã„
    pass

# çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç›´æ¥å®Ÿè¡Œã—ãªã„
# if __name__ == "__main__":
#     main()

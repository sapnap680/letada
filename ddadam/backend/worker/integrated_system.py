# Streamlit removed
import requests
import logging

from bs4 import BeautifulSoup
import pandas as pd
import os
import re
import time
import threading
import argparse
from urllib.parse import urljoin
import getpass
from datetime import datetime
import json
import uuid
import multiprocessing
# ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰PDFãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆå­˜åœ¨ã—ãªã„ç’°å¢ƒã§ã‚‚å‹•ä½œã™ã‚‹ã‚ˆã†ã«ã‚¬ãƒ¼ãƒ‰ï¼‰
try:
    from integrated_system_worker import pdf_worker_main
except Exception:
    pdf_worker_main = None
from io import StringIO
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib import colors
from reportlab.lib.pagesizes import A4, landscape
from reportlab.lib.units import mm
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.utils import simpleSplit
import multiprocessing
import platform

# æ—¢å­˜ã®JBAæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
sys.path.append('.')

# JBAæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from worker.jba_verification_lib import JBAVerificationSystem, FastCSVCorrectionSystem, DataValidator

class IntegratedTournamentSystem:
    """å¤§ä¼šIDã‹ã‚‰JBAç…§åˆã¾ã§ä¸€æ‹¬å‡¦ç†ã™ã‚‹çµ±åˆã‚·ã‚¹ãƒ†ãƒ """
    
    logger = logging.getLogger(__name__)
    
    
    def __init__(self, jba_system, validator, max_workers=20, use_parallel=True):
        self.jba_system = jba_system
        self.validator = validator
        self.base_url = "https://www.kcbbf.jp"
        self.max_workers = max_workers
        self.use_parallel = use_parallel
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ç”¨
        self.performance_stats = {
            'total_time': 0,
            'io_time': 0,
            'processing_time': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'requests_count': 0,
            'avg_response_time': 0
        }
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨
        self._cache = {}
        self._cache_lock = threading.Lock()
        
        # CPUæœ€é©åŒ–
        self.cpu_count = multiprocessing.cpu_count()
        self.max_workers = min(self.max_workers, self.cpu_count * 2)
        
        # ä¸€æ™‚ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.temp_dir = "temp_results"
        if not os.path.exists(self.temp_dir):
            os.makedirs(self.temp_dir)
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ç™»éŒ²
        self._register_japanese_fonts()
    
    def _register_japanese_fonts(self):
        """æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ç™»éŒ²"""
        try:
            # TTCãƒ•ã‚©ãƒ³ãƒˆã‚’å …ç‰¢ã«ç™»éŒ²ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼
            def _try_register_ttc(font_name_base: str, ttc_path: str, max_index: int = 8) -> str:
                """.ttc ã®ã‚µãƒ–ãƒ•ã‚©ãƒ³ãƒˆã‚’é †ã«è©¦ã™ã€‚æˆåŠŸã—ãŸãƒ•ã‚©ãƒ³ãƒˆåã‚’è¿”ã™ï¼ˆå¤±æ•—æ™‚ã¯ç©ºæ–‡å­—ï¼‰ã€‚"""
                from reportlab.pdfbase.ttfonts import TTFont
                for i in range(max_index):
                    try:
                        candidate_name = f"{font_name_base}-{i}"
                        pdfmetrics.registerFont(TTFont(candidate_name, ttc_path, subfontIndex=i))
                        return candidate_name
                    except Exception:
                        continue
                return ""

            # Windowsã®å ´åˆ
            if platform.system() == "Windows":
                # MS ã‚´ã‚·ãƒƒã‚¯
                try:
                    pdfmetrics.registerFont(TTFont('MS-Gothic', 'C:/Windows/Fonts/msgothic.ttc'))
                    self.default_font = 'MS-Gothic'
                    print("âœ… MS-Gothic ãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²æˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ MS-Gothic ç™»éŒ²å¤±æ•—: {e}")
                
                # MS æ˜æœ
                if not hasattr(self, 'default_font'):
                    try:
                        pdfmetrics.registerFont(TTFont('MS-Mincho', 'C:/Windows/Fonts/msmincho.ttc'))
                        self.default_font = 'MS-Mincho'
                        print("âœ… MS-Mincho ãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²æˆåŠŸ")
                    except Exception as e:
                        print(f"âš ï¸ MS-Mincho ç™»éŒ²å¤±æ•—: {e}")
                
                # ãƒ¡ã‚¤ãƒªã‚ª
                if not hasattr(self, 'default_font'):
                    try:
                        pdfmetrics.registerFont(TTFont('Meiryo', 'C:/Windows/Fonts/meiryo.ttc'))
                        self.default_font = 'Meiryo'
                        print("âœ… Meiryo ãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²æˆåŠŸ")
                    except Exception as e:
                        print(f"âš ï¸ Meiryo ç™»éŒ²å¤±æ•—: {e}")
            
            # Linux/Macã®å ´åˆ
            else:
                # Linuxç’°å¢ƒã§ã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œ
                font_paths_ttc = [
                    '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
                    '/usr/share/fonts/opentype/noto/NotoSerifCJK-Regular.ttc',
                    '/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc',
                    '/usr/share/fonts/truetype/noto/NotoSerifCJK-Regular.ttc'
                ]
                font_paths_ttf_otf = [
                    '/usr/share/fonts/truetype/noto/NotoSansCJKjp-Regular.otf',
                    '/usr/share/fonts/truetype/noto/NotoSerifCJKjp-Regular.otf',
                ]
                
                font_registered = False
                # ã¾ãš .ttc ã‚’ã‚µãƒ–ãƒ•ã‚©ãƒ³ãƒˆå«ã‚ã¦è©¦ã™
                for ttc_path in font_paths_ttc:
                    if os.path.exists(ttc_path):
                        name = _try_register_ttc('NotoCJK', ttc_path, max_index=16)
                        if name:
                            self.default_font = name
                            print(f"âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²æˆåŠŸ (TTC): {ttc_path} -> {name}")
                            font_registered = True
                            break
                        else:
                            print(f"âš ï¸ TTCç™»éŒ²å¤±æ•—: {ttc_path}")
                # æ¬¡ã«ã€CIDãƒ•ã‚©ãƒ³ãƒˆï¼ˆçµ„ã¿è¾¼ã¿æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼‰ã‚’å„ªå…ˆã—ã¦è©¦ã™
                if not font_registered:
                    try:
                        from reportlab.pdfbase.cidfonts import UnicodeCIDFont
                        pdfmetrics.registerFont(UnicodeCIDFont('HeiseiKakuGo-W5'))
                        self.default_font = 'HeiseiKakuGo-W5'
                        print("âœ… ReportLabçµ„ã¿è¾¼ã¿æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä½¿ç”¨ (HeiseiKakuGo-W5)")
                        font_registered = True
                    except Exception as e:
                        print(f"âš ï¸ çµ„ã¿è¾¼ã¿CIDãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²å¤±æ•—: {e}")

                # ã¤ãã«å˜ä¸€CJKãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆOTFï¼‰ã‚’è©¦ã™ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
                if not font_registered:
                    for font_path in font_paths_ttf_otf:
                        if os.path.exists(font_path):
                            try:
                                pdfmetrics.registerFont(TTFont('NotoCJK', font_path))
                                self.default_font = 'NotoCJK'
                                print(f"âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²æˆåŠŸ: {font_path}")
                                font_registered = True
                                break
                            except Exception as e:
                                print(f"âš ï¸ ãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²å¤±æ•— {font_path}: {e}")
                                continue
                
                # ãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²ã«å¤±æ•—ã—ãŸå ´åˆã¯ã€ReportLabã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨
                if not font_registered:
                    # æœ€å¾Œã®æ‰‹æ®µã¨ã—ã¦ã€è‹±å­—ãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ï¼ˆæ—¥æœ¬èªã¯è±†è…ã«ãªã‚‹å¯èƒ½æ€§ã‚ã‚Šï¼‰
                    self.default_font = 'Helvetica'
                    print("âš ï¸ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Helveticaã‚’ä¸€æ™‚ä½¿ç”¨ï¼ˆæ—¥æœ¬èªã¯è¡¨ç¤ºä¸å¯ã®å¯èƒ½æ€§ï¼‰")
                    
        except Exception as e:
            print(f"âš ï¸ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.default_font = 'Helvetica'
        
        print(f"ğŸ“ ä½¿ç”¨ãƒ•ã‚©ãƒ³ãƒˆ: {self.default_font}")
    
    def _truncate_text(self, text, max_chars=15):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šæ–‡å­—æ•°ã§åˆ‡ã‚Šè©°ã‚"""
        if not isinstance(text, str):
            text = str(text)
        if pd.isna(text) or text == 'nan':
            return ""
        # æ”¹è¡Œæ–‡å­—ã‚’é™¤å»
        text = text.replace('\n', ' ').replace('\r', ' ')
        # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
        if len(text) <= max_chars:
            return text
        else:
            return text[:max_chars-2] + ".."
    
    def _get_cached_data(self, key):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        with self._cache_lock:
            if key in self._cache:
                self.performance_stats['cache_hits'] += 1
                return self._cache[key]
            else:
                self.performance_stats['cache_misses'] += 1
                return None
    
    def _set_cached_data(self, key, value):
        """ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        with self._cache_lock:
            self._cache[key] = value
    
    def _clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        with self._cache_lock:
            self._cache.clear()
    
    def _measure_time(self, func, *args, **kwargs):
        """é–¢æ•°ã®å®Ÿè¡Œæ™‚é–“ã‚’æ¸¬å®š"""
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        execution_time = end_time - start_time
        return result, execution_time
    
    def _save_temp_results(self, univ_name, results):
        """å¤§å­¦ã”ã¨ã®çµæœã‚’ä¸€æ™‚ä¿å­˜"""
        temp_file = os.path.join(self.temp_dir, f"temp_results_{univ_name}.csv")
        try:
            if results:
                df = pd.DataFrame(results)
                df.to_csv(temp_file, index=False, encoding='utf-8-sig')
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤ï¼ˆé€²æ—ãƒãƒ¼ã®ã¿ã§ååˆ†ï¼‰
        except Exception as e:
            pass  # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚è¡¨ç¤ºã—ãªã„
    
    def _load_temp_results(self, univ_name):
        """å¤§å­¦ã”ã¨ã®çµæœã‚’ä¸€æ™‚ä¿å­˜ã‹ã‚‰èª­ã¿è¾¼ã¿"""
        temp_file = os.path.join(self.temp_dir, f"temp_results_{univ_name}.csv")
        if os.path.exists(temp_file):
            try:
                df = pd.read_csv(temp_file, encoding='utf-8-sig')
                return df.to_dict('records')
            except Exception as e:
                pass
        return None
    
    def _clear_temp_results(self):
        """ä¸€æ™‚ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªã‚¢"""
        try:
            for file in os.listdir(self.temp_dir):
                if file.startswith("temp_results_") and file.endswith(".csv"):
                    os.remove(os.path.join(self.temp_dir, file))
            pass  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ãªã„
        except Exception as e:
            pass  # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚è¡¨ç¤ºã—ãªã„
        
    def login_and_get_tournament_csvs(self, username, password, game_id):
        """ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦å¤§ä¼šã®å…¨CSVã‚’å–å¾—"""
        
        session = requests.Session()
        session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "ja,en-US;q=0.7,en;q=0.3",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1"
        })
        
        try:
            # ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†
            print("ğŸ” ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ä¸­...")
            login_url = f"{self.base_url}/restrict/login"
            login_page = session.get(login_url, timeout=30)
            
            if login_page.status_code != 200:
                print("âŒ ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“")
                return None
            
            soup = BeautifulSoup(login_page.text, "html.parser")
            form = soup.find("form")
            
            if not form:
                print("âŒ ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            # ãƒ­ã‚°ã‚¤ãƒ³å®Ÿè¡Œ
            form_action = f"{self.base_url}/master-admin/login"
            login_data = {"uid": username, "pass": password}
            session.headers.update({"Referer": login_url})
            
            login_response = session.post(form_action, data=login_data, timeout=30)
            
            if "login" in login_response.url.lower():
                print("âŒ ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None
            
            print("âœ… ãƒ­ã‚°ã‚¤ãƒ³ã«æˆåŠŸã—ã¾ã—ãŸï¼")
            
            # å¤§ä¼šCSVå–å¾—
            print(f"ğŸ€ å¤§ä¼šID {game_id} ã®CSVã‚’å–å¾—ä¸­...")
            target_url = f"{self.base_url}/master-admin-game_category_teams/index/search/true/game_category_id/{game_id}"
            
            response = session.get(target_url, timeout=30)
            if response.status_code != 200:
                print(f"âŒ å¤§ä¼šãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code})")
                return None
            
            if "404" in response.text or "Error" in response.text:
                print("âŒ å¤§ä¼šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return None
            
            soup = BeautifulSoup(response.text, "html.parser")
            
            # CSVãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
            csv_links = []
            for a in soup.find_all("a", href=True):
                href = a.get("href")
                if href and "/master-admin-game_category_teams/csv/id/" in href:
                    if href.startswith("/"):
                        full_url = f"{self.base_url}{href}"
                    else:
                        full_url = href
                    csv_links.append(full_url)
            
            print(f"ğŸ“Š {len(csv_links)} ä»¶ã®CSVãƒªãƒ³ã‚¯ã‚’æ¤œå‡º")
            
            if not csv_links:
                print("âš ï¸ CSVãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                print("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
                print(f"ã‚¢ã‚¯ã‚»ã‚¹URL: {target_url}")
                print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")
                
                # ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’ä¸€éƒ¨è¡¨ç¤º
                page_content = response.text[:1000]  # æœ€åˆã®1000æ–‡å­—
                print(f"ãƒšãƒ¼ã‚¸å†…å®¹ï¼ˆæœ€åˆã®1000æ–‡å­—ï¼‰:\n{page_content}")
                
                return None
            
            # CSVã‚’å–å¾—ã—ã¦DataFrameã«å¤‰æ›
            all_universities_data = []
            
            print("ğŸ“Š CSVå–å¾—å‡¦ç†ä¸­...")
            
            for i, csv_url in enumerate(csv_links):
                try:
                    print(f"CSV {i+1}/{len(csv_links)} ã‚’å–å¾—ä¸­...")
                    
                    csv_response = session.get(csv_url, timeout=30)
                    csv_response.raise_for_status()
                    
                    # CSVã‚’DataFrameã«å¤‰æ›ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
                    # ã¾ãšã¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèª
                    response_encoding = csv_response.encoding or 'utf-8'
                    csv_text = csv_response.text
                    
                    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œ
                    try:
                        df = pd.read_csv(StringIO(csv_text))
                    except UnicodeDecodeError:
                        # UTF-8ã§å¤±æ•—ã—ãŸå ´åˆã¯Shift_JISã‚’è©¦è¡Œ
                        try:
                            csv_text = csv_response.content.decode('shift_jis')
                            df = pd.read_csv(StringIO(csv_text))
                        except UnicodeDecodeError:
                            # Shift_JISã§ã‚‚å¤±æ•—ã—ãŸå ´åˆã¯cp932ã‚’è©¦è¡Œ
                            csv_text = csv_response.content.decode('cp932')
                            df = pd.read_csv(StringIO(csv_text))
                    
                    # å¤§å­¦åã‚’å–å¾—ï¼ˆæ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œï¼‰
                    content_disposition = csv_response.headers.get("content-disposition", "")
                    filename_match = re.search(r'filename="(.+)"', content_disposition)
                    
                    if filename_match:
                        # æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä¿®æ­£
                        university_name = filename_match.group(1).replace('.csv', '')
                        try:
                            # URLãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰UTF-8ã§ãƒ‡ã‚³ãƒ¼ãƒ‰
                            import urllib.parse
                            university_name = urllib.parse.unquote(university_name)
                            # ã•ã‚‰ã«ISO-8859-1ã‹ã‚‰UTF-8ã«å¤‰æ›ã‚’è©¦è¡Œ
                            if '\\' in university_name:
                                university_name = university_name.encode('latin-1').decode('utf-8')
                        except:
                            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¤‰æ›ã«å¤±æ•—ã—ãŸå ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
                            pass
                    else:
                        university_name = f"å¤§å­¦_{i+1}"
                    
                    # å¤§å­¦åã‚’DataFrameã«è¿½åŠ 
                    df['å¤§å­¦å'] = university_name
                    all_universities_data.append(df)
                    
                    print(f"âœ… CSV {i+1} å–å¾—æˆåŠŸ")
                    # Sleep removed  # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›
                    
                except Exception as e:
                    print(f"âš ï¸ CSV {i+1} ã®å–å¾—ã«å¤±æ•—: {str(e)}")
                    continue
            
            print("âœ… CSVå–å¾—å®Œäº†")
            
            if all_universities_data:
                # å…¨å¤§å­¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
                combined_df = pd.concat(all_universities_data, ignore_index=True)
                print(f"âœ… {len(all_universities_data)} å¤§å­¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
                return combined_df
            else:
                return None
                
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def process_tournament_data(self, df, university_name=None):
        """å¤§ä¼šãƒ‡ãƒ¼ã‚¿ã‚’JBAç…§åˆã§å‡¦ç†ï¼ˆä¸¦åˆ—å‡¦ç†å¯¾å¿œï¼‰"""
        
        if df is None or df.empty:
            print("âŒ å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        if self.use_parallel:
            print(f"âš¡ ä¸¦åˆ—å‡¦ç†ã‚’ä½¿ç”¨ï¼ˆ{self.max_workers}ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰")
            return self._process_tournament_data_parallel(df, university_name)
        else:
            print("ğŸ”„ é †æ¬¡å‡¦ç†ã‚’ä½¿ç”¨")
            return self._process_tournament_data_sequential(df, university_name)
    
    def _process_tournament_data_sequential(self, df, university_name=None):
        """é †æ¬¡å‡¦ç†ã§JBAç…§åˆ"""
        print("ğŸ” JBAç…§åˆå‡¦ç†ã‚’é–‹å§‹...")
        
        # å¤§å­¦ã”ã¨ã«å‡¦ç†
        universities = df['å¤§å­¦å'].unique() if 'å¤§å­¦å' in df.columns else [university_name or "Unknown"]
        
        all_results = []
        
        for univ in universities:
            print(f"ğŸ« {univ} ã‚’å‡¦ç†ä¸­...")
            
            # å¤§å­¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            if 'å¤§å­¦å' in df.columns:
                univ_data = df[df['å¤§å­¦å'] == univ].copy()
            else:
                univ_data = df.copy()
            
            # JBAç…§åˆå‡¦ç†
            results = []
            
            for index, row in univ_data.iterrows():
                # é¸æ‰‹åã‚’å–å¾—
                player_name = None
                name_columns = ['é¸æ‰‹å', 'æ°å', 'name', 'Name']
                
                for col in name_columns:
                    if col in univ_data.columns and pd.notna(row[col]):
                        player_name = str(row[col]).strip()
                        break
                
                if not player_name:
                    results.append({
                        'index': index,
                        'original_data': row.to_dict(),
                        'status': 'missing_data',
                        'message': 'é¸æ‰‹åãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ',
                        'correction': None
                    })
                    continue
                
                # JBAç…§åˆ
                verification_result = self.jba_system.verify_player_info(
                    player_name, None, univ, get_details=True, threshold=1.0
                )
                
                result = {
                    'index': index,
                    'original_data': row.to_dict(),
                    'verification_result': verification_result,
                    'status': verification_result['status'],
                    'university': univ
                }
                
                # å®Œå…¨ä¸€è‡´ã®å ´åˆ
                if verification_result['status'] == 'match':
                    if 'jba_data' in verification_result:
                        jba_data = verification_result['jba_data']
                        is_valid, validation_issues, school_corrections = self.validator.validate_player_data(jba_data)
                        
                        corrected_data = row.to_dict().copy()
                        
                        # JBAæƒ…å ±ã‚’è¿½åŠ 
                        if 'height' in jba_data and jba_data['height']:
                            corrected_data['èº«é•·'] = f"{jba_data['height']}cm"
                        if 'weight' in jba_data and jba_data['weight']:
                            corrected_data['ä½“é‡'] = f"{jba_data['weight']}kg"
                        if 'position' in jba_data and jba_data['position']:
                            corrected_data['ãƒã‚¸ã‚·ãƒ§ãƒ³'] = jba_data['position']
                        if 'school' in jba_data and jba_data['school']:
                            if 'school' in school_corrections:
                                corrected_data['å‡ºèº«æ ¡'] = school_corrections['school']
                            else:
                                corrected_data['å‡ºèº«æ ¡'] = jba_data['school']
                        if 'grade' in jba_data and jba_data['grade']:
                            corrected_data['å­¦å¹´'] = jba_data['grade']
                        if 'uniform_number' in jba_data and jba_data['uniform_number']:
                            corrected_data['èƒŒç•ªå·'] = jba_data['uniform_number']
                        
                        result['correction'] = corrected_data
                        
                        if not is_valid:
                            result['validation_issues'] = validation_issues
                            result['message'] = f'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´ï¼ˆè©³ç´°æƒ…å ±è¿½åŠ ï¼‰âš ï¸ ç•°å¸¸å€¤æ¤œå‡º: {", ".join(validation_issues)}'
                        else:
                            result['message'] = 'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´ï¼ˆè©³ç´°æƒ…å ±è¿½åŠ ï¼‰'
                    else:
                        result['correction'] = None
                        result['message'] = 'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´'
                
                # éƒ¨åˆ†ä¸€è‡´ã®å ´åˆ
                elif verification_result['status'] == 'partial_match':
                    jba_data = verification_result['jba_data']
                    similarity = verification_result.get('similarity', 0.0)
                    
                    corrected_data = row.to_dict().copy()
                    
                    if 'height' in jba_data and jba_data['height']:
                        corrected_data['èº«é•·'] = f"{jba_data['height']}cm"
                    if 'weight' in jba_data and jba_data['weight']:
                        corrected_data['ä½“é‡'] = f"{jba_data['weight']}kg"
                    if 'position' in jba_data and jba_data['position']:
                        corrected_data['ãƒã‚¸ã‚·ãƒ§ãƒ³'] = jba_data['position']
                    if 'school' in jba_data and jba_data['school']:
                        corrected_data['å‡ºèº«æ ¡'] = jba_data['school']
                    if 'grade' in jba_data and jba_data['grade']:
                        corrected_data['å­¦å¹´'] = jba_data['grade']
                    if 'uniform_number' in jba_data and jba_data['uniform_number']:
                        corrected_data['èƒŒç•ªå·'] = jba_data['uniform_number']
                    
                    result['correction'] = corrected_data
                    result['message'] = f"éƒ¨åˆ†ä¸€è‡´: {jba_data['name']} (é¡ä¼¼åº¦: {similarity:.3f}) - æ‰‹å‹•ç¢ºèªæ¨å¥¨"
                
                # ä¸€è‡´ãªã—ã®å ´åˆ
                else:
                    result['correction'] = None
                    result['message'] = verification_result.get('message', 'ç…§åˆã§ãã¾ã›ã‚“ã§ã—ãŸ')
                
                results.append(result)
            
            all_results.extend(results)
        
        # çµæœã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«è¡¨ç¤º
        print(f"ğŸ“Š å‡¦ç†çµæœ: {len(all_results)}é¸æ‰‹")
        print(f"ğŸ“Š å‡¦ç†å¤§å­¦æ•°: {len(universities)}")
        
        return all_results
    
    def _process_tournament_data_parallel(self, df, university_name=None):
        """ä¸¦åˆ—å‡¦ç†ã§JBAç…§åˆ"""
        import concurrent.futures
        import time
        
        # JBAç…§åˆå‡¦ç†ã‚’é–‹å§‹ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’ãƒªã‚»ãƒƒãƒˆ
        self.performance_stats = {
            'total_time': 0,
            'io_time': 0,
            'processing_time': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'requests_count': 0,
            'avg_response_time': 0
        }
        
        # å¤§å­¦ã”ã¨ã«å‡¦ç†
        universities = df['å¤§å­¦å'].unique() if 'å¤§å­¦å' in df.columns else [university_name or "Unknown"]
        
        all_results = []
        # Progress bar removed - use update_job_progress() instead
        # status_text = st.empty() removed
        
        start_time = time.time()
        total_players = len(df)
        processed = 0
        
        # å…¨é¸æ‰‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆPandasæœ€é©åŒ–ï¼‰
        player_data = []
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ã§é¸æ‰‹åã‚’ä¸€æ‹¬å–å¾—
        name_columns = ['é¸æ‰‹å', 'æ°å', 'name', 'Name']
        available_name_cols = [col for col in name_columns if col in df.columns]
        
        if available_name_cols:
            # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸåå‰ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨
            name_col = available_name_cols[0]
            df[name_col] = df[name_col].astype(str).str.strip()
            
            # å¤§å­¦ã”ã¨ã«å‡¦ç†
            for univ in universities:
                if 'å¤§å­¦å' in df.columns:
                    univ_data = df[df['å¤§å­¦å'] == univ].copy()
                else:
                    univ_data = df.copy()
                
                # æœ‰åŠ¹ãªé¸æ‰‹åã®ã¿ã‚’æŠ½å‡º
                valid_players = univ_data[pd.notna(univ_data[name_col]) & (univ_data[name_col] != '')]
                
                for index, row in valid_players.iterrows():
                    player_name = str(row[name_col]).strip()
                    if player_name:
                        player_data.append((index, row, univ, player_name))
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®æ–¹æ³•
            for univ in universities:
                if 'å¤§å­¦å' in df.columns:
                    univ_data = df[df['å¤§å­¦å'] == univ].copy()
                else:
                    univ_data = df.copy()
                
                for index, row in univ_data.iterrows():
                    player_name = None
                    for col in name_columns:
                        if col in univ_data.columns and pd.notna(row[col]):
                            player_name = str(row[col]).strip()
                            break
                    
                    if player_name:
                        player_data.append((index, row, univ, player_name))
        
        # ä¸¦åˆ—å‡¦ç†ã§JBAç…§åˆï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’å‹•çš„èª¿æ•´ï¼‰
        optimal_workers = min(self.max_workers, len(player_data), 20)
        
        # å¤§å­¦ã”ã¨ã®çµæœã‚’ä¸€æ™‚ä¿å­˜
        university_results = {}
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=optimal_workers) as executor:
            futures = []
            
            for index, row, univ, player_name in player_data:
                future = executor.submit(self._process_single_player_parallel, 
                                       index, row, univ, player_name)
                futures.append(future)
            
            # çµæœã‚’åé›†
            for future in concurrent.futures.as_completed(futures):
                try:
                    result = future.result()
                    all_results.append(result)
                    processed += 1
                    
                    # å¤§å­¦ã”ã¨ã®çµæœã‚’ä¸€æ™‚ä¿å­˜
                    univ = result.get('university', 'Unknown')
                    if univ not in university_results:
                        university_results[univ] = []
                    university_results[univ].append(result)
                    
                    # é€²æ—æ›´æ–°ï¼ˆ10é¸æ‰‹ã”ã¨ï¼‰
                    if processed % 10 == 0 or processed == total_players:
                        progress = processed / total_players
                        # Progress update - use update_job_progress(job_id, )
                        # status update removed - use update_job_message()}")
                        
                        # å¤§å­¦ã”ã¨ã®çµæœã‚’ä¸€æ™‚ä¿å­˜ï¼ˆ10é¸æ‰‹ã”ã¨ï¼‰
                        if processed % 10 == 0:
                            for univ_name, univ_results in university_results.items():
                                self._save_temp_results(univ_name, univ_results)
                    
                except Exception as e:
                    logging.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", exc_info=True)
        
        # æœ€çµ‚çš„ãªä¸€æ™‚ä¿å­˜
        for univ_name, univ_results in university_results.items():
            self._save_temp_results(univ_name, univ_results)
        
        elapsed_time = time.time() - start_time
        self.performance_stats['total_time'] = elapsed_time
        
        # çµæœã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«è¡¨ç¤º (Streamlit removed)
        # Metrics removed
        
        # ä¸¦åˆ—å‡¦ç†å®Œäº†
        
        return all_results
    
    def _process_single_player_parallel(self, index, row, univ, player_name):
        """å˜ä¸€é¸æ‰‹ã®ä¸¦åˆ—å‡¦ç†ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ
        cache_key = f"player_{player_name}_{univ}"
        cached_result = self._get_cached_data(cache_key)
        
        if cached_result:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
            cached_result['index'] = index
            cached_result['original_data'] = row.to_dict()
            return cached_result
        
        # å®Ÿéš›ã«JBAç…§åˆã‚’å®Ÿè¡Œ
        start_time = time.time()
        verification_result = self.jba_system.verify_player_info(
            player_name, None, univ, get_details=True, threshold=1.0
        )
        end_time = time.time()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’æ›´æ–°
        self.performance_stats['requests_count'] += 1
        response_time = end_time - start_time
        self.performance_stats['avg_response_time'] = (
            (self.performance_stats['avg_response_time'] * (self.performance_stats['requests_count'] - 1) + response_time) 
            / self.performance_stats['requests_count']
        )
        
        result = {
            'index': index,
            'original_data': row.to_dict(),
            'verification_result': verification_result,
            'status': verification_result['status'],
            'university': univ
        }
        
        # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        self._set_cached_data(cache_key, result)
        
        return result
    
    def create_university_reports(self, results):
        """å¤§å­¦ã”ã¨ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
        
        if not results:
            # å‡¦ç†çµæœãŒã‚ã‚Šã¾ã›ã‚“
            return None
        
        # å¤§å­¦ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        universities = {}
        for result in results:
            univ = result.get('university', 'Unknown')
            if univ not in universities:
                universities[univ] = []
            universities[univ].append(result)
        
        reports = {}
        
        for univ, univ_results in universities.items():
            # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
            total_players = len(univ_results)
            match_count = len([r for r in univ_results if r['status'] == 'match'])
            partial_match_count = len([r for r in univ_results if r['status'] == 'partial_match'])
            not_found_count = len([r for r in univ_results if r['status'] == 'not_found'])
            
            # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            report_data = {
                'university': univ,
                'total_players': total_players,
                'match_count': match_count,
                'partial_match_count': partial_match_count,
                'not_found_count': not_found_count,
                'match_rate': (match_count / total_players * 100) if total_players > 0 else 0,
                'results': univ_results
            }
            
            reports[univ] = report_data
        
        return reports
    
    def _generate_university_report(self, university_name, report):
        """å˜ä¸€å¤§å­¦ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        html_content = f"""
        <html>
        <head>
            <title>{university_name} é¸æ‰‹ãƒ‡ãƒ¼ã‚¿</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ text-align: center; margin-bottom: 30px; }}
                .stats {{ display: flex; justify-content: space-around; margin-bottom: 30px; }}
                .stat-box {{ text-align: center; padding: 10px; border: 1px solid #ccc; }}
                table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
                th, td {{ border: 1px solid #ccc; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
                .page-break {{ page-break-before: always; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>{university_name} é¸æ‰‹ãƒ‡ãƒ¼ã‚¿</h1>
                <p>ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}</p>
            </div>
            
            <div class="stats">
                <div class="stat-box">
                    <h3>ç·é¸æ‰‹æ•°</h3>
                    <p>{report['total_players']}</p>
                </div>
                <div class="stat-box">
                    <h3>å®Œå…¨ä¸€è‡´</h3>
                    <p>{report['match_count']}</p>
                </div>
                <div class="stat-box">
                    <h3>éƒ¨åˆ†ä¸€è‡´</h3>
                    <p>{report['partial_match_count']}</p>
                </div>
                <div class="stat-box">
                    <h3>æœªç™ºè¦‹</h3>
                    <p>{report['not_found_count']}</p>
                </div>
                <div class="stat-box">
                    <h3>ä¸€è‡´ç‡</h3>
                    <p>{report['match_rate']:.1f}%</p>
                </div>
            </div>
            
            <h2>é¸æ‰‹è©³ç´°ãƒ‡ãƒ¼ã‚¿</h2>
            <table>
                <tr>
                    <th>é¸æ‰‹å</th>
                    <th>èº«é•·</th>
                    <th>ä½“é‡</th>
                    <th>ãƒã‚¸ã‚·ãƒ§ãƒ³</th>
                    <th>å‡ºèº«æ ¡</th>
                    <th>å­¦å¹´</th>
                    <th>èƒŒç•ªå·</th>
                    <th>ç…§åˆçµæœ</th>
                </tr>
        """
        
        for result in report['results']:
            data = result['original_data']
            message = result.get('message', '')
            
            html_content += f"""
                <tr>
                    <td>{data.get('é¸æ‰‹å', data.get('æ°å', ''))}</td>
                    <td>{data.get('èº«é•·', '')}</td>
                    <td>{data.get('ä½“é‡', '')}</td>
                    <td>{data.get('ãƒã‚¸ã‚·ãƒ§ãƒ³', '')}</td>
                    <td>{data.get('å‡ºèº«æ ¡', '')}</td>
                    <td>{data.get('å­¦å¹´', '')}</td>
                    <td>{data.get('èƒŒç•ªå·', '')}</td>
                    <td>{message}</td>
                </tr>
            """
        
        html_content += """
            </table>
        </body>
        </html>
        """
        
        return html_content
    
    def _generate_all_universities_report(self, reports):
        """å…¨å¤§å­¦ã®ä¸€æ‹¬ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        html_content = f"""
        <html>
        <head>
            <title>å…¨å¤§å­¦é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ä¸€è¦§</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ text-align: center; margin-bottom: 30px; }}
                .university-section {{ margin-bottom: 50px; page-break-before: always; }}
                .university-section:first-child {{ page-break-before: auto; }}
                .stats {{ display: flex; justify-content: space-around; margin-bottom: 30px; }}
                .stat-box {{ text-align: center; padding: 10px; border: 1px solid #ccc; }}
                table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
                th, td {{ border: 1px solid #ccc; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
                .university-title {{ background-color: #4CAF50; color: white; padding: 15px; text-align: center; font-size: 18px; font-weight: bold; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>å…¨å¤§å­¦é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ä¸€è¦§</h1>
                <p>ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}</p>
                <p>ç·å¤§å­¦æ•°: {len(reports)} å¤§å­¦</p>
            </div>
        """
        
        # å…¨å¤§å­¦ã®çµ±è¨ˆæƒ…å ±
        total_players = sum(report['total_players'] for report in reports.values())
        total_matches = sum(report['match_count'] for report in reports.values())
        total_partial = sum(report['partial_match_count'] for report in reports.values())
        total_not_found = sum(report['not_found_count'] for report in reports.values())
        overall_match_rate = (total_matches / total_players * 100) if total_players > 0 else 0
        
        html_content += f"""
            <div class="stats">
                <div class="stat-box">
                    <h3>ç·é¸æ‰‹æ•°</h3>
                    <p>{total_players}</p>
                </div>
                <div class="stat-box">
                    <h3>å®Œå…¨ä¸€è‡´</h3>
                    <p>{total_matches}</p>
                </div>
                <div class="stat-box">
                    <h3>éƒ¨åˆ†ä¸€è‡´</h3>
                    <p>{total_partial}</p>
                </div>
                <div class="stat-box">
                    <h3>æœªç™ºè¦‹</h3>
                    <p>{total_not_found}</p>
                </div>
                <div class="stat-box">
                    <h3>å…¨ä½“ä¸€è‡´ç‡</h3>
                    <p>{overall_match_rate:.1f}%</p>
                </div>
            </div>
        """
        
        # å„å¤§å­¦ã®ãƒ‡ãƒ¼ã‚¿
        for univ_name, report in reports.items():
            html_content += f"""
                <div class="university-section">
                    <div class="university-title">{univ_name}</div>
                    
                    <div class="stats">
                        <div class="stat-box">
                            <h4>ç·é¸æ‰‹æ•°</h4>
                            <p>{report['total_players']}</p>
                        </div>
                        <div class="stat-box">
                            <h4>å®Œå…¨ä¸€è‡´</h4>
                            <p>{report['match_count']}</p>
                        </div>
                        <div class="stat-box">
                            <h4>éƒ¨åˆ†ä¸€è‡´</h4>
                            <p>{report['partial_match_count']}</p>
                        </div>
                        <div class="stat-box">
                            <h4>æœªç™ºè¦‹</h4>
                            <p>{report['not_found_count']}</p>
                        </div>
                        <div class="stat-box">
                            <h4>ä¸€è‡´ç‡</h4>
                            <p>{report['match_rate']:.1f}%</p>
                        </div>
                    </div>
                    
                    <h3>é¸æ‰‹è©³ç´°ãƒ‡ãƒ¼ã‚¿</h3>
                    <table>
                        <tr>
                            <th>é¸æ‰‹å</th>
                            <th>èº«é•·</th>
                            <th>ä½“é‡</th>
                            <th>ãƒã‚¸ã‚·ãƒ§ãƒ³</th>
                            <th>å‡ºèº«æ ¡</th>
                            <th>å­¦å¹´</th>
                            <th>èƒŒç•ªå·</th>
                            <th>ç…§åˆçµæœ</th>
                        </tr>
            """
            
            for result in report['results']:
                data = result['original_data']
                message = result.get('message', '')
                
                html_content += f"""
                    <tr>
                        <td>{data.get('é¸æ‰‹å', data.get('æ°å', ''))}</td>
                        <td>{data.get('èº«é•·', '')}</td>
                        <td>{data.get('ä½“é‡', '')}</td>
                        <td>{data.get('ãƒã‚¸ã‚·ãƒ§ãƒ³', '')}</td>
                        <td>{data.get('å‡ºèº«æ ¡', '')}</td>
                        <td>{data.get('å­¦å¹´', '')}</td>
                        <td>{data.get('èƒŒç•ªå·', '')}</td>
                        <td>{message}</td>
                    </tr>
                """
            
            html_content += """
                    </table>
                </div>
            """
        
        html_content += """
        </body>
        </html>
        """
        
        return html_content
    
    def display_university_report(self, selected_univ, report, game_id, reports):
        """å¤§å­¦åˆ¥ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º"""
        # Markdown removed
        
        # Streamlit UI å‰Šé™¤æ¸ˆã¿: ä½•ã‚‚ã—ãªã„
        return None

    def export_all_university_reports_as_pdf(self, reports, output_path="all_universities_report.pdf", max_rows_per_page=100):
        """å…¨å¤§å­¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªPDFã§å‡ºåŠ›ï¼ˆç”»åƒã®å½¢å¼ã«æº–æ‹ ï¼‰"""
        # A4ç¸¦å‘ãã§ä½œæˆ
        doc = SimpleDocTemplate(output_path, pagesize=A4, 
                               leftMargin=8*mm, rightMargin=8*mm,
                               topMargin=10*mm, bottomMargin=10*mm)
        styles = getSampleStyleSheet()
        elements = []
        
        # ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆè¶…ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆï¼‰
        compact_style = ParagraphStyle(
            'Compact',
            parent=styles['Normal'],
            fontSize=6,
            leading=6,  # è¡Œé–“ã‚’ã•ã‚‰ã«ç¸®å°
            fontName=getattr(self, 'default_font', 'MS-Gothic')
        )
        
        title_style = ParagraphStyle(
            'TitleCompact',
            parent=styles['Title'],
            fontSize=8,
            leading=9,  # è¡Œé–“ã‚’ã•ã‚‰ã«ç¸®å°
            fontName=getattr(self, 'default_font', 'MS-Gothic')
        )
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ï¼ˆæœ€å°é™ï¼‰
        elements.append(Paragraph("ğŸ€ å…¨å¤§å­¦é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ä¸€è¦§", title_style))
        elements.append(Spacer(1, 1))  # ã‚¹ãƒšãƒ¼ã‚¹ã‚’æœ€å°é™ã«
        
        # å„å¤§å­¦ã®ãƒ¬ãƒãƒ¼ãƒˆï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªè¡¨å½¢å¼ï¼‰
        for i, (univ_name, report) in enumerate(reports.items()):
            # å¤§å­¦åãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆæœ€å°é™ï¼‰
            univ_header = f"ã€{univ_name}ã€‘"
            elements.append(Paragraph(univ_header, compact_style))
            elements.append(Spacer(1, 1))  # ã‚¹ãƒšãƒ¼ã‚¹ã‚’æœ€å°é™ã«
            
            # é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ã‚’ãƒšãƒ¼ã‚¸ãƒ³ã‚°
            results = report["results"]
            total_pages = (len(results) + max_rows_per_page - 1) // max_rows_per_page
            
            for page_num in range(total_pages):
                start_idx = page_num * max_rows_per_page
                end_idx = min(start_idx + max_rows_per_page, len(results))
                page_results = results[start_idx:end_idx]
                
                # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆç”»åƒã®å½¢å¼ã«æº–æ‹ ï¼‰
                data = [["No", "é¸æ‰‹å", "ã‚«ãƒŠå", "å­¦éƒ¨", "å­¦å¹´", "èº«é•·", "ä½“é‡", "ãƒã‚¸ã‚·ãƒ§ãƒ³", "å‡ºèº«æ ¡", "JBA"]]
                
                for idx, r in enumerate(page_results, start=start_idx+1):
                    d = r["original_data"]
                    status = r.get("status", "unknown")
                    
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¨˜å·
                    if status == "match":
                        status_symbol = "âœ“"
                    elif status == "partial_match":
                        status_symbol = "â–³"
                    elif status == "not_found":
                        status_symbol = "Ã—"
                    else:
                        status_symbol = "-"
                    
                    # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’ä½œæˆï¼ˆç”»åƒã®åˆ—æ§‹æˆã«æº–æ‹ ï¼‰
                    # å¤‰æ›´ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’èµ¤å­—ã§è¡¨ç¤º
                    no = d.get("No", d.get("èƒŒç•ªå·", ""))
                    player_name = d.get("é¸æ‰‹å", d.get("æ°å", ""))
                    kana_name = d.get("ã‚«ãƒŠå", "")
                    department = d.get("å­¦éƒ¨", "")
                    grade = d.get("å­¦å¹´", "")
                    height = d.get("èº«é•·", "")
                    weight = d.get("ä½“é‡", "")
                    position = d.get("ãƒã‚¸ã‚·ãƒ§ãƒ³", "")
                    school = d.get("å‡ºèº«æ ¡", "")
                    
                    # å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã¯èµ¤å­—ã§è¡¨ç¤º
                    if r.get("correction"):
                        corrected_data = r["correction"]
                        if corrected_data.get("No") != no:
                            no = f'<font color="red">{corrected_data.get("No", no)}</font>'
                        if corrected_data.get("é¸æ‰‹å") != player_name:
                            player_name = f'<font color="red">{corrected_data.get("é¸æ‰‹å", player_name)}</font>'
                        if corrected_data.get("ã‚«ãƒŠå") != kana_name:
                            kana_name = f'<font color="red">{corrected_data.get("ã‚«ãƒŠå", kana_name)}</font>'
                        if corrected_data.get("å­¦éƒ¨") != department:
                            department = f'<font color="red">{corrected_data.get("å­¦éƒ¨", department)}</font>'
                        if corrected_data.get("å­¦å¹´") != grade:
                            grade = f'<font color="red">{corrected_data.get("å­¦å¹´", grade)}</font>'
                        if corrected_data.get("èº«é•·") != height:
                            height = f'<font color="red">{corrected_data.get("èº«é•·", height)}</font>'
                        if corrected_data.get("ä½“é‡") != weight:
                            weight = f'<font color="red">{corrected_data.get("ä½“é‡", weight)}</font>'
                        if corrected_data.get("ãƒã‚¸ã‚·ãƒ§ãƒ³") != position:
                            position = f'<font color="red">{corrected_data.get("ãƒã‚¸ã‚·ãƒ§ãƒ³", position)}</font>'
                        if corrected_data.get("å‡ºèº«æ ¡") != school:
                            school = f'<font color="red">{corrected_data.get("å‡ºèº«æ ¡", school)}</font>'
                    
                    row_data = [
                        self._truncate_text(no, 3),  # No
                        self._truncate_text(player_name, 8),  # é¸æ‰‹å
                        self._truncate_text(kana_name, 8),  # ã‚«ãƒŠå
                        self._truncate_text(department, 6),  # å­¦éƒ¨
                        self._truncate_text(grade, 3),  # å­¦å¹´
                        self._truncate_text(height, 5),  # èº«é•·
                        self._truncate_text(weight, 4),  # ä½“é‡
                        self._truncate_text(position, 6),  # ãƒã‚¸ã‚·ãƒ§ãƒ³
                        self._truncate_text(school, 10),  # å‡ºèº«æ ¡
                        status_symbol  # JBAç™»éŒ²çŠ¶æ³
                    ]
                    
                    data.append(row_data)
                
                # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆï¼ˆA4ç¸¦å‘ãæœ€é©åŒ–ï¼‰
                col_widths = [8*mm, 18*mm, 18*mm, 12*mm, 8*mm, 10*mm, 8*mm, 12*mm, 20*mm, 8*mm]
                
                # è¡Œã®é«˜ã•ã‚’å›ºå®šã§è¨­å®šï¼ˆfinal_100_output.pdfã¨åŒã˜è¨­å®šï¼‰
                row_heights = [10] + [7] * (len(data) - 1)  # ãƒ˜ãƒƒãƒ€ãƒ¼10ptã€ãƒ‡ãƒ¼ã‚¿è¡Œ7pt
                
                table = Table(data, colWidths=col_widths, rowHeights=row_heights, repeatRows=1)
                table.setStyle(TableStyle([
                # ãƒ˜ãƒƒãƒ€ãƒ¼
                ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor('#4472C4')),
                ("TEXTCOLOR", (0, 0), (-1, 0), colors.whitesmoke),
                ("ALIGN", (0, 0), (-1, -1), "CENTER"),
                ("VALIGN", (0, 0), (-1, -1), "TOP"),  # ä¸Šæƒãˆã«å¤‰æ›´
                ("FONTNAME", (0, 0), (-1, 0), getattr(self, 'default_font', 'MS-Gothic')),
                ("FONTSIZE", (0, 0), (-1, 0), 5),  # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºï¼ˆfinal_100_outputã¨åŒã˜ï¼‰
                ("BOTTOMPADDING", (0, 0), (-1, 0), 2),  # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆfinal_100_outputã¨åŒã˜ï¼‰
                
                # ãƒ‡ãƒ¼ã‚¿è¡Œ
                ("FONTNAME", (0, 1), (-1, -1), getattr(self, 'default_font', 'MS-Gothic')),
                ("FONTSIZE", (0, 1), (-1, -1), 4),  # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºï¼ˆfinal_100_outputã¨åŒã˜ï¼‰
                ("ROWBACKGROUNDS", (0, 1), (-1, -1), [colors.white, colors.HexColor('#F2F2F2')]),
                
                # ç½«ç·š
                ("GRID", (0, 0), (-1, -1), 0.3, colors.grey),  # ç½«ç·šã‚’ç´°ã
                ("LINEBELOW", (0, 0), (-1, 0), 1, colors.black),
                    
                # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°èª¿æ•´ï¼ˆæ–‡å­—ãŒãƒ†ãƒ¼ãƒ–ãƒ«å†…ã«æ­£ã—ãé…ç½®ã•ã‚Œã‚‹ã‚ˆã†ã«ï¼‰
                ("TOPPADDING", (0, 1), (-1, -1), 1),  # ä¸Šéƒ¨ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’å°‘ã—è¿½åŠ 
                ("BOTTOMPADDING", (0, 1), (-1, -1), 1),  # ä¸‹éƒ¨ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’å°‘ã—è¿½åŠ 
                ("LEFTPADDING", (0, 0), (-1, -1), 1),  # å·¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’å°‘ã—è¿½åŠ 
                ("RIGHTPADDING", (0, 0), (-1, -1), 1),  # å³ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’å°‘ã—è¿½åŠ 
                ]))
                
                elements.append(table)
                
                # ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Šï¼ˆæœ€å¾Œã®ãƒšãƒ¼ã‚¸ä»¥å¤–ï¼‰
                if page_num < total_pages - 1:
                    elements.append(Spacer(1, 5))  # ã‚¹ãƒšãƒ¼ã‚¹ã‚’å‰Šæ¸›
                    page_info = f"(ãƒšãƒ¼ã‚¸ {page_num+1}/{total_pages})"
                    elements.append(Paragraph(page_info, compact_style))
                    elements.append(PageBreak())
            
            # å¤§å­¦åŒºåˆ‡ã‚Šï¼ˆæœ€å¾Œã®å¤§å­¦ä»¥å¤–ï¼‰
            if i < len(reports) - 1:
                elements.append(PageBreak())
        
        # PDFç”Ÿæˆ
        doc.build(elements)
        print(f"ğŸ“„ PDFç”Ÿæˆå®Œäº†: {output_path} (ãƒ•ã‚©ãƒ³ãƒˆ: {getattr(self, 'default_font', 'Unknown')})")
        return output_path
    
    def start_pdf_generation_background(self, reports, output_filename=None):
        """reports ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§PDFåŒ–ã™ã‚‹ã‚¸ãƒ§ãƒ–ã‚’é–‹å§‹ã™ã‚‹ï¼ˆåˆ¥ãƒ—ãƒ­ã‚»ã‚¹ç‰ˆï¼‰ã€‚"""
        if output_filename is None:
            output_filename = os.path.join(self.temp_dir, f"all_universities_report_{int(time.time())}.zip")
        job_id = str(uuid.uuid4())
        job_meta = {
            "job_id": job_id,
            "status": "queued",
            "progress": 0.0,
            "message": "queued",
            "output_path": output_filename,
            "error": None,
            "created_at": datetime.utcnow().isoformat() + "Z"
        }
        job_meta_path = os.path.join(self.temp_dir, f"pdf_job_{job_id}.json")
        with open(job_meta_path, "w", encoding="utf-8") as f:
            json.dump(job_meta, f, ensure_ascii=False, indent=2)

        # --- å®‰å…¨å¯¾ç­–: reports ã‚’ãƒ—ãƒªã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºï¼ˆpickle ã§ã®ä¸æ•´åˆã‚’é¿ã‘ã‚‹ï¼‰ ---
        try:
            serializable_reports = json.loads(json.dumps(reports, default=str))
        except Exception:
            # æœ€ä½é™: æ–‡å­—åˆ—åŒ–ã«å¤±æ•—ã—ãŸã‚‰ãã®ã¾ã¾æ¸¡ã™ï¼ˆpickle ã«ä»»ã›ã‚‹ï¼‰
            serializable_reports = reports

        # --- spawn ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ—ãƒ­ã‚»ã‚¹ã‚’ä½œæˆï¼ˆãƒ¯ãƒ¼ã‚«ãƒ¼æœªæä¾›ãªã‚‰åŒæœŸç”Ÿæˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ ---
        if pdf_worker_main is None:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŒæœŸã§PDFç”Ÿæˆã‚’å®Ÿè¡Œï¼ˆæœ€ä½é™ã®å‹•ä½œç¢ºä¿ï¼‰
            try:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦å…¨å¤§å­¦PDFã‚’å˜ç™ºç”Ÿæˆï¼ˆreports æ§‹é€ ã«ä¾å­˜ï¼‰
                output_pdf = output_filename if output_filename.endswith('.pdf') else output_filename.replace('.zip', '.pdf')
                self.export_all_university_reports_as_pdf(reports=reports, output_path=output_pdf)
                self._write_job_meta(job_meta_path, status="done", progress=1.0, message="PDF generated (fallback)", output_path=output_pdf)
            except Exception as e:
                self._write_job_meta(job_meta_path, status="error", message=f"Fallback PDF generation failed: {e}", error=str(e))
                raise
        else:
            try:
                ctx = multiprocessing.get_context("spawn")
                proc = ctx.Process(
                    target=pdf_worker_main,
                    args=(serializable_reports, output_filename, job_meta_path),
                    daemon=False
                )
                proc.start()
            except Exception as e:
                # å¤±æ•—ã—ãŸã‚‰ job_meta ã«ã‚¨ãƒ©ãƒ¼ã‚’æ›¸ãè¾¼ã‚€
                self._write_job_meta(job_meta_path, status="error", message=f"Failed to start worker: {e}", error=str(e))
                raise

        return job_meta_path

    def _write_job_meta(self, job_meta_path, **kwargs):
        """job_meta JSON ã‚’ä¸Šæ›¸ãæ›´æ–°"""
        try:
            # read existing
            meta = {}
            if os.path.exists(job_meta_path):
                with open(job_meta_path, "r", encoding="utf-8") as f:
                    meta = json.load(f)
            meta.update(kwargs)
            with open(job_meta_path, "w", encoding="utf-8") as f:
                json.dump(meta, f, ensure_ascii=False, indent=2)
        except Exception as e:
            # ãƒ­ã‚®ãƒ³ã‚°ã®ã¿
            print(f"Failed to write job meta: {e}")

    
    def export_single_university_report_as_pdf(self, university_name, report, output_path=None):
        """å˜ä¸€å¤§å­¦ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’PDFå‡ºåŠ›"""
        if output_path is None:
            output_path = f"{university_name}_é¸æ‰‹ãƒ‡ãƒ¼ã‚¿.pdf"
        
        doc = SimpleDocTemplate(output_path, pagesize=A4)
        styles = getSampleStyleSheet()
        elements = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
        elements.append(Paragraph(f"ğŸ« {university_name} é¸æ‰‹ãƒ‡ãƒ¼ã‚¿", styles["Title"]))
        elements.append(Paragraph(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}", styles["Normal"]))
        elements.append(Spacer(1, 20))
        
        # çµ±è¨ˆæƒ…å ±
        elements.append(Paragraph("ğŸ“Š çµ±è¨ˆæƒ…å ±", styles["Heading2"]))
        elements.append(Paragraph(f"ç·é¸æ‰‹æ•°: {report['total_players']}", styles["Normal"]))
        elements.append(Paragraph(f"å®Œå…¨ä¸€è‡´: {report['match_count']}", styles["Normal"]))
        elements.append(Paragraph(f"éƒ¨åˆ†ä¸€è‡´: {report['partial_match_count']}", styles["Normal"]))
        elements.append(Paragraph(f"æœªç™ºè¦‹: {report['not_found_count']}", styles["Normal"]))
        elements.append(Paragraph(f"ä¸€è‡´ç‡: {report['match_rate']:.1f}%", styles["Normal"]))
        elements.append(Spacer(1, 20))
        
        # é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        elements.append(Paragraph("é¸æ‰‹è©³ç´°ãƒ‡ãƒ¼ã‚¿", styles["Heading2"]))
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆè»½é‡åŒ–ï¼‰
        data = [["é¸æ‰‹å", "èº«é•·", "ä½“é‡", "ãƒã‚¸ã‚·ãƒ§ãƒ³", "å‡ºèº«æ ¡", "å­¦å¹´", "èƒŒç•ªå·", "ç…§åˆçµæœ"]]
        for r in report["results"]:
            d = r["original_data"]
            status = r.get("status", "unknown")
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¿œã˜ã¦è‰²åˆ†ã‘
            status_text = ""
            if status == "match":
                status_text = "âœ… å®Œå…¨ä¸€è‡´"
            elif status == "partial_match":
                status_text = "âš ï¸ éƒ¨åˆ†ä¸€è‡´"
            elif status == "not_found":
                status_text = "âŒ æœªç™ºè¦‹"
            else:
                status_text = f"â“ {status}"
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’çŸ­ç¸®ã—ã¦PDFè»½é‡åŒ–
            data.append([
                self._truncate_text(d.get("é¸æ‰‹å", d.get("æ°å", "")), 20),
                self._truncate_text(d.get("èº«é•·", ""), 10),
                self._truncate_text(d.get("ä½“é‡", ""), 10),
                self._truncate_text(d.get("ãƒã‚¸ã‚·ãƒ§ãƒ³", ""), 15),
                self._truncate_text(d.get("å‡ºèº«æ ¡", ""), 25),
                self._truncate_text(d.get("å­¦å¹´", ""), 10),
                self._truncate_text(d.get("èƒŒç•ªå·", ""), 10),
                self._truncate_text(status_text, 20)
            ])
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        table = Table(data, repeatRows=1)
        table.setStyle(TableStyle([
            ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
            ("TEXTCOLOR", (0, 0), (-1, 0), colors.black),
            ("ALIGN", (0, 0), (-1, -1), "CENTER"),
            ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
            ("FONTSIZE", (0, 0), (-1, -1), 8),
            ("BOTTOMPADDING", (0, 0), (-1, 0), 12),
            ("BACKGROUND", (0, 1), (-1, -1), colors.beige),
            ("GRID", (0, 0), (-1, -1), 0.5, colors.black),
            ("VALIGN", (0, 0), (-1, -1), "MIDDLE"),
        ]))
        elements.append(table)
        
        # PDFç”Ÿæˆ
        doc.build(elements)
        return output_path

    def generate_pdfs_by_university(self, df, output_dir, filename_prefix="tournament"):
        """å¤§å­¦ã”ã¨ã«PDFã‚’ç”Ÿæˆï¼ˆ1å¤§å­¦1ãƒšãƒ¼ã‚¸ï¼‰"""
        if df is None or df.empty:
            return None

        # å¤§å­¦ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        universities = df['å¤§å­¦å'].unique() if 'å¤§å­¦å' in df.columns else ["Unknown"]
        pdf_files = []

        for univ in universities:
            if 'å¤§å­¦å' in df.columns:
                univ_data = df[df['å¤§å­¦å'] == univ].copy()
            else:
                univ_data = df.copy()

            # å¤§å­¦ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ
            report = {
                'university': univ,
                'total_players': len(univ_data),
                'match_count': 0,  # ç°¡æ˜“ç‰ˆ
                'partial_match_count': 0,
                'not_found_count': 0,
                'match_rate': 0.0,
                'results': []  # ç°¡æ˜“ç‰ˆ
            }

            # é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ã‚’çµæœå½¢å¼ã«å¤‰æ›
            for index, row in univ_data.iterrows():
                result = {
                    'index': index,
                    'original_data': row.to_dict(),
                    'status': 'unknown',
                    'message': 'å‡¦ç†æ¸ˆã¿'
                }
                report['results'].append(result)

            # PDFç”Ÿæˆ
            pdf_filename = f"{filename_prefix}_{univ}.pdf"
            pdf_path = os.path.join(output_dir, pdf_filename)
            
            try:
                self.export_single_university_report_as_pdf(univ, report, pdf_path)
                pdf_files.append(pdf_path)
                logger.info(f"âœ… PDFç”Ÿæˆå®Œäº†: {pdf_path}")
            except Exception as e:
                logger.error(f"âŒ PDFç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({univ}): {e}")

        return pdf_files


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # CLI/Streamlit UI ã¯å‰Šé™¤æ¸ˆã¿
    return

if __name__ == "__main__":
    main()

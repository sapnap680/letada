#!/usr/bin/env python3
"""
CSVè‡ªå‹•è¨‚æ­£ã‚·ã‚¹ãƒ†ãƒ 
JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ç…§åˆã—ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•è¨‚æ­£
"""

import streamlit as st
import pandas as pd
import requests
import json
from bs4 import BeautifulSoup
from datetime import datetime
import re
import unicodedata
from difflib import SequenceMatcher
import io
# import google.generativeai as genai  # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
import os
import concurrent.futures
import time
import threading

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="CSVè‡ªå‹•è¨‚æ­£ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ€",
    layout="wide"
)

class JBAVerificationSystem:
    """JBAæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆrequests + BeautifulSoupãƒ™ãƒ¼ã‚¹ï¼‰"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
            'Accept': 'application/json',
            'Accept-Language': 'ja,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Origin': 'https://team-jba.jp',
            'Referer': 'https://team-jba.jp/organization/15250600/team/search',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
            'X-Requested-With': 'XMLHttpRequest'
        })
        self.logged_in = False
    
    def get_current_fiscal_year(self):
        """ç¾åœ¨ã®å¹´åº¦ã‚’å–å¾—"""
        current_year = datetime.now().year
        current_month = datetime.now().month
        
        if current_month >= 1:
            return str(current_year)
        else:
            return str(current_year - 1)
    
    def normalize_university_name(self, university_name):
        """å¤§å­¦åã‚’æ­£è¦åŒ–ï¼ˆæŸ”è»Ÿãªç…§åˆã®ãŸã‚ï¼‰"""
        if not university_name:
            return ""
        
        # åŸºæœ¬çš„ãªæ­£è¦åŒ–
        normalized = university_name.strip()
        
        # ã‚ˆãã‚ã‚‹è¡¨è¨˜ã®çµ±ä¸€
        replacements = {
            'ç™½é·—å¤§å­¦': 'ç™½é´å¤§å­¦',
            'ç™½é´å¤§å­¦': 'ç™½é´å¤§å­¦',
            'ç™½é·—': 'ç™½é´',
            'ç™½é´': 'ç™½é´',
            'å¤§å­¦': 'å¤§å­¦',
            'å­¦é™¢': 'å­¦é™¢',
            'çŸ­æœŸå¤§å­¦': 'çŸ­æœŸå¤§å­¦',
            'çŸ­å¤§': 'çŸ­æœŸå¤§å­¦'
        }
        
        for old, new in replacements.items():
            normalized = normalized.replace(old, new)
        
        return normalized
    
    def get_search_variations(self, university_name):
        """å¤§å­¦åã®æ¤œç´¢ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        if not university_name:
            return []
        
        variations = [university_name.strip()]
        
        # é•·ã„å¤§å­¦åã®å ´åˆã€çŸ­ç¸®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚è¿½åŠ 
        if len(university_name) > 6:  # é•·ã„åå‰ã®å ´åˆ
            # èªå°¾ã‚’æ®µéšçš„ã«å‰Šé™¤
            suffixes_to_remove = ['ä½“è‚²ä¼šãƒã‚¹ã‚±ãƒƒãƒˆãƒœãƒ¼ãƒ«éƒ¨', 'ãƒã‚¹ã‚±ãƒƒãƒˆãƒœãƒ¼ãƒ«éƒ¨', 'ä½“è‚²ä¼š', 'éƒ¨']
            
            for suffix in suffixes_to_remove:
                if university_name.endswith(suffix):
                    base_name = university_name[:-len(suffix)].strip()
                    if base_name and len(base_name) > 2:  # æœ€ä½3æ–‡å­—ä»¥ä¸Š
                        variations.append(base_name)
        
        # é‡è¤‡ã‚’å‰Šé™¤
        return list(set(variations))
    
    def login(self, email, password):
        """JBAã‚µã‚¤ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³"""
        try:
            st.info("ğŸ” JBAã‚µã‚¤ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³ä¸­...")
            
            login_page = self.session.get("https://team-jba.jp/login")
            soup = BeautifulSoup(login_page.content, 'html.parser')
            
            csrf_token = ""
            csrf_input = soup.find('input', {'name': '_token'})
            if csrf_input:
                csrf_token = csrf_input.get('value', '')
            
            login_data = {
                '_token': csrf_token,
                'login_id': email,
                'password': password
            }
            
            login_url = "https://team-jba.jp/login/done"
            login_response = self.session.post(login_url, data=login_data, allow_redirects=True)
            
            if "ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ" in login_response.text:
                st.success("âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
                self.logged_in = True
                return True
            else:
                st.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
                
        except Exception as e:
            st.error(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def search_teams_by_university(self, university_name):
        """å¤§å­¦åã§ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ï¼ˆæŸ”è»Ÿãªç…§åˆï¼‰"""
        try:
            if not self.logged_in:
                st.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™")
                return []
            
            current_year = self.get_current_fiscal_year()
            st.info(f"ğŸ” {university_name}ã®ç”·å­ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ä¸­... ({current_year}å¹´åº¦)")
            
            # å¤§å­¦åã®æ­£è¦åŒ–ï¼ˆæŸ”è»Ÿãªç…§åˆã®ãŸã‚ï¼‰
            normalized_university = self.normalize_university_name(university_name)
            st.info(f"ğŸ” æ­£è¦åŒ–ã•ã‚ŒãŸå¤§å­¦å: {normalized_university}")
            
            # æ­£è¦åŒ–ã•ã‚ŒãŸå¤§å­¦åã§æ¤œç´¢
            search_university = normalized_university
            
            # æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            search_url = "https://team-jba.jp/organization/15250600/team/search"
            search_page = self.session.get(search_url)
            
            if search_page.status_code != 200:
                st.error("âŒ æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“")
                return []
            
            soup = BeautifulSoup(search_page.content, 'html.parser')
            
            # CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            csrf_token = ""
            csrf_input = soup.find('input', {'name': '_token'})
            if csrf_input:
                csrf_token = csrf_input.get('value', '')
            
            # JSON APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢ï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰
            search_data = {
                "limit": 100,
                "offset": 0,
                "searchLogic": "AND",
                "search": [
                    {"field": "fiscal_year", "type": "text", "operator": "is", "value": current_year},
                    {"field": "team_name", "type": "text", "operator": "contains", "value": search_university},
                    {"field": "competition_division_id", "type": "int", "operator": "is", "value": 1},
                    {"field": "team_search_out_of_range", "type": "int", "operator": "is", "value": 1}
                ]
            }
            
            form_data = {'request': json.dumps(search_data, ensure_ascii=False)}
            headers = {
                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                'X-CSRF-Token': csrf_token,
                'X-Requested-With': 'XMLHttpRequest'
            }
            
            # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ï¼ˆJSON APIã¨ã—ã¦ï¼‰
            search_response = self.session.post(
                search_url, 
                data=form_data,
                headers=headers
            )
            
            if search_response.status_code != 200:
                st.error("âŒ æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
                return []
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            try:
                data = search_response.json()
                teams = []
                
                if data.get('status') == 'success' and 'records' in data:
                    for team_data in data['records']:
                        # ç”·å­ãƒãƒ¼ãƒ ã®ã¿ã‚’å¯¾è±¡
                        if team_data.get('team_gender_id') == 'ç”·å­':
                            teams.append({
                                'id': team_data.get('id', ''),
                                'name': team_data.get('team_name', ''),
                                'url': f"https://team-jba.jp/organization/15250600/team/{team_data.get('id', '')}/detail"
                            })
                
                st.success(f"âœ… {university_name}ã®ç”·å­ãƒãƒ¼ãƒ : {len(teams)}ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                return teams
                
            except Exception as e:
                st.error(f"âŒ æ¤œç´¢çµæœã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                return []
            
        except Exception as e:
            st.error(f"âŒ ãƒãƒ¼ãƒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _search_teams_by_university_silent(self, university_name):
        """å¤§å­¦åã§ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ï¼ˆé™ã‹ãªå®Ÿè¡Œç‰ˆ - st.*å‡ºåŠ›ãªã—ï¼‰"""
        try:
            if not self.logged_in:
                return []
            
            current_year = self.get_current_fiscal_year()
            
            # å¤§å­¦åã®æ­£è¦åŒ–ï¼ˆæŸ”è»Ÿãªç…§åˆã®ãŸã‚ï¼‰
            normalized_university = self.normalize_university_name(university_name)
            
            # æ­£è¦åŒ–ã•ã‚ŒãŸå¤§å­¦åã§æ¤œç´¢
            search_university = normalized_university
            
            # æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            search_url = "https://team-jba.jp/organization/15250600/team/search"
            search_page = self.session.get(search_url)
            
            if search_page.status_code != 200:
                return []
            
            soup = BeautifulSoup(search_page.content, 'html.parser')
            
            # CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            csrf_token = ""
            csrf_input = soup.find('input', {'name': '_token'})
            if csrf_input:
                csrf_token = csrf_input.get('value', '')
            
            # JSON APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢ï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰
            search_data = {
                "limit": 100,
                "offset": 0,
                "searchLogic": "AND",
                "search": [
                    {"field": "fiscal_year", "type": "text", "operator": "is", "value": current_year},
                    {"field": "team_name", "type": "text", "operator": "contains", "value": search_university},
                    {"field": "competition_division_id", "type": "int", "operator": "is", "value": 1},
                    {"field": "team_search_out_of_range", "type": "int", "operator": "is", "value": 1}
                ]
            }
            
            form_data = {'request': json.dumps(search_data, ensure_ascii=False)}
            headers = {
                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                'X-CSRF-Token': csrf_token,
                'X-Requested-With': 'XMLHttpRequest'
            }
            
            # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ï¼ˆJSON APIã¨ã—ã¦ï¼‰
            search_response = self.session.post(
                search_url, 
                data=form_data,
                headers=headers
            )
            
            if search_response.status_code != 200:
                return []
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            try:
                data = search_response.json()
                teams = []
                
                if data.get('status') == 'success' and 'records' in data:
                    for team_data in data['records']:
                        # ç”·å­ãƒãƒ¼ãƒ ã®ã¿ã‚’å¯¾è±¡
                        if team_data.get('team_gender_id') == 'ç”·å­':
                            teams.append({
                                'id': team_data.get('id', ''),
                                'name': team_data.get('team_name', ''),
                                'url': f"https://team-jba.jp/organization/15250600/team/{team_data.get('id', '')}/detail"
                            })
                
                return teams
                
            except Exception as e:
                return []
            
        except Exception as e:
            return []

    def get_team_members(self, team_url):
        """ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰"""
        try:
            st.info(f"ğŸ“Š ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ä¸­...")
            st.write(f"ğŸ” ãƒãƒ¼ãƒ URL: {team_url}")
            
            # ãƒãƒ¼ãƒ è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            team_page = self.session.get(team_url)
            
            if team_page.status_code != 200:
                st.error(f"âŒ ãƒãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ (Status: {team_page.status_code})")
                return {"team_name": "Error", "members": []}
            
            soup = BeautifulSoup(team_page.content, 'html.parser')
            
            # ãƒãƒ¼ãƒ åã‚’å–å¾—
            team_name = "Unknown Team"
            title_element = soup.find('title')
            if title_element:
                team_name = title_element.get_text(strip=True)
            
            st.write(f"ğŸ” ãƒãƒ¼ãƒ å: {team_name}")

            # ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’æŠ½å‡ºï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç‰¹å®šï¼‰
            members = []
            
            tables = soup.find_all('table')

            # ç”·å­ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™ï¼ˆ3åˆ—ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™ï¼‰
            member_table = None
            for i, table in enumerate(tables):
                rows = table.find_all('tr')
                if len(rows) > 10:  # ãƒ¡ãƒ³ãƒãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã¯é€šå¸¸10è¡Œä»¥ä¸Š
                    # æœ€åˆã®è¡Œã«ã€Œãƒ¡ãƒ³ãƒãƒ¼ID / æ°å / ç”Ÿå¹´æœˆæ—¥ã€ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    first_row_cells = rows[0].find_all(['td', 'th'])
                    if len(first_row_cells) >= 3:
                        first_cell = first_row_cells[0].get_text(strip=True)
                        second_cell = first_row_cells[1].get_text(strip=True)
                        third_cell = first_row_cells[2].get_text(strip=True)
                        if "ãƒ¡ãƒ³ãƒãƒ¼ID" in first_cell and "æ°å" in second_cell and "ç”Ÿå¹´æœˆæ—¥" in third_cell:
                            member_table = table
                            break

            if member_table:
                rows = member_table.find_all('tr')
                for row in rows[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 3:
                        member_id = cells[0].get_text(strip=True)
                        name = cells[1].get_text(strip=True)
                        birth_date = cells[2].get_text(strip=True)
                        
                        # ãƒ¡ãƒ³ãƒãƒ¼IDãŒæ•°å­—ã§ã€åå‰ãŒç©ºã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                        if member_id.isdigit() and name and name != "æ°å":
                            # é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã®ãƒªãƒ³ã‚¯ã‚’å–å¾—
                            detail_link = None
                            name_cell = cells[1]
                            link = name_cell.find('a')
                            if link and link.get('href'):
                                detail_link = link.get('href')
                                # ç›¸å¯¾URLã‚’çµ¶å¯¾URLã«å¤‰æ›
                                if detail_link.startswith('/'):
                                    detail_link = f"https://team-jba.jp{detail_link}"
                            
                            members.append({
                                "member_id": member_id,
                                "name": name,
                                "birth_date": birth_date,
                                "detail_url": detail_link
                            })

            return {
                "team_name": team_name,
                "members": members
            }
            
        except Exception as e:
            st.error(f"âŒ ãƒ¡ãƒ³ãƒãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            st.write(f"**ã‚¨ãƒ©ãƒ¼è©³ç´°**: {traceback.format_exc()}")
            return {"team_name": "Error", "team_url": team_url, "members": []}
    
    def _get_team_members_silent(self, team_url):
        """ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ï¼ˆé™ã‹ãªå®Ÿè¡Œç‰ˆ - st.*å‡ºåŠ›ãªã—ï¼‰"""
        try:
            # ãƒãƒ¼ãƒ è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            team_page = self.session.get(team_url)
            
            if team_page.status_code != 200:
                return {"team_name": "Error", "members": []}
            
            soup = BeautifulSoup(team_page.content, 'html.parser')
            
            # ãƒãƒ¼ãƒ åã‚’å–å¾—
            team_name = "Unknown Team"
            title_element = soup.find('title')
            if title_element:
                team_name = title_element.get_text(strip=True)
            
            # ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—
            members = []
            
            # é¸æ‰‹ä¸€è¦§ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
            member_tables = soup.find_all('table', class_='table')
            
            for table in member_tables:
                rows = table.find_all('tr')
                
                for row in rows[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    cells = row.find_all(['td', 'th'])
                    
                    if len(cells) >= 3:  # æœ€ä½é™ã®æƒ…å ±ãŒã‚ã‚‹è¡Œã®ã¿å‡¦ç†
                        # é¸æ‰‹åã®ãƒªãƒ³ã‚¯ã‚’æ¢ã™
                        name_link = row.find('a', href=re.compile(r'/player/\d+'))
                        
                        if name_link:
                            player_name = name_link.get_text(strip=True)
                            detail_url = name_link['href']
                            
                            if not detail_url.startswith('http'):
                                detail_url = f"https://team-jba.jp{detail_url}"
                            
                            # ãã®ä»–ã®æƒ…å ±ã‚’å–å¾—
                            position = ""
                            grade = ""
                            height = ""
                            weight = ""
                            
                            for i, cell in enumerate(cells):
                                cell_text = cell.get_text(strip=True)
                                
                                # ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼ˆé€šå¸¸ã¯2ç•ªç›®ã®ã‚«ãƒ©ãƒ ï¼‰
                                if i == 1 and cell_text and cell_text not in ['é¸æ‰‹å', 'æ°å']:
                                    position = cell_text
                                
                                # å­¦å¹´ï¼ˆé€šå¸¸ã¯3ç•ªç›®ã®ã‚«ãƒ©ãƒ ï¼‰
                                elif i == 2 and cell_text and cell_text not in ['å­¦å¹´', 'å¹´']:
                                    grade = cell_text
                                
                                # èº«é•·ãƒ»ä½“é‡ã®æƒ…å ±ã‚’æ¢ã™
                                if 'cm' in cell_text:
                                    height = cell_text
                                elif 'kg' in cell_text:
                                    weight = cell_text
                            
                            members.append({
                                "name": player_name,
                                "position": position,
                                "grade": grade,
                                "height": height,
                                "weight": weight,
                                "detail_url": detail_url
                            })
            
            return {
                "team_name": team_name,
                "members": members
            }
            
        except Exception as e:
            return {"team_name": "Error", "members": []}
    
    def get_player_details(self, detail_url):
        """é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰èº«é•·ãƒ»ä½“é‡ãªã©ã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        try:
            if not detail_url:
                return {}
            
            st.info(f"ğŸ” é¸æ‰‹è©³ç´°æƒ…å ±ã‚’å–å¾—ä¸­: {detail_url}")
            
            # é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            detail_page = self.session.get(detail_url)
            
            if detail_page.status_code != 200:
                st.warning(f"âš ï¸ é¸æ‰‹è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ (Status: {detail_page.status_code})")
                return {}
            
            soup = BeautifulSoup(detail_page.content, 'html.parser')
            
            # é¸æ‰‹è©³ç´°æƒ…å ±ã‚’æŠ½å‡º
            player_details = {}
            
            # èº«é•·ãƒ»ä½“é‡æƒ…å ±ã‚’æ¢ã™
            # ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
            height_patterns = [
                r'èº«é•·[ï¼š:]\s*(\d+\.?\d*)\s*cm',
                r'èº«é•·[ï¼š:]\s*(\d+\.?\d*)\s*ã‚»ãƒ³ãƒ',
                r'Height[ï¼š:]\s*(\d+\.?\d*)\s*cm'
            ]
            
            weight_patterns = [
                r'ä½“é‡[ï¼š:]\s*(\d+\.?\d*)\s*kg',
                r'ä½“é‡[ï¼š:]\s*(\d+\.?\d*)\s*ã‚­ãƒ­',
                r'Weight[ï¼š:]\s*(\d+\.?\d*)\s*kg'
            ]
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
            tables = soup.find_all('table')
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:
                        label = cells[0].get_text(strip=True)
                        value = cells[1].get_text(strip=True)
                        
                        # èº«é•·æƒ…å ±ï¼ˆJBAã®ã€Œèº«é•·ï¼ˆç«¶æŠ€è€…ç”¨ï¼‰ã€ã«å¯¾å¿œï¼‰
                        if 'èº«é•·' in label or 'Height' in label:
                            # æ•°å€¤éƒ¨åˆ†ã‚’æŠ½å‡º
                            import re
                            height_match = re.search(r'(\d+\.?\d*)', value)
                            if height_match and value.strip():  # ç©ºã§ãªã„å ´åˆã®ã¿
                                player_details['height'] = height_match.group(1)
                        
                        # ä½“é‡æƒ…å ±ï¼ˆJBAã®ã€Œä½“é‡ï¼ˆç«¶æŠ€è€…ç”¨ï¼‰ã€ã«å¯¾å¿œï¼‰
                        elif 'ä½“é‡' in label or 'Weight' in label:
                            # æ•°å€¤éƒ¨åˆ†ã‚’æŠ½å‡º
                            import re
                            weight_match = re.search(r'(\d+\.?\d*)', value)
                            if weight_match and value.strip():  # ç©ºã§ãªã„å ´åˆã®ã¿
                                player_details['weight'] = weight_match.group(1)
                        
                        # ãƒã‚¸ã‚·ãƒ§ãƒ³æƒ…å ±
                        elif 'ãƒã‚¸ã‚·ãƒ§ãƒ³' in label or 'Position' in label:
                            player_details['position'] = value
                        
                        # å‡ºèº«æ ¡æƒ…å ±
                        elif 'å‡ºèº«æ ¡' in label or 'å‡ºèº«' in label:
                            player_details['school'] = value
                        
                        # å­¦å¹´æƒ…å ±
                        elif 'å­¦å¹´' in label or 'Grade' in label:
                            player_details['grade'] = value
                        
                        # ãƒ¦ãƒ‹ãƒ•ã‚©ãƒ¼ãƒ ç•ªå·
                        elif 'ãƒ¦ãƒ‹ãƒ•ã‚©ãƒ¼ãƒ ç•ªå·' in label or 'èƒŒç•ªå·' in label:
                            player_details['uniform_number'] = value
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã§è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãƒšãƒ¼ã‚¸å…¨ä½“ã‹ã‚‰æ­£è¦è¡¨ç¾ã§æ¤œç´¢
            if 'height' not in player_details or 'weight' not in player_details:
                page_text = soup.get_text()
                
                # èº«é•·ã‚’æ¤œç´¢
                for pattern in height_patterns:
                    import re
                    match = re.search(pattern, page_text)
                    if match:
                        player_details['height'] = match.group(1)
                        break
                
                # ä½“é‡ã‚’æ¤œç´¢
                for pattern in weight_patterns:
                    import re
                    match = re.search(pattern, page_text)
                    if match:
                        player_details['weight'] = match.group(1)
                        break
            
            return player_details
            
        except Exception as e:
            st.warning(f"âš ï¸ é¸æ‰‹è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}
    

    def normalize_name(self, name):
        """åå‰ã®æ­£è¦åŒ–"""
        if not name or pd.isna(name):
            return ""
        
        name = str(name)
        
        # 1. å…¨è§’ãƒ»åŠè§’çµ±ä¸€
        name = unicodedata.normalize('NFKC', name)
        
        # 2. è¨˜å·ãƒ»ã‚¹ãƒšãƒ¼ã‚¹ã®æ­£è¦åŒ–ï¼ˆå…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚‚å«ã‚€ï¼‰
        name = re.sub(r'[ãƒ»ï½¥ã€ï¼Œ,\.\sã€€]+', '', name)
        
        # 3. å¤§æ–‡å­—å°æ–‡å­—çµ±ä¸€
        name = name.lower()
        
        # 4. ã‚ˆãã‚ã‚‹è¡¨è¨˜æºã‚Œã®çµ±ä¸€
        name = re.sub(r'[ãƒ¼âˆ’â€â€”â€“]', '', name)  # é•·éŸ³ç¬¦ã€ãƒã‚¤ãƒ•ãƒ³ã€ã‚¨ãƒ ãƒ€ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒ³ãƒ€ãƒƒã‚·ãƒ¥é™¤å»
        
        return name

    def calculate_similarity(self, name1, name2):
        """åå‰ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        if not name1 or not name2:
            return 0.0
        
        # æ­£è¦åŒ–
        norm_name1 = self.normalize_name(name1)
        norm_name2 = self.normalize_name(name2)
        
        if norm_name1 == norm_name2:
            return 1.0
        
        # åŸºæœ¬çš„ãªé¡ä¼¼åº¦
        basic_similarity = SequenceMatcher(None, norm_name1, norm_name2).ratio()
        
        return basic_similarity
    
    def show_name_differences(self, name1, name2):
        """åå‰ã®å¾®å¦™ãªé•ã„ã‚’è¦–è¦šçš„ã«è¡¨ç¤º"""
        if not name1 or not name2:
            return ""
        
        # æ­£è¦åŒ–
        norm_name1 = self.normalize_name(name1)
        norm_name2 = self.normalize_name(name2)
        
        if norm_name1 == norm_name2:
            return "âœ… å®Œå…¨ä¸€è‡´"
        
        # æ–‡å­—å˜ä½ã§ã®å·®åˆ†ã‚’è¡¨ç¤º
        matcher = SequenceMatcher(None, norm_name1, norm_name2)
        differences = []
        
        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag == 'equal':
                differences.append(norm_name1[i1:i2])
            elif tag == 'delete':
                differences.append(f"âŒ{norm_name1[i1:i2]}âŒ")
            elif tag == 'insert':
                differences.append(f"â•{norm_name2[j1:j2]}â•")
            elif tag == 'replace':
                differences.append(f"ğŸ”„{norm_name1[i1:i2]}â†’{norm_name2[j1:j2]}ğŸ”„")
        
        result = "".join(differences)
        return f"ğŸ” å·®åˆ†: {result}"

    def verify_player_info(self, player_name, birth_date, university, get_details=False, threshold=1.0):
        """å€‹åˆ¥é¸æ‰‹æƒ…å ±ã®ç…§åˆï¼ˆç”·å­ãƒãƒ¼ãƒ ã®ã¿ï¼‰"""
        try:
            st.write(f"ğŸ” é¸æ‰‹ç…§åˆ: {player_name}, å¤§å­¦: {university}")
            
            # å¤§å­¦åã®æ¤œç´¢ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
            search_variations = self.get_search_variations(university)
            st.write(f"ğŸ” æ¤œç´¢ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³: {search_variations}")
            
            all_matched_members = []  # ã™ã¹ã¦ã®ãƒãƒƒãƒå€™è£œã‚’ä¿å­˜
            
            teams = []
            for variation in search_variations:
                st.write(f"ğŸ” ãƒãƒ¼ãƒ æ¤œç´¢é–‹å§‹: {variation}")
                teams = self.search_teams_by_university(variation)
                st.write(f"ğŸ” æ¤œç´¢çµæœ: {len(teams)}ãƒãƒ¼ãƒ è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                
                if teams:
                    st.success(f"âœ… {variation}ã§ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                    break
                else:
                    st.info(f"âŒ {variation}ã§ã¯ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            if not teams:
                st.warning(f"âŒ {university}ã®ç”·å­ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return {"status": "not_found", "message": f"{university}ã®ç”·å­ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}

            # å„ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—ã—ã¦ç…§åˆ
            for team in teams:
                st.write(f"ğŸ” ãƒãƒ¼ãƒ : {team['name']} ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’å–å¾—ä¸­...")
                team_data = self.get_team_members(team['url'])
                
                if team_data and team_data["members"]:
                    st.write(f"ğŸ” ãƒ¡ãƒ³ãƒãƒ¼æ•°: {len(team_data['members'])}äºº")
                    
                    for i, member in enumerate(team_data["members"]):
                        st.write(f"  - ãƒ¡ãƒ³ãƒãƒ¼{i+1}: {member['name']}")
                        
                        # åå‰ã®é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯
                        name_similarity = self.calculate_similarity(player_name, member["name"])

                        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                        st.write(f"  - JBAé¸æ‰‹: {member['name']}")
                        st.write(f"  - åå‰é¡ä¼¼åº¦: {name_similarity:.3f}")
                        
                        # å¾®å¦™ãªé•ã„ã‚’è¡¨ç¤ºï¼ˆ0.6ä»¥ä¸Šã®å€™è£œã®ã¿ï¼‰
                        if name_similarity >= 0.6:
                            diff_info = self.show_name_differences(player_name, member["name"])
                            st.write(f"  - {diff_info}")

                        # ç¬¬1æ®µéš: 0.6ã®é–¾å€¤ã§å€™è£œã‚’æ¢ã™
                        if name_similarity >= 0.6:
                            st.info(f"ğŸ” å€™è£œç™ºè¦‹: {member['name']} (é¡ä¼¼åº¦: {name_similarity:.3f})")
                            
                            # ç¬¬2æ®µéš: 1.0ã®é–¾å€¤ã§å®Œå…¨ä¸€è‡´ã‚’ç¢ºèª
                            if name_similarity >= 1.0:
                                st.success(f"âœ… å®Œå…¨ä¸€è‡´: {member['name']}")
                                
                                # è©³ç´°æƒ…å ±ã‚’å–å¾—ã™ã‚‹å ´åˆ
                                if get_details and member.get("detail_url"):
                                    player_details = self.get_player_details(member["detail_url"])
                                    member.update(player_details)
                                
                                return {
                                    "status": "match",
                                    "jba_data": member,
                                    "similarity": name_similarity
                                }
                            
                            # 0.6ä»¥ä¸Š1.0æœªæº€ã®å€™è£œã‚‚ä¿å­˜ï¼ˆæœ€çµ‚çš„ã«è¿”ã™å¯èƒ½æ€§ï¼‰
                            elif name_similarity >= 0.6 and name_similarity < 1.0:
                                st.info(f"ğŸ“ å€™è£œä¿å­˜: {member['name']} (é¡ä¼¼åº¦: {name_similarity:.3f})")
                                
                                if get_details and member.get("detail_url"):
                                    player_details = self.get_player_details(member["detail_url"])
                                    member.update(player_details)
                                
                                all_matched_members.append({
                                    "status": "partial_match",
                                    "jba_data": member,
                                    "similarity": name_similarity,
                                    "message": f"éƒ¨åˆ†ä¸€è‡´: {member['name']} (é¡ä¼¼åº¦: {name_similarity:.3f})"
                                })
                else:
                    st.warning(f"âŒ ãƒãƒ¼ãƒ  {team['name']} ã®ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

            # å®Œå…¨ä¸€è‡´ã‚’å„ªå…ˆã—ã€ãªã‘ã‚Œã°éƒ¨åˆ†ä¸€è‡´ã‚’è¿”ã™
            if all_matched_members:
                # å®Œå…¨ä¸€è‡´ï¼ˆé¡ä¼¼åº¦1.0ï¼‰ã‚’å„ªå…ˆ
                exact_matches = [m for m in all_matched_members if m["similarity"] >= 1.0]
                if exact_matches:
                    st.info(f"ğŸ¯ å®Œå…¨ä¸€è‡´å€™è£œ: {len(exact_matches)}ä»¶")
                    return exact_matches[0]  # æœ€åˆã®å®Œå…¨ä¸€è‡´ã‚’è¿”ã™
                
                # éƒ¨åˆ†ä¸€è‡´ï¼ˆé¡ä¼¼åº¦0.6ä»¥ä¸Š1.0æœªæº€ï¼‰ã‚’è¿”ã™
                partial_matches = [m for m in all_matched_members if m["similarity"] >= 0.6 and m["similarity"] < 1.0]
                if partial_matches:
                    st.info(f"ğŸ“ éƒ¨åˆ†ä¸€è‡´å€™è£œ: {len(partial_matches)}ä»¶")
                    return partial_matches[0]  # æœ€åˆã®éƒ¨åˆ†ä¸€è‡´ã‚’è¿”ã™
                
                # ãã®ä»–ã®å€™è£œ
                st.info(f"ğŸ” ãã®ä»–å€™è£œ: {len(all_matched_members)}ä»¶")
                return all_matched_members[0]

            return {"status": "not_found", "message": "JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è©²å½“ã™ã‚‹é¸æ‰‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}

        except Exception as e:
            return {"status": "error", "message": f"ç…§åˆã‚¨ãƒ©ãƒ¼: {str(e)}"}

# AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤
    
# AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤
    
# AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤

class DataValidator:
    """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
    
    def __init__(self, gemini_api_key=None):
        # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
        pass
    
    def validate_weight(self, weight):
        """ä½“é‡ã®å¦¥å½“æ€§ã‚’è©•ä¾¡ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        if not weight:
            return True, []
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªç¯„å›²ãƒã‚§ãƒƒã‚¯
        try:
            weight_value = float(weight)
            if 45 <= weight_value <= 140:
                return True, []
            else:
                return False, [f"ä½“é‡ãŒç¯„å›²å¤–ã§ã™: {weight}kg (45-140kgã®ç¯„å›²ã§å…¥åŠ›ã—ã¦ãã ã•ã„)"]
        except (ValueError, TypeError):
            return False, [f"ä½“é‡ãŒæ•°å€¤ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {weight}"]
    
    def validate_and_correct_school(self, school_name):
        """å‡ºèº«æ ¡ã®å¦¥å½“æ€§ã‚’è©•ä¾¡ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        if not school_name or school_name.strip() == "":
            return True, [], None
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªæ–‡å­—åˆ—ãƒã‚§ãƒƒã‚¯
        school_name = str(school_name).strip()
        if len(school_name) < 2:
            return False, ["å­¦æ ¡åãŒçŸ­ã™ãã¾ã™"], None
        
        return True, [], None
    
    def validate_uniform_number(self, uniform_number):
        """èƒŒç•ªå·ã®å¦¥å½“æ€§ã‚’è©•ä¾¡ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        if not uniform_number:
            return True, []
        
        # èƒŒç•ªå·ã¯æ•°å­—ã®ã¿ã®ã‚·ãƒ³ãƒ—ãƒ«æ¤œè¨¼
        try:
            num = int(uniform_number)
            if 1 <= num <= 99:
                return True, []
            else:
                return False, ["èƒŒç•ªå·ã¯1ã€œ99ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"]
        except ValueError:
            return False, ["èƒŒç•ªå·ã¯æ•°å­—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"]
    
    def validate_player_data(self, player_data):
        """ä½“é‡ãƒ»å‡ºèº«æ ¡ãƒ»èƒŒç•ªå·ã®æ¤œè¨¼ï¼ˆAIæ©Ÿèƒ½ãªã—ï¼‰"""
        all_issues = []
        
        # ä½“é‡ã®æ¤œè¨¼
        weight = player_data.get('weight')
        if weight:
            is_valid_weight, weight_issues = self.validate_weight(weight)
            all_issues.extend(weight_issues)
        
        # å‡ºèº«æ ¡ã®æ¤œè¨¼
        school = player_data.get('school')
        if school:
            is_valid_school, school_issues, _ = self.validate_and_correct_school(school)
            all_issues.extend(school_issues)
        
        # èƒŒç•ªå·ã®æ¤œè¨¼
        uniform_number = player_data.get('uniform_number')
        if uniform_number:
            is_valid_uniform, uniform_issues = self.validate_uniform_number(uniform_number)
            all_issues.extend(uniform_issues)
        
        return len(all_issues) == 0, all_issues

class FastCSVCorrectionSystem:
    """CSVè¨‚æ­£ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ”¹ç‰ˆï¼‰"""
    
    def __init__(self, jba_system, gemini_api_key=None, max_workers=5):
        self.jba_system = jba_system
        self.validator = DataValidator(gemini_api_key)
        self.max_workers = max_workers
        self.lock = threading.Lock()
    
    def _preload_university_data(self, university_name):
        """å¤§å­¦ã®ãƒãƒ¼ãƒ æƒ…å ±ã‚’äº‹å‰ã«å…¨ã¦å–å¾—ï¼ˆ1å›ã ã‘å®Ÿè¡Œï¼‰"""
        if university_name in self.university_teams_data:
            return self.university_teams_data[university_name]
        
        # ãƒãƒ¼ãƒ æ¤œç´¢ï¼ˆæ¤œç´¢ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰- é™ã‹ãªå®Ÿè¡Œ
        search_variations = self.jba_system.get_search_variations(university_name)
        teams = []
        
        for variation in search_variations:
            teams = self.jba_system._search_teams_by_university_silent(variation)
            if teams:
                break
        
        if not teams:
            with self.lock:
                self.university_teams_data[university_name] = None
            return None
        
        # å„ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’å–å¾— - é™ã‹ãªå®Ÿè¡Œ
        teams_data = {}
        
        for team in teams:
            team_id = team['id']
            team_url = team['url']
            
            # æ—¢ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ã‚Œã°ä½¿ç”¨
            if team_url in self.team_members_cache:
                team_data = self.team_members_cache[team_url]
            else:
                team_data = self.jba_system._get_team_members_silent(team_url)
                with self.lock:
                    self.team_members_cache[team_url] = team_data
            
            teams_data[team_id] = {
                'team_name': team['name'],
                'team_url': team_url,
                'members': team_data.get('members', [])
            }
        
        with self.lock:
            self.university_teams_data[university_name] = teams_data
        
        return teams_data
    
    def _process_single_player(self, row_data):
        """å˜ä¸€é¸æ‰‹ã‚’å‡¦ç†ï¼ˆè¨‚æ­£å¿…è¦ãªå ´åˆã®ã¿æƒ…å ±ã‚’è©°ã‚ã‚‹ï¼‰"""
        index, row, university_name, threshold = row_data
        
        try:
            player_name = None
            name_column = None
            name_columns = ['é¸æ‰‹å', 'æ°å', 'name', 'Name']
            
            for col in name_columns:
                if col in row.index and pd.notna(row[col]):
                    player_name = str(row[col]).strip()
                    name_column = col
                    break
            
            if not player_name:
                return {
                    'index': index,
                    'original_data': row.to_dict(),
                    'status': 'missing_data',
                    'corrections': {},
                    'jba_data': {},
                    'validation_warnings': [],
                    'has_correction': False
                }
            
            # JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ç…§åˆ
            verification_result = self.jba_system.verify_player_info(
                player_name, None, university_name, get_details=True, threshold=threshold
            )
            
            result = {
                'index': index,
                'original_data': row.to_dict(),
                'verification_result': verification_result,
                'status': verification_result.get('status', 'error'),
                'corrections': {},
                'jba_data': {},
                'validation_warnings': [],
                'has_correction': False
            }
            
            # jba_data ã‚’äº‹å‰ã«åˆæœŸåŒ–
            jba_data = {}
            
            if verification_result.get('status') in ['match', 'partial_match']:
                jba_data = verification_result.get('jba_data', {})
                result['jba_data'] = jba_data
                
                # åå‰ãŒç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('name') and jba_data['name'] != player_name:
                    result['corrections'][name_column] = jba_data['name']
                    result['has_correction'] = True
                
                # ä½“é‡ï¼šJBAã«ã‚ã‚Œã°å„ªå…ˆã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('weight') and str(jba_data['weight']).strip():
                    weight_value = str(jba_data['weight']).strip()
                    weight_match = re.search(r'(\d+\.?\d*)', weight_value)
                    if weight_match:
                        extracted_weight = weight_match.group(1)
                        try:
                            original_weight = float(row.get('ä½“é‡', 0))
                            jba_weight = float(extracted_weight)
                            if original_weight != jba_weight:
                                result['corrections']['ä½“é‡'] = extracted_weight
                                result['has_correction'] = True
                        except (ValueError, TypeError):
                            pass
                
                # å­¦å¹´ï¼šJBAã«è¨˜è¼‰ãŒã‚ã‚Œã°ã€æ•°å­—ã ã‘ã‚’æŠ½å‡ºã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('grade') and str(jba_data['grade']).strip():
                    grade_value = str(jba_data['grade']).strip()
                    grade_match = re.search(r'(\d+)', grade_value)
                    if grade_match:
                        extracted_grade = grade_match.group(1)
                        try:
                            original_grade = str(row.get('å­¦å¹´', '')).strip()
                            if original_grade.isdigit():
                                original_grade_num = original_grade
                            else:
                                grade_num_match = re.search(r'(\d+)', original_grade)
                                original_grade_num = grade_num_match.group(1) if grade_num_match else original_grade
                            
                            if original_grade_num != extracted_grade:
                                result['corrections']['å­¦å¹´'] = extracted_grade
                                result['has_correction'] = True
                        except:
                            pass
                
                # èº«é•·ï¼šJBAã«è¨˜è¼‰ãŒã‚ã‚Œã°ã€æ•°å­—ã ã‘ã‚’æŠ½å‡ºã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                if jba_data.get('height') and str(jba_data['height']).strip():
                    height_value = str(jba_data['height']).strip()
                    height_match = re.search(r'(\d+\.?\d*)', height_value)
                    if height_match:
                        extracted_height = height_match.group(1)
                        try:
                            original_height = float(row.get('èº«é•·', 0))
                            jba_height = float(extracted_height)
                            if original_height != jba_height:
                                result['corrections']['èº«é•·'] = extracted_height
                                result['has_correction'] = True
                        except (ValueError, TypeError):
                            pass
                
                # å…ƒãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸å€¤ã‚’AIã§æ¤œå‡ºï¼ˆJBAã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ã¿ï¼‰
                if not jba_data.get('weight') and not jba_data.get('height'):
                    validation_warnings = []  # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
                    result['validation_warnings'] = validation_warnings
            else:
                # JBAç™»éŒ²ãªã—ãƒ»æœªç™ºè¦‹ã®å ´åˆã‚‚è­¦å‘Šã‚’ãƒã‚§ãƒƒã‚¯
                validation_warnings = []  # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
                result['validation_warnings'] = validation_warnings
            
            return result
        
        except Exception as e:
            import traceback
            return {
                'index': index,
                'original_data': row.to_dict(),
                'status': 'error',
                'corrections': {},
                'jba_data': {},
                'validation_warnings': [f'ã‚¨ãƒ©ãƒ¼: {str(e)}'],
                'has_correction': False
            }
    
    def _validate_player_data_with_ai(self, row, jba_data):
        """å…ƒãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸å€¤ã‚’æ¤œå‡ºï¼ˆJBAã«è¨˜è¼‰ãŒãªã„å ´åˆã®ã¿ï¼‰"""
        warnings = []
        
        # ä½“é‡ï¼šJBAã«è¨˜è¼‰ãŒãªã„å ´åˆã®ã¿è¨±å®¹ç¯„å›²ã§ãƒã‚§ãƒƒã‚¯
        if not jba_data.get('weight') and pd.notna(row.get('ä½“é‡')):
            weight = row.get('ä½“é‡')
            try:
                weight_value = float(weight)
                if weight_value < 45 or weight_value > 140:
                    warnings.append(f"âš ï¸ ä½“é‡ãŒè¨±å®¹ç¯„å›²å¤–: {weight_value}kg (è¨±å®¹ç¯„å›²: 45-140kg)")
            except (ValueError, TypeError):
                warnings.append(f"âš ï¸ ä½“é‡ãŒæ•°å€¤ã§ã¯ãªã„: {weight}")
        
        return warnings
    
    def process_csv_file_parallel(self, df, university_name, threshold=1.0):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¦åˆ—å‡¦ç†ã§é«˜é€Ÿã«å‡¦ç†"""
        
        st.info("ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã‚’ä¸¦åˆ—å‡¦ç†ä¸­...")
        
        process_data = [
            (index, row, university_name, threshold)
            for index, row in df.iterrows()
        ]
        
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {executor.submit(self._process_single_player, data): data[0] for data in process_data}
            
            completed = 0
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                results.append(result)
                
                completed += 1
                progress = completed / len(futures)
                progress_bar.progress(progress)
                
                player_name = result['original_data'].get('é¸æ‰‹å', 'Unknown')
                status_text.text(f"å‡¦ç†ä¸­: {completed}/{len(futures)} - {player_name}")
        
        elapsed_time = time.time() - start_time
        
        progress_bar.progress(1.0)
        status_text.text("âœ… å‡¦ç†å®Œäº†")
        
        results.sort(key=lambda x: x['index'])
        
        # â˜… çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        st.success(f"âœ… {len(df)}è¡Œã‚’{elapsed_time:.2f}ç§’ã§å‡¦ç†ã—ã¾ã—ãŸ")
        
        # çµ±è¨ˆæƒ…å ±
        matched = sum(1 for r in results if r['status'] == 'match')
        partial = sum(1 for r in results if r['status'] == 'partial_match')
        warnings_count = sum(len(r.get('validation_warnings', [])) for r in results)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("JBAä¸€è‡´", matched)
        with col2:
            st.metric("éƒ¨åˆ†ä¸€è‡´", partial)
        with col3:
            st.metric("âš ï¸ è­¦å‘Š", warnings_count)
        with col4:
            st.metric("å‡¦ç†æ™‚é–“", f"{elapsed_time:.2f}ç§’")
        
        return results
    
    def create_corrected_csv(self, df, results):
        """ä¿®æ­£ç‰ˆCSVã‚’ä½œæˆï¼ˆå…ƒã®åˆ—é †ã‚’ä¿æŒã€ã‚»ãƒ«å½¢å¼ã‚’ä¿æŒï¼‰"""
        corrected_df = df.copy()
        
        for result in results:
            # è¨‚æ­£ãŒã‚ã‚‹å ´åˆã®ã¿å‡¦ç†
            if not result.get('has_correction'):
                continue
            
            index = result['index']
            corrections = result.get('corrections', {})
            
            if not corrections:
                continue
            
            # å„ä¿®æ­£é …ç›®ã‚’CSVã«åæ˜ ï¼ˆåˆ—é †ã¯å¤‰ã‚ã‚‰ãªã„ï¼‰
            for csv_col, corrected_value in corrections.items():
                if csv_col not in corrected_df.columns:
                    # åˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆè¿½åŠ ã—ãªã„ï¼‰
                    continue
                
                # ä¿®æ­£å€¤ã‚’é©ç”¨
                corrected_df.at[index, csv_col] = corrected_value
        
        return corrected_df
    
    def create_colored_excel(self, df, results):
        """è‰²ä»˜ãExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆä¿®æ­£ç®‡æ‰€ã¯èµ¤ã€è­¦å‘Šã¯é»„è‰²ã€å…¨ä½“ä¸­å¤®æƒãˆï¼‰"""
        from openpyxl import Workbook
        from openpyxl.styles import PatternFill, Font, Alignment
        
        excel_buffer = io.BytesIO()
        
        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='ä¿®æ­£æ¸ˆã¿')
            
            ws = writer.sheets['ä¿®æ­£æ¸ˆã¿']
            
            # ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾©
            red_fill = PatternFill(start_color='FF0000', end_color='FF0000', fill_type='solid')
            yellow_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')
            white_font = Font(color='FFFFFF', bold=True)
            black_font = Font(color='000000')
            center_alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
            
            columns = list(df.columns)
            
            # å…¨ã‚»ãƒ«ã‚’ä¸­å¤®æƒãˆã«
            for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=len(columns)):
                for cell in row:
                    cell.alignment = center_alignment
            
            for result in results:
                row_index = result['index'] + 2
                
                # è¨‚æ­£ãŒã‚ã‚‹å ´åˆï¼šèµ¤è‰²
                if result.get('has_correction'):
                    for col_name, corrected_value in result['corrections'].items():
                        if col_name in columns:
                            col_index = columns.index(col_name) + 1
                            cell = ws.cell(row=row_index, column=col_index)
                            cell.fill = red_fill
                            cell.font = white_font
                            cell.alignment = center_alignment
                
                # è­¦å‘ŠãŒã‚ã‚‹å ´åˆï¼šé»„è‰²
                if result.get('validation_warnings'):
                    for warning in result['validation_warnings']:
                        if 'ä½“é‡' in warning and 'ä½“é‡' in columns:
                            col_index = columns.index('ä½“é‡') + 1
                            cell = ws.cell(row=row_index, column=col_index)
                            cell.fill = yellow_fill
                            cell.font = black_font
                            cell.alignment = center_alignment
                        elif 'èº«é•·' in warning and 'èº«é•·' in columns:
                            col_index = columns.index('èº«é•·') + 1
                            cell = ws.cell(row=row_index, column=col_index)
                            cell.fill = yellow_fill
                            cell.font = black_font
                            cell.alignment = center_alignment
                        elif 'å‡ºèº«æ ¡' in warning and 'å‡ºèº«æ ¡' in columns:
                            col_index = columns.index('å‡ºèº«æ ¡') + 1
                            cell = ws.cell(row=row_index, column=col_index)
                            cell.fill = yellow_fill
                            cell.font = black_font
                            cell.alignment = center_alignment
            
            # åˆ—å¹…è‡ªå‹•èª¿æ•´
            for col_idx, col_name in enumerate(columns, 1):
                ws.column_dimensions[chr(64 + col_idx)].width = 15
        
        excel_buffer.seek(0)
        return excel_buffer

class CSVCorrectionSystem:
    """CSVè‡ªå‹•è¨‚æ­£ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¾“æ¥ç‰ˆï¼‰"""
    
    def __init__(self, jba_system, gemini_api_key=None):
        self.jba_system = jba_system
        self.validator = DataValidator(gemini_api_key)
    
    def process_csv_file(self, df, university_name, threshold=0.8, get_details=False):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦è¨‚æ­£ç‰ˆã‚’ä½œæˆ"""
        st.info(f"ğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­... ({len(df)}è¡Œ)")
        st.write(f"ğŸ” å‡¦ç†é–‹å§‹: å¤§å­¦å={university_name}, é–¾å€¤={threshold}, è©³ç´°å–å¾—={get_details}")
        
        results = []
        corrections = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for index, row in df.iterrows():
            progress = (index + 1) / len(df)
            progress_bar.progress(progress)
            status_text.text(f"å‡¦ç†ä¸­: {index + 1}/{len(df)} - {row.get('é¸æ‰‹å', row.get('æ°å', 'Unknown'))}")
            
            st.write(f"ğŸ” è¡Œ {index + 1} ã‚’å‡¦ç†ä¸­...")
            
            # é¸æ‰‹åã®ã¿ã‚’å–å¾—
            player_name = None
            name_columns = ['é¸æ‰‹å', 'æ°å', 'name', 'Name']
            
            for col in name_columns:
                if col in df.columns and pd.notna(row[col]):
                    player_name = str(row[col]).strip()
                    st.write(f"  - é¸æ‰‹åå–å¾—: {player_name} (ã‚«ãƒ©ãƒ : {col})")
                    break
            
            if not player_name:
                st.warning(f"  - é¸æ‰‹åãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                results.append({
                    'index': index,
                    'original_data': row.to_dict(),
                    'status': 'missing_data',
                    'message': 'é¸æ‰‹åãŒä¸è¶³ã—ã¦ã„ã¾ã™',
                    'correction': None
                })
                continue
            
            # JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®ç…§åˆ
            verification_result = self.jba_system.verify_player_info(
                player_name, None, university_name, get_details, threshold
            )
            
            result = {
                'index': index,
                'original_data': row.to_dict(),
                'verification_result': verification_result,
                'status': verification_result['status']
            }
            
            # å®Œå…¨ä¸€è‡´ã®å ´åˆ
            if verification_result['status'] == 'match':
                if get_details and 'jba_data' in verification_result:
                    jba_data = verification_result['jba_data']
                    is_valid, validation_issues, school_corrections = self.validator.validate_player_data(jba_data)
                    
                    corrected_data = row.to_dict().copy()
                    
                    # JBAæƒ…å ±ã‚’è¿½åŠ 
                    if 'height' in jba_data and jba_data['height']:
                        corrected_data['èº«é•·'] = f"{jba_data['height']}cm"
                    if 'weight' in jba_data and jba_data['weight']:
                        corrected_data['ä½“é‡'] = f"{jba_data['weight']}kg"
                    if 'position' in jba_data and jba_data['position']:
                        corrected_data['ãƒã‚¸ã‚·ãƒ§ãƒ³'] = jba_data['position']
                    if 'school' in jba_data and jba_data['school']:
                        if 'school' in school_corrections:
                            corrected_data['å‡ºèº«æ ¡'] = school_corrections['school']
                            result['school_correction'] = f"{jba_data['school']} â†’ {school_corrections['school']}"
                        else:
                            corrected_data['å‡ºèº«æ ¡'] = jba_data['school']
                    if 'grade' in jba_data and jba_data['grade']:
                        corrected_data['å­¦å¹´'] = jba_data['grade']
                    if 'uniform_number' in jba_data and jba_data['uniform_number']:
                        corrected_data['èƒŒç•ªå·'] = jba_data['uniform_number']
                    
                    if not is_valid:
                        result['validation_issues'] = validation_issues
                        result['message'] = f'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´ï¼ˆè©³ç´°æƒ…å ±è¿½åŠ ï¼‰âš ï¸ ç•°å¸¸å€¤æ¤œå‡º: {", ".join(validation_issues)}'
                    else:
                        result['message'] = 'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´ï¼ˆè©³ç´°æƒ…å ±è¿½åŠ ï¼‰'
                    
                    result['correction'] = corrected_data
                else:
                    result['correction'] = None
                    result['message'] = 'JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨å®Œå…¨ä¸€è‡´'
            
            # éƒ¨åˆ†ä¸€è‡´ã®å ´åˆ
            elif verification_result['status'] == 'partial_match':
                jba_data = verification_result['jba_data']
                similarity = verification_result.get('similarity', 0.0)
                
                corrected_data = row.to_dict().copy()
                
                if get_details:
                    if 'height' in jba_data and jba_data['height']:
                        corrected_data['èº«é•·'] = f"{jba_data['height']}cm"
                    if 'weight' in jba_data and jba_data['weight']:
                        corrected_data['ä½“é‡'] = f"{jba_data['weight']}kg"
                    if 'position' in jba_data and jba_data['position']:
                        corrected_data['ãƒã‚¸ã‚·ãƒ§ãƒ³'] = jba_data['position']
                    if 'school' in jba_data and jba_data['school']:
                        corrected_data['å‡ºèº«æ ¡'] = jba_data['school']
                    if 'grade' in jba_data and jba_data['grade']:
                        corrected_data['å­¦å¹´'] = jba_data['grade']
                    if 'uniform_number' in jba_data and jba_data['uniform_number']:
                        corrected_data['èƒŒç•ªå·'] = jba_data['uniform_number']
                
                result['correction'] = corrected_data
                result['message'] = f"éƒ¨åˆ†ä¸€è‡´: {jba_data['name']} (é¡ä¼¼åº¦: {similarity:.3f}) - æ‰‹å‹•ç¢ºèªæ¨å¥¨"
            
            # ä¸€è‡´ãªã—ã®å ´åˆ
            else:
                result['correction'] = None
                result['message'] = verification_result.get('message', 'ç…§åˆã§ãã¾ã›ã‚“ã§ã—ãŸ')
            
            results.append(result)
        
        progress_bar.progress(1.0)
        status_text.text("âœ… å‡¦ç†å®Œäº†")
        
        return results, corrections
    
    def create_corrected_csv(self, df, results):
        """è¨‚æ­£ç‰ˆCSVã‚’ä½œæˆï¼ˆè¨‚æ­£éƒ¨åˆ†ã‚’èµ¤å­—ã§è¡¨ç¤ºï¼‰"""
        corrected_df = df.copy()
        
        # è¨‚æ­£ã‚’é©ç”¨
        for result in results:
            if result['correction']:
                index = result['index']
                corrected_data = result['correction']
                
                # å„ã‚«ãƒ©ãƒ ã‚’æ›´æ–°
                for col, value in corrected_data.items():
                    if col in corrected_df.columns:
                        # å…ƒã®å€¤ã¨ç•°ãªã‚‹å ´åˆã®ã¿è¨‚æ­£
                        original_value = corrected_df.at[index, col]
                        if original_value != value:
                            # è¨‚æ­£ã•ã‚ŒãŸå€¤ã‚’èµ¤å­—ã§è¡¨ç¤º
                            corrected_df.at[index, col] = f"ğŸ”´ {value}"
        
        return corrected_df

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'jba_logged_in' not in st.session_state:
        st.session_state.jba_logged_in = False
    if 'jba_system' not in st.session_state:
        st.session_state.jba_system = None
    if 'csv_system' not in st.session_state:
        st.session_state.csv_system = None
    if 'uploaded_df' not in st.session_state:
        st.session_state.uploaded_df = None
    if 'university_name' not in st.session_state:
        st.session_state.university_name = ""
    if 'threshold' not in st.session_state:
        st.session_state.threshold = 0.8
    if 'get_details' not in st.session_state:
        st.session_state.get_details = False
    
    st.title("ğŸ€ CSVè‡ªå‹•è¨‚æ­£ã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("**JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ç…§åˆã—ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•è¨‚æ­£ã—ã¾ã™**")
    
    # ã‚«ã‚¹ã‚¿ãƒ CSS
    st.markdown("""
    <style>
    .main-header {
        background: linear-gradient(90deg, #2563eb, #3b82f6);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .card {
        background: white;
        padding: 1.5rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ” JBAãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±")
        email = st.text_input("JBAãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", type="default")
        password = st.text_input("JBAãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
        
        if st.button("JBAã«ãƒ­ã‚°ã‚¤ãƒ³", type="primary"):
            if email and password:
                # JBAã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
                if st.session_state.jba_system is None:
                    st.session_state.jba_system = JBAVerificationSystem()
                
                if st.session_state.jba_system.login(email, password):
                    st.session_state.jba_logged_in = True
                    st.success("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
                else:
                    st.session_state.jba_logged_in = False
                    st.error("ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—")
            else:
                st.error("ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        # ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã®è¡¨ç¤º
        if st.session_state.jba_logged_in:
            st.success("âœ… JBAã«ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿")
        else:
            st.warning("âš ï¸ JBAã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„")
        
        # å†…éƒ¨è¨­å®šï¼ˆè¡¨ç¤ºãªã—ï¼‰
        threshold = 1.0  # å®Œå…¨ä¸€è‡´ã®ã¿
        get_details = True  # å¸¸ã«ã‚ªãƒ³
        # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
        use_parallel_processing = True  # ä¸¦åˆ—å‡¦ç†ã‚’ä½¿ç”¨
        max_workers = 5  # ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    if 'jba_system' not in st.session_state:
        st.session_state.jba_system = JBAVerificationSystem()
    
    # ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã®å¾©å…ƒãƒã‚§ãƒƒã‚¯
    if 'jba_logged_in' not in st.session_state:
        st.session_state.jba_logged_in = False
    
    # CSVã‚·ã‚¹ãƒ†ãƒ ã‚’æ¯å›æ›´æ–°ï¼ˆAPIã‚­ãƒ¼ã®å¤‰æ›´ã«å¯¾å¿œï¼‰
    if st.session_state.jba_system is not None:
        if use_parallel_processing:
            st.session_state.csv_system = FastCSVCorrectionSystem(
                st.session_state.jba_system, 
                None,  # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
                max_workers=max_workers
            )
        else:
            st.session_state.csv_system = CSVCorrectionSystem(st.session_state.jba_system, None)  # AIæ©Ÿèƒ½ã¯ä½¿ç”¨ã—ãªã„
    else:
        st.session_state.csv_system = None
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    st.header("ğŸ“„ CSVãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†")
    
    # å¤§å­¦åå…¥åŠ›
    university_name = st.text_input("å¤§å­¦å", placeholder="ä¾‹: ç™½é´å¤§å­¦", help="JBAãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹å¤§å­¦åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=['csv'],
        help="é¸æ‰‹åãŒå«ã¾ã‚Œã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
    )
    
    if uploaded_file is not None:
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆè¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œï¼‰
            encodings = ['utf-8', 'shift_jis', 'cp932', 'utf-8-sig', 'iso-2022-jp']
            df = None
            
            for encoding in encodings:
                try:
                    uploaded_file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
                    df = pd.read_csv(uploaded_file, encoding=encoding)
                    st.success(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ ({len(df)}è¡Œ) - ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {encoding}")
                    break
                except UnicodeDecodeError:
                    continue
            
            if df is None:
                st.error("âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒåˆ¤åˆ¥ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’UTF-8ã§ä¿å­˜ã—ç›´ã—ã¦ãã ã•ã„ã€‚")
                st.stop()
            
            # èƒŒç•ªå·é–¢é€£ã®åˆ—ã‚’å‰Šé™¤
            columns_to_drop = [col for col in df.columns if 'èƒŒç•ªå·' in col or 'uniform' in col.lower()]
            if columns_to_drop:
                st.info(f"ğŸ”§ èƒŒç•ªå·é–¢é€£ã®åˆ—ã‚’å‰Šé™¤ã—ã¾ã™: {columns_to_drop}")
                df = df.drop(columns=columns_to_drop)
            
            # capã‚«ãƒ©ãƒ ã‚’é™¤å¤–ï¼ˆç„¡è¦–ï¼‰
            if 'cap' in df.columns:
                st.info("ğŸ“ ã€Œcapã€ã‚«ãƒ©ãƒ ã¯ç„¡è¦–ã—ã¾ã™")
                df = df.drop(columns=['cap'])
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.dataframe(df.head())
            
            # ã‚«ãƒ©ãƒ æƒ…å ±
            st.subheader("ğŸ“‹ ã‚«ãƒ©ãƒ æƒ…å ±")
            st.write(f"ã‚«ãƒ©ãƒ æ•°: {len(df.columns)}")
            st.write(f"ã‚«ãƒ©ãƒ å: {list(df.columns)}")
            
            # å‡¦ç†å®Ÿè¡Œ
            if st.button("ğŸš€ è‡ªå‹•è¨‚æ­£ã‚’å®Ÿè¡Œ", type="primary"):
                if not st.session_state.jba_logged_in:
                    st.error("âŒ å…ˆã«JBAã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„")
                elif not university_name:
                    st.error("âŒ å¤§å­¦åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                elif st.session_state.csv_system is None:
                    st.error("âŒ CSVã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚JBAã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
                else:
                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                    st.info(f"ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
                    st.write(f"- å¤§å­¦å: {university_name}")
                    st.write(f"- ãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(df)}")
                    st.write(f"- ã‚«ãƒ©ãƒ å: {list(df.columns)}")
                    st.write(f"- JBAãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹: {st.session_state.jba_logged_in}")
                    st.write(f"- é¡ä¼¼åº¦é–¾å€¤: {threshold}")
                    st.write(f"- è©³ç´°æƒ…å ±å–å¾—: {get_details}")
                    
                    # æœ€åˆã®æ•°è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                    st.write("**æœ€åˆã®3è¡Œã®ãƒ‡ãƒ¼ã‚¿:**")
                    st.dataframe(df.head(3))
                    
                    # CSVå‡¦ç†å®Ÿè¡Œ
                    if use_parallel_processing:
                        results = st.session_state.csv_system.process_csv_file_parallel(
                            df, university_name, threshold
                        )
                        corrections = []  # ä¸¦åˆ—å‡¦ç†ç‰ˆã§ã¯ corrections ã¯åˆ¥é€”å‡¦ç†
                    else:
                        results, corrections = st.session_state.csv_system.process_csv_file(
                            df, university_name, threshold, get_details
                        )
                    
                    # çµæœè¡¨ç¤º
                    st.subheader("ğŸ“Š å‡¦ç†çµæœ")
                    
                    # è¨‚æ­£ã‚ã‚Šã®ä»¶æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    total_records = len(results)
                    matched_count = sum(1 for r in results if r['status'] == 'match')
                    partial_match_count = sum(1 for r in results if r['status'] == 'partial_match')
                    has_correction_count = sum(1 for r in results if r.get('has_correction', False))
                    warnings_count = sum(len(r.get('validation_warnings', [])) for r in results)
                    not_found_count = sum(1 for r in results if r['status'] == 'not_found')
                    
                    col1, col2, col3, col4, col5, col6 = st.columns(6)
                    with col1:
                        st.metric("å…¨ä»¶æ•°", total_records)
                    with col2:
                        st.metric("JBAä¸€è‡´", matched_count)
                    with col3:
                        st.metric("éƒ¨åˆ†ä¸€è‡´", partial_match_count)
                    with col4:
                        st.metric("è¨‚æ­£ã‚ã‚Š", has_correction_count)  # å®Ÿéš›ã«è¨‚æ­£ãŒã‚ã£ãŸä»¶æ•°
                    with col5:
                        st.metric("âš ï¸ è­¦å‘Š", warnings_count)
                    with col6:
                        st.metric("JBAç™»éŒ²ãªã—", not_found_count)
                    
                    # è¨‚æ­£ç‰ˆCSVã‚’ä½œæˆ
                    corrected_df = st.session_state.csv_system.create_corrected_csv(df, results)
                    
                    # è‰²ä»˜ãExcelã‚’ä½œæˆ
                    excel_buffer = st.session_state.csv_system.create_colored_excel(corrected_df, results)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    st.download_button(
                        label="ğŸ“Š ä¿®æ­£ç‰ˆExcelï¼ˆè‰²ä»˜ã‘ï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=excel_buffer.getvalue(),
                        file_name=f"corrected_{uploaded_file.name.replace('.csv', '.xlsx')}",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    
                    # è©³ç´°çµæœè¡¨ç¤º
                    st.subheader("ğŸ“‹ è©³ç´°çµæœ")
                    
                    # ã‚¿ãƒ–ã§çµæœã‚’åˆ†ã‘ã‚‹
                    tab1, tab2, tab3, tab4 = st.tabs(["å…¨è©³ç´°", "è­¦å‘Šä¸€è¦§", "JBAç™»éŒ²ãªã—", "è¨‚æ­£ã‚ã‚Š"])
                    
                    with tab1:
                        st.write(f"**å…¨è©³ç´°æƒ…å ±**")
                        for i, result in enumerate(results):
                            player_name = result['original_data'].get('é¸æ‰‹å', 'Unknown')
                            status_emoji = {
                                'match': 'âœ…',
                                'partial_match': 'ğŸ”¶',
                                'not_found': 'âŒ',
                                'missing_data': 'âš ï¸'
                            }.get(result['status'], 'â“')
                            
                            with st.expander(f"{status_emoji} {i+1}. {player_name}"):
                                st.write(f"çŠ¶æ…‹: {result['status']}")
                                if result.get('has_correction'):
                                    st.write("ä¿®æ­£å†…å®¹:")
                                    st.json(result['corrections'])
                                if result.get('validation_warnings'):
                                    st.write("è­¦å‘Š:")
                                    for warning in result['validation_warnings']:
                                        st.warning(warning)
                    
                    with tab2:
                        warning_results = [r for r in results if r.get('validation_warnings')]
                        if warning_results:
                            st.write(f"**è­¦å‘Š: {len(warning_results)}ä»¶**")
                            for result in warning_results:
                                player_name = result['original_data'].get('é¸æ‰‹å', 'Unknown')
                                with st.expander(f"âš ï¸ {player_name}"):
                                    for warning in result['validation_warnings']:
                                        st.warning(warning)
                        else:
                            st.success("è­¦å‘Šã¯ã‚ã‚Šã¾ã›ã‚“")
                    
                    with tab3:
                        not_found_results = [r for r in results if r['status'] == 'not_found']
                        if not_found_results:
                            st.write(f"**JBAç™»éŒ²ãªã—: {len(not_found_results)}ä»¶**")
                            for result in not_found_results:
                                player_name = result['original_data'].get('é¸æ‰‹å', 'Unknown')
                                st.warning(f"âŒ {player_name}")
                        else:
                            st.success("å…¨ã¦ç™ºè¦‹ã•ã‚Œã¾ã—ãŸ")
                    
                    with tab4:
                        # è¨‚æ­£ã‚ã‚Šã®è¡Œã®ã¿ã‚’è¡¨ç¤º
                        correction_results = [r for r in results if r.get('has_correction', False)]
                        if correction_results:
                            st.write(f"**è¨‚æ­£ã‚ã‚Š: {len(correction_results)}ä»¶**")
                            for result in correction_results:
                                player_name = result['original_data'].get('é¸æ‰‹å', 'Unknown')
                                with st.expander(f"ğŸ”§ {player_name} (è¡Œ{result['index']+1})"):
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.write("**ä¿®æ­£å‰:**")
                                        st.json(result['original_data'])
                                    with col2:
                                        st.write("**ä¿®æ­£å†…å®¹:**")
                                        st.json(result['corrections'])
                        else:
                            st.info("è¨‚æ­£ã‚ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“")
                    
        
        except Exception as e:
            st.error(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

if __name__ == "__main__":
    main()
